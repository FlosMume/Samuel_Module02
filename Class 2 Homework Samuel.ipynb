{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö Week 2 ‚Äì Data Collection & Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Tesseract OCR Guide\n",
    "\n",
    "Tesseract is an open-source Optical Character Recognition (OCR) engine developed by Google. It is used to convert scanned images, PDFs, and images with text into machine-readable text. Tesseract supports more than 100 languages, including complex scripts like Arabic, Chinese, and many others.\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Installation\n",
    "\n",
    "### **Installing Tesseract on Different Platforms**\n",
    "\n",
    "1. **On macOS** (using Homebrew):\n",
    "    ```bash\n",
    "    brew install tesseract\n",
    "    ```\n",
    "\n",
    "2. **On Ubuntu/Debian**:\n",
    "    ```bash\n",
    "    sudo apt update\n",
    "    sudo apt install tesseract-ocr\n",
    "    ```\n",
    "\n",
    "3. **On Windows**:\n",
    "    - Download the Tesseract installer from the [Tesseract GitHub releases](https://github.com/tesseract-ocr/tesseract/releases).\n",
    "    - Follow the installation instructions, and ensure to add Tesseract to your system‚Äôs `PATH`.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Basic Usage\n",
    "\n",
    "Once Tesseract is installed, you can use it either from the command line or by using the Python wrapper `pytesseract`.\n",
    "\n",
    "### **Command Line Usage**\n",
    "\n",
    "To perform OCR on an image:\n",
    "```bash\n",
    "tesseract image.png output.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Tesseract with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System >¬ª Display ¬ª Advanced display\n",
      "\n",
      "Select a display to view or change its settings Display 1: MAG 274QRFW\n",
      "\n",
      "Display information\n",
      "\n",
      "MAG 274QRFW\n",
      "Display 1: Connected to NVIDIA GeForce RTX 4070 SUPER\n",
      "\n",
      "Desktop mode 2560 x 1440, 180 Hz\n",
      "Active signal mode 2560 x 1440, 180 Hz\n",
      "Variable refresh rate Not Supported\n",
      "\n",
      "Bit depth 10-bit\n",
      "\n",
      "Color format RGB\n",
      "\n",
      "Color space High dynamic range (HDR)\n",
      "\n",
      "HDR certification Not found More about HDR certification\n",
      "Peak brightness 418 nits\n",
      "\n",
      "Display adapter properties for Display 1\n",
      "\n",
      "Choose a refresh rate\n",
      "\n",
      "180 Hz v\n",
      "A higher rate gives smoother motion, but also uses more power More about refresh rate\n",
      "Dynamic refresh rate\n",
      "To help save power, Windows adjusts the refresh rate up to the selected rate above or @\n",
      "\n",
      "Dynamic refresh rate isn't supported\n",
      "More about dynamic refresh rate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pytesseract #pip install pytesseract first\n",
    "\n",
    "# Specify the path to the tesseract.exe executable\n",
    "# Make sure this path is correct for your installation\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Load an image using Pillow (PIL)\n",
    "image = Image.open('myGPU.png')\n",
    "\n",
    "# Perform OCR on the image\n",
    "text = pytesseract.image_to_string(image)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tesseract supports over 100 languages, and you can even train it for custom languages or fonts. To use a different language, you can download the corresponding trained data files and specify the language in the -l flag.\n",
    "\n",
    "For example, to use Spanish (spa):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesseract image.png output -l spa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üßë‚Äçüíª Tesseract Best Practices\\\n",
    "Preprocess Images: Always preprocess images by converting to grayscale, adjusting brightness/contrast, and removing noise to improve Tesseract‚Äôs accuracy.\n",
    "\n",
    "Use Correct --psm: The Page Segmentation Mode (--psm) plays a crucial role in how Tesseract segments the image and interprets the text. Experiment with different modes for complex documents.\n",
    "\n",
    "Choose the Right Language: Always specify the correct language (-l lang_code) for better accuracy. Tesseract performs poorly when the language is incorrect.\n",
    "\n",
    "Custom Training: For specialized fonts or languages, you can train Tesseract to recognize custom fonts or languages. This is especially useful for handwriting or unusual fonts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Hands‚Äëon Assignment Sheet\n",
    "here is bonus part of our homework,which focuses on various aspects of data collection, extraction, and cleaning using OCR (Optical Character Recognition) technology like Tesseract, as well as other techniques such as Web Scraping and Automatic Speech Recognition (ASR). The goal is to apply different tools and methods to extract useful information from web pages, PDFs, audio files, and clean the data for further analysis.\n",
    "\n",
    "---\n",
    "### Task Overview\n",
    "\n",
    "| # | üí° Module / Skill | üéØ Task Goal | üõ†Ô∏è Core Tools | üìå Deliverables |\n",
    "|---|-------------------|--------------|----------------|-----------------|\n",
    "| **1** | üåê *Web Scraping & HTML Cleaning* | **arXiv Paper Abstract Scraper**<br>‚Ä¢ Query any subcategory (e.g., *cs.CL*) to fetch the latest 200 papers.<br>‚Ä¢ Scrape the `/abs/` page and use **Trafilatura** to clean the content.<br>‚Ä¢ Use **Tesseract OCR** to extract abstract text from screenshots of the downloaded pages.<br>‚Ä¢ Save the data as JSON: `{url, title, abstract, authors, date}` | `trafilatura`,  `pytesseract`,  | `arxiv_clean.json` (‚â§1MB) + scraper script |\n",
    "| **2** | üñºÔ∏è *PDF to Text OCR* | **Batch OCR for arXiv PDFs** (same paper set as Task 1).<br>‚Ä¢ Use **Tesseract** to convert PDFs to text.<br>‚Ä¢ Retain OCR layout (e.g., titles, sections) if needed. | `pytesseract`, `pdf2image` | `pdf_ocr/` folder with TXT files + code notebook |\n",
    "| **3** | üîä *Automatic Speech Recognition (ASR)* | **Whisper Transcription Bot** for 10 short NLP conference talks (~3 minutes each).<br>‚Ä¢ Use **yt‚Äëdl** to fetch YouTube audio.<br>‚Ä¢ Transcribe with **Tesseract** for any OCR-based text in the transcript images.<br>‚Ä¢ Save `.jsonl` with timestamps. | `yt-dlp`, `pytesseract` | `talks_transcripts.jsonl` + transcription script |\n",
    "| **4** | üßπ *Data Cleaning & Deduplication* | **End‚Äëto‚ÄëEnd Cleaner**:<br>‚Ä¢ Merge the outputs from Tasks 1‚Äë3 into one dataset.<br>‚Ä¢ Steps: language detection ‚Üí strip HTML noise ‚Üí use MinHash for deduplication (similarity ‚â• 0.7) ‚Üí remove PII (emails, credit card numbers, phone numbers) ‚Üí remove repetitive n‚Äëgrams. | `langdetect`, `datasketch` | `clean_corpus.txt` + `stats.md` (token count, removal percentage) |\n",
    "\n",
    "\n",
    "\n",
    "### üí¨ Resources\n",
    "\n",
    "1. **Trafilatura Quick Start:**  \n",
    "   - [Trafilatura Documentation](https://github.com/adbar/trafilatura)  \n",
    "   - Usage: `trafilatura.extract(html, include_comments=False, include_tables=False)`\n",
    "\n",
    "2. **Tesseract OCR:**  \n",
    "   - [Tesseract OCR GitHub Repository](https://github.com/tesseract-ocr/tesseract)  \n",
    "   - [Tesseract OCR Documentation](https://tesseract-ocr.github.io/)  \n",
    "   - [pytesseract Python Wrapper Documentation](https://github.com/madmaze/pytesseract)  \n",
    "   - Use Tesseract for OCR conversion of PDFs or images. For complex layouts, use **Tesseract‚Äôs layout analysis** feature.  \n",
    "     - Example: `text = pytesseract.image_to_string(image, config='--psm 6')`\n",
    "\n",
    "3. **Whisper Automatic Speech Recognition (ASR):**  \n",
    "   - [Whisper GitHub Repository](https://github.com/openai/whisper)  \n",
    "   - [Whisper Documentation](https://github.com/openai/whisper#usage)  \n",
    "   - To use Whisper with Python, follow the setup instructions provided on the official repository.\n",
    "\n",
    "4. **yt-dlp for Downloading YouTube Audio:**  \n",
    "   - [yt-dlp GitHub Repository](https://github.com/yt-dlp/yt-dlp)  \n",
    "   - [yt-dlp Installation and Usage](https://github.com/yt-dlp/yt-dlp#installation)\n",
    "\n",
    "5. **PDF to Image Conversion (Using `pdf2image`):**  \n",
    "   - [pdf2image Documentation](https://pdf2image.readthedocs.io/en/latest/)  \n",
    "   - This library converts PDF pages to images, which you can then process with Tesseract.\n",
    "\n",
    "6. **MinHash for Deduplication:**  \n",
    "   - [Datasketch Documentation](https://datasketch.readthedocs.io/en/latest/)  \n",
    "   - **MinHashLSH** is useful for deduplicating large text corpora by finding similar documents.\n",
    "\n",
    "7. **Cleaning HTML and Removing PII (Personally Identifiable Information):**  \n",
    "   - [BeautifulSoup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)  \n",
    "   - **langdetect** Python library for language detection:  \n",
    "     - [langdetect GitHub Repository](https://github.com/Mimino666/langdetect)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Web Scraping & HTML Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task Goal:__ arXiv Paper Abstract Scraper\n",
    "* Query any subcategory (e.g.,¬†cs.CL) to fetch the latest 200 papers.\n",
    "* Scrape the¬†/abs/¬†page and use¬†Trafilatura¬†to clean the content.\n",
    "* Use¬†Tesseract OCR¬†to extract abstract text from screenshots of the downloaded pages.\n",
    "* Save the data as JSON:¬†{url, title, abstract, authors, date}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Core Tools:__ trafilatura,¬†pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Deliverables:__ arxiv_clean.json¬†(‚â§1MB) + scraper script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the arXiv Paper Abstract Scraper in a Python Jupyter Notebook, we'll break it down into steps, utilizing the specified tools: requests for web scraping, BeautifulSoup for initial HTML parsing (though Trafilatura will do the heavy lifting for cleaning), trafilatura for content extraction and cleaning, and pytesseract for OCR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make sure you have all the necessary libraries installed. You can run the following in your Jupyter Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: requests\n",
      "Version: 2.32.2\n",
      "Summary: Python HTTP for Humans.\n",
      "Home-page: https://requests.readthedocs.io\n",
      "Author: Kenneth Reitz\n",
      "Author-email: me@kennethreitz.org\n",
      "License: Apache-2.0\n",
      "Location: C:\\Users\\ch939\\anaconda3\\Lib\\site-packages\n",
      "Requires: certifi, charset-normalizer, idna, urllib3\n",
      "Required-by: aext-assistant-server, anaconda-catalogs, anaconda-client, anaconda-cloud-auth, anaconda-project, conda, conda-build, conda-repo-cli, conda_package_streaming, cookiecutter, datasets, datashader, huggingface-hub, intake, jupyterlab_server, langchain, langchain-community, langsmith, panel, requests-file, requests-toolbelt, Sphinx, streamlit, tensorflow, tensorflow_intel, tldextract, transformers, webdriver-manager\n"
     ]
    }
   ],
   "source": [
    "!pip show requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: beautifulsoup4\n",
      "Version: 4.12.3\n",
      "Summary: Screen-scraping library\n",
      "Home-page: https://www.crummy.com/software/BeautifulSoup/bs4/\n",
      "Author: \n",
      "Author-email: Leonard Richardson <leonardr@segfault.org>\n",
      "License: MIT License\n",
      "Location: C:\\Users\\ch939\\anaconda3\\Lib\\site-packages\n",
      "Requires: soupsieve\n",
      "Required-by: conda-build, nbconvert\n"
     ]
    }
   ],
   "source": [
    "!pip show beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: trafilatura\n",
      "Version: 2.0.0\n",
      "Summary: Python & Command-line tool to gather text and metadata on the Web: Crawling, scraping, extraction, output as CSV, JSON, HTML, MD, TXT, XML.\n",
      "Home-page: https://trafilatura.readthedocs.io\n",
      "Author: \n",
      "Author-email: Adrien Barbaresi <barbaresi@bbaw.de>\n",
      "License: Apache 2.0\n",
      "Location: C:\\Users\\ch939\\anaconda3\\Lib\\site-packages\n",
      "Requires: certifi, charset_normalizer, courlan, htmldate, justext, lxml, urllib3\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show trafilatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pytesseract\n",
      "Version: 0.3.13\n",
      "Summary: Python-tesseract is a python wrapper for Google's Tesseract-OCR\n",
      "Home-page: https://github.com/madmaze/pytesseract\n",
      "Author: Samuel Hoffstaetter\n",
      "Author-email: samuel@hoffstaetter.com\n",
      "License: Apache License 2.0\n",
      "Location: C:\\Users\\ch939\\anaconda3\\Lib\\site-packages\n",
      "Requires: packaging, Pillow\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pillow\n",
      "Version: 10.3.0\n",
      "Summary: Python Imaging Library (Fork)\n",
      "Home-page: https://python-pillow.org\n",
      "Author: \n",
      "Author-email: \"Jeffrey A. Clark\" <aclark@aclark.net>\n",
      "License: HPND\n",
      "Location: C:\\Users\\ch939\\anaconda3\\Lib\\site-packages\n",
      "Requires: \n",
      "Required-by: bokeh, datashader, gradio, imageio, matplotlib, pytesseract, scikit-image, streamlit, torchvision\n"
     ]
    }
   ],
   "source": [
    "!pip show pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The Most Recommended Solution: Create and Use a Virtual Environment__\n",
    "This is the best practice for Python development. Virtual environments isolate your project's dependencies from your system-wide Python installation and from other projects. This prevents conflicts like the one you're facing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anaconda:\n",
    "1. Create a virtual environment:\n",
    "    python -m venv venv_arxiv_scraper\n",
    "2. Activate the virtual environment:\n",
    "    venv_arxiv_scraper\\Scripts\\activate.bat\n",
    "3. Install the required packages within the virtual environment:\n",
    "    pip install requests beautifulsoup4 trafilatura pytesseract pillow tensorflow-intel==2.18.0\n",
    "4. Run your Jupyter Notebook:\n",
    "    pip install ipykernel\n",
    "    python -m ipykernel install --user --name=venv_arxiv_scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping latest 200 papers from arXiv subcategory: cs.CL\n",
      "Fetching initial list from: https://arxiv.org/list/cs.CL/pastweek?skip=0&show=250\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22887\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22829\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22811\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22758\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22753\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22752\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22744\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22729\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22720\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22716\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22676\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22623\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22608\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22603\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22581\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22564\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22545\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22542\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22533\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22478\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22462\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22457\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22448\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22445\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22411\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22410\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22387\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22367\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22337\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22289\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22286\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22219\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22209\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22201\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22187\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22168\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22159\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22879\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22878\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22847\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22746\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22607\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22565\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22543\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22359\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22281\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22197\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22160\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22133\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22080\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22074\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22050\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21980\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21934\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21931\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21919\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21914\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21892\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21836\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21831\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21828\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21815\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21813\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21810\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21782\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21773\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21750\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21652\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21645\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21609\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21568\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21556\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21544\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21536\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21532\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21526\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21522\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21509\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21500\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21482\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21476\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21432\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21428\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21369\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21340\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21331\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21319\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21302\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21242\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21234\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21186\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21168\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21138\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21134\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21112\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21110\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21108\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21107\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21106\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21104\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21099\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21095\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21086\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21084\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21083\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21080\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21073\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21065\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21058\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22062\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22034\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.22025\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21903\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21513\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21420\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21391\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21389\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21276\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21257\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21184\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21183\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21170\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21105\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21103\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21089\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21075\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.17307\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21028\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.21009\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20956\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20930\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20924\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20917\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20906\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20859\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20858\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20849\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20786\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20783\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20752\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20749\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20704\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20700\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20673\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20643\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20614\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20564\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20546\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20528\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20527\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20520\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20491\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20423\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20419\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20411\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20409\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20398\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20352\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20343\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20301\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20279\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20278\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20264\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20252\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20249\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20241\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20210\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20208\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20187\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20185\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20181\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20152\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20145\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20136\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20133\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20111\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20091\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20059\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20055\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20046\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20030\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.20019\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.19995\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.19980\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.19969\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.19962\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.19906\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.19899\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.19885\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.19869\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.19867\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.19823\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.19786\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.19766\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.19756\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.19748\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.19741\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.19710\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.19699\n",
      "\n",
      "Processing paper: https://arxiv.org/abs/2507.19666\n",
      "\n",
      "Successfully scraped 200 papers and saved to arxiv_clean.json\n",
      "File size: 0.54 MB\n",
      "\n",
      "--- Sample Scraped Paper ---\n",
      "{'abstract': 'In-context learning (ICL) is a critical emerging capability of '\n",
      "             'large language models (LLMs), enabling few-shot learning during '\n",
      "             'inference by including a few demonstrations (demos) in the '\n",
      "             \"prompt. However, it has been found that ICL's performance can be \"\n",
      "             'sensitive to the choices of demos and their order. This paper '\n",
      "             'investigates an unexplored new positional bias of ICL for the '\n",
      "             'first time: we observe that the predictions and accuracy can '\n",
      "             'drift drastically when the positions of demos, the system '\n",
      "             'prompt, and the user message in LLM input are varied. We refer '\n",
      "             \"to this bias as DEMOS' POSITION IN PROMPT (DPP) bias. We design \"\n",
      "             'a systematic evaluation pipeline to study this type of '\n",
      "             'positional bias across classification, question answering, '\n",
      "             'summarization, and reasoning tasks. We introduce two metrics, '\n",
      "             'ACCURACY-CHANGE and PREDICTION-CHANGE, to quantify net gains and '\n",
      "             \"output volatility induced by changes in the demos' position. \"\n",
      "             'Extensive experiments on ten LLMs from four open-source model '\n",
      "             'families (QWEN, LLAMA3, MISTRAL, COHERE) verify that the bias '\n",
      "             'significantly affects their accuracy and predictions: placing '\n",
      "             'demos at the start of the prompt yields the most stable and '\n",
      "             'accurate outputs with gains of up to +6 points. In contrast, '\n",
      "             'placing demos at the end of the user message flips over 30\\\\% of '\n",
      "             'predictions without improving correctness on QA tasks. Smaller '\n",
      "             'models are most affected by this sensitivity, though even large '\n",
      "             'models remain marginally affected on complex tasks.\\n'\n",
      "             'Submission history\\n'\n",
      "             'From: Kwesi Adu Cobbina [view email][v1] Wed, 30 Jul 2025 '\n",
      "             '17:59:46 UTC (9,561 KB)\\n'\n",
      "             'References & Citations\\n'\n",
      "             'Bibliographic and Citation Tools\\n'\n",
      "             'Bibliographic Explorer (What is the Explorer?)\\n'\n",
      "             'Connected Papers (What is Connected Papers?)\\n'\n",
      "             'Litmaps (What is Litmaps?)\\n'\n",
      "             'scite Smart Citations (What are Smart Citations?)\\n'\n",
      "             'Code, Data and Media Associated with this Article\\n'\n",
      "             'alphaXiv (What is alphaXiv?)\\n'\n",
      "             'CatalyzeX Code Finder for Papers (What is CatalyzeX?)\\n'\n",
      "             'DagsHub (What is DagsHub?)\\n'\n",
      "             'Gotit.pub (What is GotitPub?)\\n'\n",
      "             'Hugging Face (What is Huggingface?)\\n'\n",
      "             'Papers with Code (What is Papers with Code?)\\n'\n",
      "             'ScienceCast (What is ScienceCast?)\\n'\n",
      "             'Demos\\n'\n",
      "             'Recommenders and Search Tools\\n'\n",
      "             'Influence Flower (What are Influence Flowers?)\\n'\n",
      "             'CORE Recommender (What is CORE?)\\n'\n",
      "             'arXivLabs: experimental projects with community collaborators\\n'\n",
      "             'arXivLabs is a framework that allows collaborators to develop '\n",
      "             'and share new arXiv features directly on our website.\\n'\n",
      "             'Both individuals and organizations that work with arXivLabs have '\n",
      "             'embraced and accepted our values of openness, community, '\n",
      "             'excellence, and user data privacy. arXiv is committed to these '\n",
      "             'values and only works with partners that adhere to them.\\n'\n",
      "             \"Have an idea for a project that will add value for arXiv's \"\n",
      "             'community? Learn more about arXivLabs.',\n",
      " 'authors': 'Kwesi Cobbina, Tianyi Zhou',\n",
      " 'date': 'Wed, 30 Jul 2025',\n",
      " 'title': 'Where to show Demos in Your Prompt: A Positional Bias of In-Context '\n",
      "          'Learning',\n",
      " 'url': 'https://arxiv.org/abs/2507.22887'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from trafilatura import extract\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "# Set the path to the Tesseract executable if it's not in your PATH\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/tesseract' # Example for macOS\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' # Example for Windows\n",
    "\n",
    "# --- Constants ---\n",
    "ARXIV_BASE_URL = \"https://arxiv.org\"\n",
    "ARXIV_SEARCH_URL = \"https://arxiv.org/list/cs.CL/pastweek?skip=0&show=250\"\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def fetch_page(url):\n",
    "    \"\"\"Fetches the content of a given URL.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, timeout=10)\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad responses (4xx or 5xx)\n",
    "        return response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_abstract_from_html(html_content):\n",
    "    \"\"\"\n",
    "    Extracts the abstract text from HTML content using Trafilatura.\n",
    "    If Trafilatura doesn't find a good abstract, we'll try a more specific BeautifulSoup parse.\n",
    "    \"\"\"\n",
    "    extracted_data = extract(html_content, include_comments=False, no_fallback=False)\n",
    "    if extracted_data:\n",
    "        # Trafilatura extracts the full content, we need to find the abstract part.\n",
    "        # This is a heuristic: looking for \"Abstract:\" or similar markers.\n",
    "        match = re.search(r'(?i)abstract:\\s*(.*)', extracted_data, re.DOTALL)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "        else:\n",
    "            # If no clear abstract marker, try to get a significant block of text\n",
    "            # which often is the abstract in such pages.\n",
    "            return extracted_data.strip()\n",
    "    return None\n",
    "\n",
    "def extract_info_from_abs_page(abs_page_html):\n",
    "    \"\"\"\n",
    "    Extracts title, authors, and date from the /abs/ page.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(abs_page_html, 'html.parser')\n",
    "\n",
    "    title = soup.find('h1', class_='title')\n",
    "    title = title.text.replace('Title:', '').strip() if title else 'N/A'\n",
    "\n",
    "    authors_div = soup.find('div', class_='authors')\n",
    "    authors = []\n",
    "    if authors_div:\n",
    "        for a_tag in authors_div.find_all('a'):\n",
    "            authors.append(a_tag.text.strip())\n",
    "    authors_str = ', '.join(authors) if authors else 'N/A'\n",
    "\n",
    "    date_line = soup.find('div', class_='submission-history')\n",
    "    date = 'N/A'\n",
    "    if date_line:\n",
    "        # Example: [v1] Thu, 1 Jul 2024 13:00:00 UTC (1,234KB)\n",
    "        match = re.search(r'\\[v\\d+\\]\\s*([^,]+,\\s*\\d+\\s+\\w+\\s+\\d{4})', date_line.text)\n",
    "        if match:\n",
    "            date = match.group(1).strip()\n",
    "    return title, authors_str, date\n",
    "\n",
    "def get_screenshot_and_ocr(url):\n",
    "    \"\"\"\n",
    "    (Conceptual) This function would typically require a headless browser (e.g., Selenium)\n",
    "    to render the page and take a screenshot. For this exercise, we will simulate\n",
    "    it by attempting to use Trafilatura's text and, if it fails to find an abstract,\n",
    "    we would acknowledge the need for a visual capture and OCR.\n",
    "\n",
    "    As direct \"screenshot taking\" from a URL without a browser is not possible\n",
    "    with `requests` or `BeautifulSoup`, this part of the task is more conceptual\n",
    "    for a pure `requests`/`bs4` setup. If OCR is *strictly* required for downloaded pages,\n",
    "    a headless browser (like Selenium with ChromeDriver) would be necessary to\n",
    "    capture an image of the abstract section.\n",
    "\n",
    "    For the sake of this implementation, we'll focus on text extraction first.\n",
    "    If a clear abstract is not found via HTML parsing, we'll flag it.\n",
    "    \"\"\"\n",
    "    print(f\"  Attempting OCR fallback for {url} (Requires screenshot tool, not implemented here directly).\")\n",
    "    # In a real scenario, you would use Selenium to get a screenshot\n",
    "    # Example (requires selenium and a webdriver):\n",
    "    # from selenium import webdriver\n",
    "    # from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "    # from webdriver_manager.chrome import ChromeDriverManager\n",
    "    #\n",
    "    # options = webdriver.ChromeOptions()\n",
    "    # options.add_argument('--headless')\n",
    "    # options.add_argument('--disable-gpu')\n",
    "    # driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "    # driver.get(url)\n",
    "    # driver.save_screenshot('temp_screenshot.png')\n",
    "    # driver.quit()\n",
    "    #\n",
    "    # text = pytesseract.image_to_string(Image.open('temp_screenshot.png'))\n",
    "    # return text\n",
    "    return \"OCR fallback simulated: Could not extract abstract directly.\"\n",
    "\n",
    "\n",
    "# --- Main Scraper Function ---\n",
    "\n",
    "def scrape_arxiv_subcategory(subcategory, num_papers=200):\n",
    "    \"\"\"\n",
    "    Scrapes the latest papers from a given arXiv subcategory.\n",
    "    \"\"\"\n",
    "    print(f\"Scraping latest {num_papers} papers from arXiv subcategory: {subcategory}\")\n",
    "    initial_url = ARXIV_SEARCH_URL.format(subcategory=subcategory, num_papers=num_papers)\n",
    "    print(f\"Fetching initial list from: {initial_url}\")\n",
    "\n",
    "    html_list_page = fetch_page(initial_url)\n",
    "    if not html_list_page:\n",
    "        print(\"Failed to fetch the initial list page.\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(html_list_page, 'html.parser')\n",
    "    paper_entries = soup.find_all('dt') # <dt> holds the paper id\n",
    "    paper_metadata = soup.find_all('dd') # <dd> holds the title, authors, abstract link\n",
    "\n",
    "    papers_data = []\n",
    "\n",
    "    for i in range(min(len(paper_entries), len(paper_metadata), num_papers)):\n",
    "        entry_dt = paper_entries[i]\n",
    "        entry_dd = paper_metadata[i]\n",
    "\n",
    "        paper_id_link = entry_dt.find('a', title=\"Abstract\")\n",
    "        if not paper_id_link:\n",
    "            continue\n",
    "\n",
    "        paper_url = ARXIV_BASE_URL + paper_id_link['href']\n",
    "\n",
    "        print(f\"\\nProcessing paper: {paper_url}\")\n",
    "\n",
    "        # Fetch the /abs/ page\n",
    "        abs_page_html = fetch_page(paper_url)\n",
    "        if not abs_page_html:\n",
    "            print(f\"Skipping {paper_url} due to fetch error.\")\n",
    "            continue\n",
    "\n",
    "        title, authors, date = extract_info_from_abs_page(abs_page_html)\n",
    "\n",
    "        # Try to extract abstract using Trafilatura\n",
    "        abstract = extract_abstract_from_html(abs_page_html)\n",
    "\n",
    "        if not abstract or \"OCR fallback simulated\" in abstract: # Check if Trafilatura was insufficient\n",
    "            print(f\"  Abstract not clearly found via Trafilatura for {paper_url}. Attempting OCR fallback (conceptual).\")\n",
    "            # In a real scenario, you would trigger the Selenium-based screenshot and OCR here.\n",
    "            # For this exercise, we'll acknowledge the limitation and use a placeholder or\n",
    "            # indicate that a direct HTML parse might be sufficient for many cases.\n",
    "            abstract_via_ocr = get_screenshot_and_ocr(paper_url) # This is conceptual\n",
    "            if \"OCR fallback simulated\" in abstract_via_ocr and not abstract:\n",
    "                abstract = \"Abstract could not be extracted via direct parsing or simulated OCR fallback.\"\n",
    "            elif \"OCR fallback simulated\" not in abstract_via_ocr:\n",
    "                abstract = abstract_via_ocr # If OCR worked conceptually\n",
    "\n",
    "        paper_info = {\n",
    "            \"url\": paper_url,\n",
    "            \"title\": title,\n",
    "            \"abstract\": abstract,\n",
    "            \"authors\": authors,\n",
    "            \"date\": date\n",
    "        }\n",
    "        papers_data.append(paper_info)\n",
    "        time.sleep(0.5) # Be polite to the server\n",
    "\n",
    "        if len(papers_data) >= num_papers:\n",
    "            break\n",
    "\n",
    "    return papers_data\n",
    "\n",
    "# --- Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    subcategory_to_query = \"cs.CL\" # Example: Computational Linguistics\n",
    "    num_papers_to_fetch = 200\n",
    "\n",
    "    scraped_papers = scrape_arxiv_subcategory(subcategory_to_query, num_papers_to_fetch)\n",
    "\n",
    "    # Save to JSON\n",
    "    output_filename = \"arxiv_clean.json\"\n",
    "    try:\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(scraped_papers, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"\\nSuccessfully scraped {len(scraped_papers)} papers and saved to {output_filename}\")\n",
    "        print(f\"File size: {round(os.path.getsize(output_filename) / (1024 * 1024), 2)} MB\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving JSON file: {e}\")\n",
    "\n",
    "    # Optional: Display a sample of the scraped data\n",
    "    if scraped_papers:\n",
    "        print(\"\\n--- Sample Scraped Paper ---\")\n",
    "        import pprint\n",
    "        pprint.pprint(scraped_papers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: PDF to Text OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task Goal:__ Batch OCR for arXiv PDFs (same paper set as Module 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Deliverables:__ pdf_ocr/ folder with TXT files + code notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ore Tools:__ pytesseract, pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdf2image\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from pdf2image) (10.3.0)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pdf2image\n",
      "Successfully installed pdf2image-1.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading paper data from: arxiv_clean.json\n",
      "Found 200 papers to process for PDF OCR.\n",
      "\n",
      "Processing paper 1/200: Where to show Demos in Your Prompt: A Positional Bias of In-Context Learning\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22887\n",
      "  Performing OCR on: 2507.22887.pdf\n",
      "    Processing page 1/34\n",
      "    Processing page 2/34\n",
      "    Processing page 3/34\n",
      "    Processing page 4/34\n",
      "    Processing page 5/34\n",
      "    Processing page 6/34\n",
      "    Processing page 7/34\n",
      "    Processing page 8/34\n",
      "    Processing page 9/34\n",
      "    Processing page 10/34\n",
      "    Processing page 11/34\n",
      "    Processing page 12/34\n",
      "    Processing page 13/34\n",
      "    Processing page 14/34\n",
      "    Processing page 15/34\n",
      "    Processing page 16/34\n",
      "    Processing page 17/34\n",
      "    Processing page 18/34\n",
      "    Processing page 19/34\n",
      "    Processing page 20/34\n",
      "    Processing page 21/34\n",
      "    Processing page 22/34\n",
      "    Processing page 23/34\n",
      "    Processing page 24/34\n",
      "    Processing page 25/34\n",
      "    Processing page 26/34\n",
      "    Processing page 27/34\n",
      "    Processing page 28/34\n",
      "    Processing page 29/34\n",
      "    Processing page 30/34\n",
      "    Processing page 31/34\n",
      "    Processing page 32/34\n",
      "    Processing page 33/34\n",
      "    Processing page 34/34\n",
      "  OCR complete. Text saved to: 2507.22887.txt\n",
      "\n",
      "Processing paper 2/200: Beyond Natural Language Plans: Structure-Aware Planning for Query-Focused Table Summarization\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22829\n",
      "  Performing OCR on: 2507.22829.pdf\n",
      "    Processing page 1/10\n",
      "    Processing page 2/10\n",
      "    Processing page 3/10\n",
      "    Processing page 4/10\n",
      "    Processing page 5/10\n",
      "    Processing page 6/10\n",
      "    Processing page 7/10\n",
      "    Processing page 8/10\n",
      "    Processing page 9/10\n",
      "    Processing page 10/10\n",
      "  OCR complete. Text saved to: 2507.22829.txt\n",
      "\n",
      "Processing paper 3/200: DBLPLink 2.0 -- An Entity Linker for the DBLP Scholarly Knowledge Graph\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22811\n",
      "  Performing OCR on: 2507.22811.pdf\n",
      "    Processing page 1/6\n",
      "    Processing page 2/6\n",
      "    Processing page 3/6\n",
      "    Processing page 4/6\n",
      "    Processing page 5/6\n",
      "    Processing page 6/6\n",
      "  OCR complete. Text saved to: 2507.22811.txt\n",
      "\n",
      "Processing paper 4/200: MASCA: LLM based-Multi Agents System for Credit Assessment\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22758\n",
      "  Performing OCR on: 2507.22758.pdf\n",
      "    Processing page 1/19\n",
      "    Processing page 2/19\n",
      "    Processing page 3/19\n",
      "    Processing page 4/19\n",
      "    Processing page 5/19\n",
      "    Processing page 6/19\n",
      "    Processing page 7/19\n",
      "    Processing page 8/19\n",
      "    Processing page 9/19\n",
      "    Processing page 10/19\n",
      "    Processing page 11/19\n",
      "    Processing page 12/19\n",
      "    Processing page 13/19\n",
      "    Processing page 14/19\n",
      "    Processing page 15/19\n",
      "    Processing page 16/19\n",
      "    Processing page 17/19\n",
      "    Processing page 18/19\n",
      "    Processing page 19/19\n",
      "  OCR complete. Text saved to: 2507.22758.txt\n",
      "\n",
      "Processing paper 5/200: Opportunities and Challenges of LLMs in Education: An NLP Perspective\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22753\n",
      "  Performing OCR on: 2507.22753.pdf\n",
      "    Processing page 1/33\n",
      "    Processing page 2/33\n",
      "    Processing page 3/33\n",
      "    Processing page 4/33\n",
      "    Processing page 5/33\n",
      "    Processing page 6/33\n",
      "    Processing page 7/33\n",
      "    Processing page 8/33\n",
      "    Processing page 9/33\n",
      "    Processing page 10/33\n",
      "    Processing page 11/33\n",
      "    Processing page 12/33\n",
      "    Processing page 13/33\n",
      "    Processing page 14/33\n",
      "    Processing page 15/33\n",
      "    Processing page 16/33\n",
      "    Processing page 17/33\n",
      "    Processing page 18/33\n",
      "    Processing page 19/33\n",
      "    Processing page 20/33\n",
      "    Processing page 21/33\n",
      "    Processing page 22/33\n",
      "    Processing page 23/33\n",
      "    Processing page 24/33\n",
      "    Processing page 25/33\n",
      "    Processing page 26/33\n",
      "    Processing page 27/33\n",
      "    Processing page 28/33\n",
      "    Processing page 29/33\n",
      "    Processing page 30/33\n",
      "    Processing page 31/33\n",
      "    Processing page 32/33\n",
      "    Processing page 33/33\n",
      "  OCR complete. Text saved to: 2507.22753.txt\n",
      "\n",
      "Processing paper 6/200: CUS-QA: Local-Knowledge-Oriented Open-Ended Question Answering Dataset\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22752\n",
      "  Performing OCR on: 2507.22752.pdf\n",
      "    Processing page 1/20\n",
      "    Processing page 2/20\n",
      "    Processing page 3/20\n",
      "    Processing page 4/20\n",
      "    Processing page 5/20\n",
      "    Processing page 6/20\n",
      "    Processing page 7/20\n",
      "    Processing page 8/20\n",
      "    Processing page 9/20\n",
      "    Processing page 10/20\n",
      "    Processing page 11/20\n",
      "    Processing page 12/20\n",
      "    Processing page 13/20\n",
      "    Processing page 14/20\n",
      "    Processing page 15/20\n",
      "    Processing page 16/20\n",
      "    Processing page 17/20\n",
      "    Processing page 18/20\n",
      "    Processing page 19/20\n",
      "    Processing page 20/20\n",
      "  OCR complete. Text saved to: 2507.22752.txt\n",
      "\n",
      "Processing paper 7/200: Reducing Hallucinations in Summarization via Reinforcement Learning with Entity Hallucination Index\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22744\n",
      "  Performing OCR on: 2507.22744.pdf\n",
      "    Processing page 1/9\n",
      "    Processing page 2/9\n",
      "    Processing page 3/9\n",
      "    Processing page 4/9\n",
      "    Processing page 5/9\n",
      "    Processing page 6/9\n",
      "    Processing page 7/9\n",
      "    Processing page 8/9\n",
      "    Processing page 9/9\n",
      "  OCR complete. Text saved to: 2507.22744.txt\n",
      "\n",
      "Processing paper 8/200: Resource-Efficient Adaptation of Large Language Models for Text Embeddings via Prompt Engineering and Contrastive Fine-tuning\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22729\n",
      "  Performing OCR on: 2507.22729.pdf\n",
      "    Processing page 1/11\n",
      "    Processing page 2/11\n",
      "    Processing page 3/11\n",
      "    Processing page 4/11\n",
      "    Processing page 5/11\n",
      "    Processing page 6/11\n",
      "    Processing page 7/11\n",
      "    Processing page 8/11\n",
      "    Processing page 9/11\n",
      "    Processing page 10/11\n",
      "    Processing page 11/11\n",
      "  OCR complete. Text saved to: 2507.22729.txt\n",
      "\n",
      "Processing paper 9/200: Investigating Hallucination in Conversations for Low Resource Languages\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22720\n",
      "  Performing OCR on: 2507.22720.pdf\n",
      "    Processing page 1/19\n",
      "    Processing page 2/19\n",
      "    Processing page 3/19\n",
      "    Processing page 4/19\n",
      "    Processing page 5/19\n",
      "    Processing page 6/19\n",
      "    Processing page 7/19\n",
      "    Processing page 8/19\n",
      "    Processing page 9/19\n",
      "    Processing page 10/19\n",
      "    Processing page 11/19\n",
      "    Processing page 12/19\n",
      "    Processing page 13/19\n",
      "    Processing page 14/19\n",
      "    Processing page 15/19\n",
      "    Processing page 16/19\n",
      "    Processing page 17/19\n",
      "    Processing page 18/19\n",
      "    Processing page 19/19\n",
      "  OCR complete. Text saved to: 2507.22720.txt\n",
      "\n",
      "Processing paper 10/200: From Sufficiency to Reflection: Reinforcement-Guided Thinking Quality in Retrieval-Augmented Reasoning for LLMs\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22716\n",
      "  Performing OCR on: 2507.22716.pdf\n",
      "    Processing page 1/26\n",
      "    Processing page 2/26\n",
      "    Processing page 3/26\n",
      "    Processing page 4/26\n",
      "    Processing page 5/26\n",
      "    Processing page 6/26\n",
      "    Processing page 7/26\n",
      "    Processing page 8/26\n",
      "    Processing page 9/26\n",
      "    Processing page 10/26\n",
      "    Processing page 11/26\n",
      "    Processing page 12/26\n",
      "    Processing page 13/26\n",
      "    Processing page 14/26\n",
      "    Processing page 15/26\n",
      "    Processing page 16/26\n",
      "    Processing page 17/26\n",
      "    Processing page 18/26\n",
      "    Processing page 19/26\n",
      "    Processing page 20/26\n",
      "    Processing page 21/26\n",
      "    Processing page 22/26\n",
      "    Processing page 23/26\n",
      "    Processing page 24/26\n",
      "    Processing page 25/26\n",
      "    Processing page 26/26\n",
      "  OCR complete. Text saved to: 2507.22716.txt\n",
      "\n",
      "Processing paper 11/200: Listening to the Unspoken: Exploring 365 Aspects of Multimodal Interview Performance Assessment\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22676\n",
      "  Performing OCR on: 2507.22676.pdf\n",
      "    Processing page 1/8\n",
      "    Processing page 2/8\n",
      "    Processing page 3/8\n",
      "    Processing page 4/8\n",
      "    Processing page 5/8\n",
      "    Processing page 6/8\n",
      "    Processing page 7/8\n",
      "    Processing page 8/8\n",
      "  OCR complete. Text saved to: 2507.22676.txt\n",
      "\n",
      "Processing paper 12/200: Multilingual Political Views of Large Language Models: Identification and Steering\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22623\n",
      "  Performing OCR on: 2507.22623.pdf\n",
      "    Processing page 1/41\n",
      "    Processing page 2/41\n",
      "    Processing page 3/41\n",
      "    Processing page 4/41\n",
      "    Processing page 5/41\n",
      "    Processing page 6/41\n",
      "    Processing page 7/41\n",
      "    Processing page 8/41\n",
      "    Processing page 9/41\n",
      "    Processing page 10/41\n",
      "    Processing page 11/41\n",
      "    Processing page 12/41\n",
      "    Processing page 13/41\n",
      "    Processing page 14/41\n",
      "    Processing page 15/41\n",
      "    Processing page 16/41\n",
      "    Processing page 17/41\n",
      "    Processing page 18/41\n",
      "    Processing page 19/41\n",
      "    Processing page 20/41\n",
      "    Processing page 21/41\n",
      "    Processing page 22/41\n",
      "    Processing page 23/41\n",
      "    Processing page 24/41\n",
      "    Processing page 25/41\n",
      "    Processing page 26/41\n",
      "    Processing page 27/41\n",
      "    Processing page 28/41\n",
      "    Processing page 29/41\n",
      "    Processing page 30/41\n",
      "    Processing page 31/41\n",
      "    Processing page 32/41\n",
      "    Processing page 33/41\n",
      "    Processing page 34/41\n",
      "    Processing page 35/41\n",
      "    Processing page 36/41\n",
      "    Processing page 37/41\n",
      "    Processing page 38/41\n",
      "    Processing page 39/41\n",
      "    Processing page 40/41\n",
      "    Processing page 41/41\n",
      "  OCR complete. Text saved to: 2507.22623.txt\n",
      "\n",
      "Processing paper 13/200: Language Arithmetics: Towards Systematic Language Neuron Identification and Manipulation\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22608\n",
      "  Performing OCR on: 2507.22608.pdf\n",
      "    Processing page 1/31\n",
      "    Processing page 2/31\n",
      "    Processing page 3/31\n",
      "    Processing page 4/31\n",
      "    Processing page 5/31\n",
      "    Processing page 6/31\n",
      "    Processing page 7/31\n",
      "    Processing page 8/31\n",
      "    Processing page 9/31\n",
      "    Processing page 10/31\n",
      "    Processing page 11/31\n",
      "    Processing page 12/31\n",
      "    Processing page 13/31\n",
      "    Processing page 14/31\n",
      "    Processing page 15/31\n",
      "    Processing page 16/31\n",
      "    Processing page 17/31\n",
      "    Processing page 18/31\n",
      "    Processing page 19/31\n",
      "    Processing page 20/31\n",
      "    Processing page 21/31\n",
      "    Processing page 22/31\n",
      "    Processing page 23/31\n",
      "    Processing page 24/31\n",
      "    Processing page 25/31\n",
      "    Processing page 26/31\n",
      "    Processing page 27/31\n",
      "    Processing page 28/31\n",
      "    Processing page 29/31\n",
      "    Processing page 30/31\n",
      "    Processing page 31/31\n",
      "  OCR complete. Text saved to: 2507.22608.txt\n",
      "\n",
      "Processing paper 14/200: BALSAM: A Platform for Benchmarking Arabic Large Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22603\n",
      "  Performing OCR on: 2507.22603.pdf\n",
      "    Processing page 1/17\n",
      "    Processing page 2/17\n",
      "    Processing page 3/17\n",
      "    Processing page 4/17\n",
      "    Processing page 5/17\n",
      "    Processing page 6/17\n",
      "    Processing page 7/17\n",
      "    Processing page 8/17\n",
      "    Processing page 9/17\n",
      "    Processing page 10/17\n",
      "    Processing page 11/17\n",
      "    Processing page 12/17\n",
      "    Processing page 13/17\n",
      "    Processing page 14/17\n",
      "    Processing page 15/17\n",
      "    Processing page 16/17\n",
      "    Processing page 17/17\n",
      "  OCR complete. Text saved to: 2507.22603.txt\n",
      "\n",
      "Processing paper 15/200: Unveiling the Influence of Amplifying Language-Specific Neurons\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22581\n",
      "  Performing OCR on: 2507.22581.pdf\n",
      "    Processing page 1/50\n",
      "    Processing page 2/50\n",
      "    Processing page 3/50\n",
      "    Processing page 4/50\n",
      "    Processing page 5/50\n",
      "    Processing page 6/50\n",
      "    Processing page 7/50\n",
      "    Processing page 8/50\n",
      "    Processing page 9/50\n",
      "    Processing page 10/50\n",
      "    Processing page 11/50\n",
      "    Processing page 12/50\n",
      "    Processing page 13/50\n",
      "    Processing page 14/50\n",
      "    Processing page 15/50\n",
      "    Processing page 16/50\n",
      "    Processing page 17/50\n",
      "    Processing page 18/50\n",
      "    Processing page 19/50\n",
      "    Processing page 20/50\n",
      "    Processing page 21/50\n",
      "    Processing page 22/50\n",
      "    Processing page 23/50\n",
      "    Processing page 24/50\n",
      "    Processing page 25/50\n",
      "    Processing page 26/50\n",
      "    Processing page 27/50\n",
      "    Processing page 28/50\n",
      "    Processing page 29/50\n",
      "    Processing page 30/50\n",
      "    Processing page 31/50\n",
      "    Processing page 32/50\n",
      "    Processing page 33/50\n",
      "    Processing page 34/50\n",
      "    Processing page 35/50\n",
      "    Processing page 36/50\n",
      "    Processing page 37/50\n",
      "    Processing page 38/50\n",
      "    Processing page 39/50\n",
      "    Processing page 40/50\n",
      "    Processing page 41/50\n",
      "    Processing page 42/50\n",
      "    Processing page 43/50\n",
      "    Processing page 44/50\n",
      "    Processing page 45/50\n",
      "    Processing page 46/50\n",
      "    Processing page 47/50\n",
      "    Processing page 48/50\n",
      "    Processing page 49/50\n",
      "    Processing page 50/50\n",
      "  OCR complete. Text saved to: 2507.22581.txt\n",
      "\n",
      "Processing paper 16/200: Exploiting Synergistic Cognitive Biases to Bypass Safety in LLMs\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22564\n",
      "  Performing OCR on: 2507.22564.pdf\n",
      "    Processing page 1/26\n",
      "    Processing page 2/26\n",
      "    Processing page 3/26\n",
      "    Processing page 4/26\n",
      "    Processing page 5/26\n",
      "    Processing page 6/26\n",
      "    Processing page 7/26\n",
      "    Processing page 8/26\n",
      "    Processing page 9/26\n",
      "    Processing page 10/26\n",
      "    Processing page 11/26\n",
      "    Processing page 12/26\n",
      "    Processing page 13/26\n",
      "    Processing page 14/26\n",
      "    Processing page 15/26\n",
      "    Processing page 16/26\n",
      "    Processing page 17/26\n",
      "    Processing page 18/26\n",
      "    Processing page 19/26\n",
      "    Processing page 20/26\n",
      "    Processing page 21/26\n",
      "    Processing page 22/26\n",
      "    Processing page 23/26\n",
      "    Processing page 24/26\n",
      "    Processing page 25/26\n",
      "    Processing page 26/26\n",
      "  OCR complete. Text saved to: 2507.22564.txt\n",
      "\n",
      "Processing paper 17/200: ControlMed: Adding Reasoning Control to Medical Language Model\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22545\n",
      "  Performing OCR on: 2507.22545.pdf\n",
      "    Processing page 1/13\n",
      "    Processing page 2/13\n",
      "    Processing page 3/13\n",
      "    Processing page 4/13\n",
      "    Processing page 5/13\n",
      "    Processing page 6/13\n",
      "    Processing page 7/13\n",
      "    Processing page 8/13\n",
      "    Processing page 9/13\n",
      "    Processing page 10/13\n",
      "    Processing page 11/13\n",
      "    Processing page 12/13\n",
      "    Processing page 13/13\n",
      "  OCR complete. Text saved to: 2507.22545.txt\n",
      "\n",
      "Processing paper 18/200: A Benchmark Dataset and Evaluation Framework for Vietnamese Large Language Models in Customer Support\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22542\n",
      "  Performing OCR on: 2507.22542.pdf\n",
      "    Processing page 1/15\n",
      "    Processing page 2/15\n",
      "    Processing page 3/15\n",
      "    Processing page 4/15\n",
      "    Processing page 5/15\n",
      "    Processing page 6/15\n",
      "    Processing page 7/15\n",
      "    Processing page 8/15\n",
      "    Processing page 9/15\n",
      "    Processing page 10/15\n",
      "    Processing page 11/15\n",
      "    Processing page 12/15\n",
      "    Processing page 13/15\n",
      "    Processing page 14/15\n",
      "    Processing page 15/15\n",
      "  OCR complete. Text saved to: 2507.22542.txt\n",
      "\n",
      "Processing paper 19/200: CliCARE: Grounding Large Language Models in Clinical Guidelines for Decision Support over Longitudinal Cancer Electronic Health Records\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22533\n",
      "  Performing OCR on: 2507.22533.pdf\n",
      "    Processing page 1/17\n",
      "    Processing page 2/17\n",
      "    Processing page 3/17\n",
      "    Processing page 4/17\n",
      "    Processing page 5/17\n",
      "    Processing page 6/17\n",
      "    Processing page 7/17\n",
      "    Processing page 8/17\n",
      "    Processing page 9/17\n",
      "    Processing page 10/17\n",
      "    Processing page 11/17\n",
      "    Processing page 12/17\n",
      "    Processing page 13/17\n",
      "    Processing page 14/17\n",
      "    Processing page 15/17\n",
      "    Processing page 16/17\n",
      "    Processing page 17/17\n",
      "  OCR complete. Text saved to: 2507.22533.txt\n",
      "\n",
      "Processing paper 20/200: SLM-SQL: An Exploration of Small Language Models for Text-to-SQL\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22478\n",
      "  Performing OCR on: 2507.22478.pdf\n",
      "    Processing page 1/16\n",
      "    Processing page 2/16\n",
      "    Processing page 3/16\n",
      "    Processing page 4/16\n",
      "    Processing page 5/16\n",
      "    Processing page 6/16\n",
      "    Processing page 7/16\n",
      "    Processing page 8/16\n",
      "    Processing page 9/16\n",
      "    Processing page 10/16\n",
      "    Processing page 11/16\n",
      "    Processing page 12/16\n",
      "    Processing page 13/16\n",
      "    Processing page 14/16\n",
      "    Processing page 15/16\n",
      "    Processing page 16/16\n",
      "  OCR complete. Text saved to: 2507.22478.txt\n",
      "\n",
      "Processing paper 21/200: IFEvalCode: Controlled Code Generation\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22462\n",
      "  Performing OCR on: 2507.22462.pdf\n",
      "    Processing page 1/25\n",
      "    Processing page 2/25\n",
      "    Processing page 3/25\n",
      "    Processing page 4/25\n",
      "    Processing page 5/25\n",
      "    Processing page 6/25\n",
      "    Processing page 7/25\n",
      "    Processing page 8/25\n",
      "    Processing page 9/25\n",
      "    Processing page 10/25\n",
      "    Processing page 11/25\n",
      "    Processing page 12/25\n",
      "    Processing page 13/25\n",
      "    Processing page 14/25\n",
      "    Processing page 15/25\n",
      "    Processing page 16/25\n",
      "    Processing page 17/25\n",
      "    Processing page 18/25\n",
      "    Processing page 19/25\n",
      "    Processing page 20/25\n",
      "    Processing page 21/25\n",
      "    Processing page 22/25\n",
      "    Processing page 23/25\n",
      "    Processing page 24/25\n",
      "    Processing page 25/25\n",
      "  OCR complete. Text saved to: 2507.22462.txt\n",
      "\n",
      "Processing paper 22/200: What is an \"Abstract Reasoner\"? Revisiting Experiments and Arguments about Large Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22457\n",
      "  Performing OCR on: 2507.22457.pdf\n",
      "    Processing page 1/13\n",
      "    Processing page 2/13\n",
      "    Processing page 3/13\n",
      "    Processing page 4/13\n",
      "    Processing page 5/13\n",
      "    Processing page 6/13\n",
      "    Processing page 7/13\n",
      "    Processing page 8/13\n",
      "    Processing page 9/13\n",
      "    Processing page 10/13\n",
      "    Processing page 11/13\n",
      "    Processing page 12/13\n",
      "    Processing page 13/13\n",
      "  OCR complete. Text saved to: 2507.22457.txt\n",
      "\n",
      "Processing paper 23/200: Falcon-H1: A Family of Hybrid-Head Language Models Redefining Efficiency and Performance\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22448\n",
      "  Performing OCR on: 2507.22448.pdf\n",
      "    Processing page 1/81\n",
      "    Processing page 2/81\n",
      "    Processing page 3/81\n",
      "    Processing page 4/81\n",
      "    Processing page 5/81\n",
      "    Processing page 6/81\n",
      "    Processing page 7/81\n",
      "    Processing page 8/81\n",
      "    Processing page 9/81\n",
      "    Processing page 10/81\n",
      "    Processing page 11/81\n",
      "    Processing page 12/81\n",
      "    Processing page 13/81\n",
      "    Processing page 14/81\n",
      "    Processing page 15/81\n",
      "    Processing page 16/81\n",
      "    Processing page 17/81\n",
      "    Processing page 18/81\n",
      "    Processing page 19/81\n",
      "    Processing page 20/81\n",
      "    Processing page 21/81\n",
      "    Processing page 22/81\n",
      "    Processing page 23/81\n",
      "    Processing page 24/81\n",
      "    Processing page 25/81\n",
      "    Processing page 26/81\n",
      "    Processing page 27/81\n",
      "    Processing page 28/81\n",
      "    Processing page 29/81\n",
      "    Processing page 30/81\n",
      "    Processing page 31/81\n",
      "    Processing page 32/81\n",
      "    Processing page 33/81\n",
      "    Processing page 34/81\n",
      "    Processing page 35/81\n",
      "    Processing page 36/81\n",
      "    Processing page 37/81\n",
      "    Processing page 38/81\n",
      "    Processing page 39/81\n",
      "    Processing page 40/81\n",
      "    Processing page 41/81\n",
      "    Processing page 42/81\n",
      "    Processing page 43/81\n",
      "    Processing page 44/81\n",
      "    Processing page 45/81\n",
      "    Processing page 46/81\n",
      "    Processing page 47/81\n",
      "    Processing page 48/81\n",
      "    Processing page 49/81\n",
      "    Processing page 50/81\n",
      "    Processing page 51/81\n",
      "    Processing page 52/81\n",
      "    Processing page 53/81\n",
      "    Processing page 54/81\n",
      "    Processing page 55/81\n",
      "    Processing page 56/81\n",
      "    Processing page 57/81\n",
      "    Processing page 58/81\n",
      "    Processing page 59/81\n",
      "    Processing page 60/81\n",
      "    Processing page 61/81\n",
      "    Processing page 62/81\n",
      "    Processing page 63/81\n",
      "    Processing page 64/81\n",
      "    Processing page 65/81\n",
      "    Processing page 66/81\n",
      "    Processing page 67/81\n",
      "    Processing page 68/81\n",
      "    Processing page 69/81\n",
      "    Processing page 70/81\n",
      "    Processing page 71/81\n",
      "    Processing page 72/81\n",
      "    Processing page 73/81\n",
      "    Processing page 74/81\n",
      "    Processing page 75/81\n",
      "    Processing page 76/81\n",
      "    Processing page 77/81\n",
      "    Processing page 78/81\n",
      "    Processing page 79/81\n",
      "    Processing page 80/81\n",
      "    Processing page 81/81\n",
      "  OCR complete. Text saved to: 2507.22448.txt\n",
      "\n",
      "Processing paper 24/200: AI-generated stories favour stability over change: homogeneity and cultural stereotyping in narratives generated by gpt-4o-mini\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22445\n",
      "  Performing OCR on: 2507.22445.pdf\n",
      "    Processing page 1/17\n",
      "    Processing page 2/17\n",
      "    Processing page 3/17\n",
      "    Processing page 4/17\n",
      "    Processing page 5/17\n",
      "    Processing page 6/17\n",
      "    Processing page 7/17\n",
      "    Processing page 8/17\n",
      "    Processing page 9/17\n",
      "    Processing page 10/17\n",
      "    Processing page 11/17\n",
      "    Processing page 12/17\n",
      "    Processing page 13/17\n",
      "    Processing page 14/17\n",
      "    Processing page 15/17\n",
      "    Processing page 16/17\n",
      "    Processing page 17/17\n",
      "  OCR complete. Text saved to: 2507.22445.txt\n",
      "\n",
      "Processing paper 25/200: NeedleChain: Measuring Intact Long-Context Reasoning Capability of Large Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22411\n",
      "  Performing OCR on: 2507.22411.pdf\n",
      "    Processing page 1/13\n",
      "    Processing page 2/13\n",
      "    Processing page 3/13\n",
      "    Processing page 4/13\n",
      "    Processing page 5/13\n",
      "    Processing page 6/13\n",
      "    Processing page 7/13\n",
      "    Processing page 8/13\n",
      "    Processing page 9/13\n",
      "    Processing page 10/13\n",
      "    Processing page 11/13\n",
      "    Processing page 12/13\n",
      "    Processing page 13/13\n",
      "  OCR complete. Text saved to: 2507.22411.txt\n",
      "\n",
      "Processing paper 26/200: Question Generation for Assessing Early Literacy Reading Comprehension\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22410\n",
      "  Performing OCR on: 2507.22410.pdf\n",
      "    Processing page 1/2\n",
      "    Processing page 2/2\n",
      "  OCR complete. Text saved to: 2507.22410.txt\n",
      "\n",
      "Processing paper 27/200: PATENTWRITER: A Benchmarking Study for Patent Drafting with LLMs\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22387\n",
      "  Performing OCR on: 2507.22387.pdf\n",
      "    Processing page 1/16\n",
      "    Processing page 2/16\n",
      "    Processing page 3/16\n",
      "    Processing page 4/16\n",
      "    Processing page 5/16\n",
      "    Processing page 6/16\n",
      "    Processing page 7/16\n",
      "    Processing page 8/16\n",
      "    Processing page 9/16\n",
      "    Processing page 10/16\n",
      "    Processing page 11/16\n",
      "    Processing page 12/16\n",
      "    Processing page 13/16\n",
      "    Processing page 14/16\n",
      "    Processing page 15/16\n",
      "    Processing page 16/16\n",
      "  OCR complete. Text saved to: 2507.22387.txt\n",
      "\n",
      "Processing paper 28/200: Traits Run Deep: Enhancing Personality Assessment via Psychology-Guided LLM Representations and Multimodal Apparent Behaviors\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22367\n",
      "  Performing OCR on: 2507.22367.pdf\n",
      "    Processing page 1/8\n",
      "    Processing page 2/8\n",
      "    Processing page 3/8\n",
      "    Processing page 4/8\n",
      "    Processing page 5/8\n",
      "    Processing page 6/8\n",
      "    Processing page 7/8\n",
      "    Processing page 8/8\n",
      "  OCR complete. Text saved to: 2507.22367.txt\n",
      "\n",
      "Processing paper 29/200: A Comprehensive Taxonomy of Negation for NLP and Neural Retrievers\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22337\n",
      "  Performing OCR on: 2507.22337.pdf\n",
      "    Processing page 1/25\n",
      "    Processing page 2/25\n",
      "    Processing page 3/25\n",
      "    Processing page 4/25\n",
      "    Processing page 5/25\n",
      "    Processing page 6/25\n",
      "    Processing page 7/25\n",
      "    Processing page 8/25\n",
      "    Processing page 9/25\n",
      "    Processing page 10/25\n",
      "    Processing page 11/25\n",
      "    Processing page 12/25\n",
      "    Processing page 13/25\n",
      "    Processing page 14/25\n",
      "    Processing page 15/25\n",
      "    Processing page 16/25\n",
      "    Processing page 17/25\n",
      "    Processing page 18/25\n",
      "    Processing page 19/25\n",
      "    Processing page 20/25\n",
      "    Processing page 21/25\n",
      "    Processing page 22/25\n",
      "    Processing page 23/25\n",
      "    Processing page 24/25\n",
      "    Processing page 25/25\n",
      "  OCR complete. Text saved to: 2507.22337.txt\n",
      "\n",
      "Processing paper 30/200: Intent Recognition and Out-of-Scope Detection using LLMs in Multi-party Conversations\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22289\n",
      "  Performing OCR on: 2507.22289.pdf\n",
      "    Processing page 1/9\n",
      "    Processing page 2/9\n",
      "    Processing page 3/9\n",
      "    Processing page 4/9\n",
      "    Processing page 5/9\n",
      "    Processing page 6/9\n",
      "    Processing page 7/9\n",
      "    Processing page 8/9\n",
      "    Processing page 9/9\n",
      "  OCR complete. Text saved to: 2507.22289.txt\n",
      "\n",
      "Processing paper 31/200: Meaning-infused grammar: Gradient Acceptability Shapes the Geometric Representations of Constructions in LLMs\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22286\n",
      "  Performing OCR on: 2507.22286.pdf\n",
      "    Processing page 1/5\n",
      "    Processing page 2/5\n",
      "    Processing page 3/5\n",
      "    Processing page 4/5\n",
      "    Processing page 5/5\n",
      "  OCR complete. Text saved to: 2507.22286.txt\n",
      "\n",
      "Processing paper 32/200: RL from Teacher-Model Refinement: Gradual Imitation Learning for Machine Translation\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22219\n",
      "  Performing OCR on: 2507.22219.pdf\n",
      "    Processing page 1/13\n",
      "    Processing page 2/13\n",
      "    Processing page 3/13\n",
      "    Processing page 4/13\n",
      "    Processing page 5/13\n",
      "    Processing page 6/13\n",
      "    Processing page 7/13\n",
      "    Processing page 8/13\n",
      "    Processing page 9/13\n",
      "    Processing page 10/13\n",
      "    Processing page 11/13\n",
      "    Processing page 12/13\n",
      "    Processing page 13/13\n",
      "  OCR complete. Text saved to: 2507.22219.txt\n",
      "\n",
      "Processing paper 33/200: How Well Does First-Token Entropy Approximate Word Entropy as a Psycholinguistic Predictor?\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22209\n",
      "  Performing OCR on: 2507.22209.pdf\n",
      "    Processing page 1/7\n",
      "    Processing page 2/7\n",
      "    Processing page 3/7\n",
      "    Processing page 4/7\n",
      "    Processing page 5/7\n",
      "    Processing page 6/7\n",
      "    Processing page 7/7\n",
      "  OCR complete. Text saved to: 2507.22209.txt\n",
      "\n",
      "Processing paper 34/200: The role of media memorability in facilitating startups' access to venture capital funding\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22201\n",
      "  Performing OCR on: 2507.22201.pdf\n",
      "    Processing page 1/75\n",
      "    Processing page 2/75\n",
      "    Processing page 3/75\n",
      "    Processing page 4/75\n",
      "    Processing page 5/75\n",
      "    Processing page 6/75\n",
      "    Processing page 7/75\n",
      "    Processing page 8/75\n",
      "    Processing page 9/75\n",
      "    Processing page 10/75\n",
      "    Processing page 11/75\n",
      "    Processing page 12/75\n",
      "    Processing page 13/75\n",
      "    Processing page 14/75\n",
      "    Processing page 15/75\n",
      "    Processing page 16/75\n",
      "    Processing page 17/75\n",
      "    Processing page 18/75\n",
      "    Processing page 19/75\n",
      "    Processing page 20/75\n",
      "    Processing page 21/75\n",
      "    Processing page 22/75\n",
      "    Processing page 23/75\n",
      "    Processing page 24/75\n",
      "    Processing page 25/75\n",
      "    Processing page 26/75\n",
      "    Processing page 27/75\n",
      "    Processing page 28/75\n",
      "    Processing page 29/75\n",
      "    Processing page 30/75\n",
      "    Processing page 31/75\n",
      "    Processing page 32/75\n",
      "    Processing page 33/75\n",
      "    Processing page 34/75\n",
      "    Processing page 35/75\n",
      "    Processing page 36/75\n",
      "    Processing page 37/75\n",
      "    Processing page 38/75\n",
      "    Processing page 39/75\n",
      "    Processing page 40/75\n",
      "    Processing page 41/75\n",
      "    Processing page 42/75\n",
      "    Processing page 43/75\n",
      "    Processing page 44/75\n",
      "    Processing page 45/75\n",
      "    Processing page 46/75\n",
      "    Processing page 47/75\n",
      "    Processing page 48/75\n",
      "    Processing page 49/75\n",
      "    Processing page 50/75\n",
      "    Processing page 51/75\n",
      "    Processing page 52/75\n",
      "    Processing page 53/75\n",
      "    Processing page 54/75\n",
      "    Processing page 55/75\n",
      "    Processing page 56/75\n",
      "    Processing page 57/75\n",
      "    Processing page 58/75\n",
      "    Processing page 59/75\n",
      "    Processing page 60/75\n",
      "    Processing page 61/75\n",
      "    Processing page 62/75\n",
      "    Processing page 63/75\n",
      "    Processing page 64/75\n",
      "    Processing page 65/75\n",
      "    Processing page 66/75\n",
      "    Processing page 67/75\n",
      "    Processing page 68/75\n",
      "    Processing page 69/75\n",
      "    Processing page 70/75\n",
      "    Processing page 71/75\n",
      "    Processing page 72/75\n",
      "    Processing page 73/75\n",
      "    Processing page 74/75\n",
      "    Processing page 75/75\n",
      "  OCR complete. Text saved to: 2507.22201.txt\n",
      "\n",
      "Processing paper 35/200: A Scalable Pipeline for Estimating Verb Frame Frequencies Using Large Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22187\n",
      "  Performing OCR on: 2507.22187.pdf\n",
      "    Processing page 1/20\n",
      "    Processing page 2/20\n",
      "    Processing page 3/20\n",
      "    Processing page 4/20\n",
      "    Processing page 5/20\n",
      "    Processing page 6/20\n",
      "    Processing page 7/20\n",
      "    Processing page 8/20\n",
      "    Processing page 9/20\n",
      "    Processing page 10/20\n",
      "    Processing page 11/20\n",
      "    Processing page 12/20\n",
      "    Processing page 13/20\n",
      "    Processing page 14/20\n",
      "    Processing page 15/20\n",
      "    Processing page 16/20\n",
      "    Processing page 17/20\n",
      "    Processing page 18/20\n",
      "    Processing page 19/20\n",
      "    Processing page 20/20\n",
      "  OCR complete. Text saved to: 2507.22187.txt\n",
      "\n",
      "Processing paper 36/200: Persona-Augmented Benchmarking: Evaluating LLMs Across Diverse Writing Styles\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22168\n",
      "  Performing OCR on: 2507.22168.pdf\n",
      "    Processing page 1/32\n",
      "    Processing page 2/32\n",
      "    Processing page 3/32\n",
      "    Processing page 4/32\n",
      "    Processing page 5/32\n",
      "    Processing page 6/32\n",
      "    Processing page 7/32\n",
      "    Processing page 8/32\n",
      "    Processing page 9/32\n",
      "    Processing page 10/32\n",
      "    Processing page 11/32\n",
      "    Processing page 12/32\n",
      "    Processing page 13/32\n",
      "    Processing page 14/32\n",
      "    Processing page 15/32\n",
      "    Processing page 16/32\n",
      "    Processing page 17/32\n",
      "    Processing page 18/32\n",
      "    Processing page 19/32\n",
      "    Processing page 20/32\n",
      "    Processing page 21/32\n",
      "    Processing page 22/32\n",
      "    Processing page 23/32\n",
      "    Processing page 24/32\n",
      "    Processing page 25/32\n",
      "    Processing page 26/32\n",
      "    Processing page 27/32\n",
      "    Processing page 28/32\n",
      "    Processing page 29/32\n",
      "    Processing page 30/32\n",
      "    Processing page 31/32\n",
      "    Processing page 32/32\n",
      "  OCR complete. Text saved to: 2507.22168.txt\n",
      "\n",
      "Processing paper 37/200: IndoPref: A Multi-Domain Pairwise Preference Dataset for Indonesian\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22159\n",
      "  Performing OCR on: 2507.22159.pdf\n",
      "    Processing page 1/9\n",
      "    Processing page 2/9\n",
      "    Processing page 3/9\n",
      "    Processing page 4/9\n",
      "    Processing page 5/9\n",
      "    Processing page 6/9\n",
      "    Processing page 7/9\n",
      "    Processing page 8/9\n",
      "    Processing page 9/9\n",
      "  OCR complete. Text saved to: 2507.22159.txt\n",
      "\n",
      "Processing paper 38/200: RecGPT Technical Report\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22879\n",
      "  Performing OCR on: 2507.22879.pdf\n",
      "    Processing page 1/42\n",
      "    Processing page 2/42\n",
      "    Processing page 3/42\n",
      "    Processing page 4/42\n",
      "    Processing page 5/42\n",
      "    Processing page 6/42\n",
      "    Processing page 7/42\n",
      "    Processing page 8/42\n",
      "    Processing page 9/42\n",
      "    Processing page 10/42\n",
      "    Processing page 11/42\n",
      "    Processing page 12/42\n",
      "    Processing page 13/42\n",
      "    Processing page 14/42\n",
      "    Processing page 15/42\n",
      "    Processing page 16/42\n",
      "    Processing page 17/42\n",
      "    Processing page 18/42\n",
      "    Processing page 19/42\n",
      "    Processing page 20/42\n",
      "    Processing page 21/42\n",
      "    Processing page 22/42\n",
      "    Processing page 23/42\n",
      "    Processing page 24/42\n",
      "    Processing page 25/42\n",
      "    Processing page 26/42\n",
      "    Processing page 27/42\n",
      "    Processing page 28/42\n",
      "    Processing page 29/42\n",
      "    Processing page 30/42\n",
      "    Processing page 31/42\n",
      "    Processing page 32/42\n",
      "    Processing page 33/42\n",
      "    Processing page 34/42\n",
      "    Processing page 35/42\n",
      "    Processing page 36/42\n",
      "    Processing page 37/42\n",
      "    Processing page 38/42\n",
      "    Processing page 39/42\n",
      "    Processing page 40/42\n",
      "    Processing page 41/42\n",
      "    Processing page 42/42\n",
      "  OCR complete. Text saved to: 2507.22879.txt\n",
      "\n",
      "Processing paper 39/200: GeoOutageKG: A Multimodal Geospatiotemporal Knowledge Graph for Multiresolution Power Outage Analysis\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22878\n",
      "  Performing OCR on: 2507.22878.pdf\n",
      "    Processing page 1/19\n",
      "    Processing page 2/19\n",
      "    Processing page 3/19\n",
      "    Processing page 4/19\n",
      "    Processing page 5/19\n",
      "    Processing page 6/19\n",
      "    Processing page 7/19\n",
      "    Processing page 8/19\n",
      "    Processing page 9/19\n",
      "    Processing page 10/19\n",
      "    Processing page 11/19\n",
      "    Processing page 12/19\n",
      "    Processing page 13/19\n",
      "    Processing page 14/19\n",
      "    Processing page 15/19\n",
      "    Processing page 16/19\n",
      "    Processing page 17/19\n",
      "    Processing page 18/19\n",
      "    Processing page 19/19\n",
      "  OCR complete. Text saved to: 2507.22878.txt\n",
      "\n",
      "Processing paper 40/200: The Incomplete Bridge: How AI Research (Mis)Engages with Psychology\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22847\n",
      "  Performing OCR on: 2507.22847.pdf\n",
      "    Processing page 1/61\n",
      "    Processing page 2/61\n",
      "    Processing page 3/61\n",
      "    Processing page 4/61\n",
      "    Processing page 5/61\n",
      "    Processing page 6/61\n",
      "    Processing page 7/61\n",
      "    Processing page 8/61\n",
      "    Processing page 9/61\n",
      "    Processing page 10/61\n",
      "    Processing page 11/61\n",
      "    Processing page 12/61\n",
      "    Processing page 13/61\n",
      "    Processing page 14/61\n",
      "    Processing page 15/61\n",
      "    Processing page 16/61\n",
      "    Processing page 17/61\n",
      "    Processing page 18/61\n",
      "    Processing page 19/61\n",
      "    Processing page 20/61\n",
      "    Processing page 21/61\n",
      "    Processing page 22/61\n",
      "    Processing page 23/61\n",
      "    Processing page 24/61\n",
      "    Processing page 25/61\n",
      "    Processing page 26/61\n",
      "    Processing page 27/61\n",
      "    Processing page 28/61\n",
      "    Processing page 29/61\n",
      "    Processing page 30/61\n",
      "    Processing page 31/61\n",
      "    Processing page 32/61\n",
      "    Processing page 33/61\n",
      "    Processing page 34/61\n",
      "    Processing page 35/61\n",
      "    Processing page 36/61\n",
      "    Processing page 37/61\n",
      "    Processing page 38/61\n",
      "    Processing page 39/61\n",
      "    Processing page 40/61\n",
      "    Processing page 41/61\n",
      "    Processing page 42/61\n",
      "    Processing page 43/61\n",
      "    Processing page 44/61\n",
      "    Processing page 45/61\n",
      "    Processing page 46/61\n",
      "    Processing page 47/61\n",
      "    Processing page 48/61\n",
      "    Processing page 49/61\n",
      "    Processing page 50/61\n",
      "    Processing page 51/61\n",
      "    Processing page 52/61\n",
      "    Processing page 53/61\n",
      "    Processing page 54/61\n",
      "    Processing page 55/61\n",
      "    Processing page 56/61\n",
      "    Processing page 57/61\n",
      "    Processing page 58/61\n",
      "    Processing page 59/61\n",
      "    Processing page 60/61\n",
      "    Processing page 61/61\n",
      "  OCR complete. Text saved to: 2507.22847.txt\n",
      "\n",
      "Processing paper 41/200: Next Tokens Denoising for Speech Synthesis\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22746\n",
      "  Performing OCR on: 2507.22746.pdf\n",
      "    Processing page 1/12\n",
      "    Processing page 2/12\n",
      "    Processing page 3/12\n",
      "    Processing page 4/12\n",
      "    Processing page 5/12\n",
      "    Processing page 6/12\n",
      "    Processing page 7/12\n",
      "    Processing page 8/12\n",
      "    Processing page 9/12\n",
      "    Processing page 10/12\n",
      "    Processing page 11/12\n",
      "    Processing page 12/12\n",
      "  OCR complete. Text saved to: 2507.22746.txt\n",
      "\n",
      "Processing paper 42/200: VL-Cogito: Progressive Curriculum Reinforcement Learning for Advanced Multimodal Reasoning\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22607\n",
      "  Performing OCR on: 2507.22607.pdf\n",
      "    Processing page 1/21\n",
      "    Processing page 2/21\n",
      "    Processing page 3/21\n",
      "    Processing page 4/21\n",
      "    Processing page 5/21\n",
      "    Processing page 6/21\n",
      "    Processing page 7/21\n",
      "    Processing page 8/21\n",
      "    Processing page 9/21\n",
      "    Processing page 10/21\n",
      "    Processing page 11/21\n",
      "    Processing page 12/21\n",
      "    Processing page 13/21\n",
      "    Processing page 14/21\n",
      "    Processing page 15/21\n",
      "    Processing page 16/21\n",
      "    Processing page 17/21\n",
      "    Processing page 18/21\n",
      "    Processing page 19/21\n",
      "    Processing page 20/21\n",
      "    Processing page 21/21\n",
      "  OCR complete. Text saved to: 2507.22607.txt\n",
      "\n",
      "Processing paper 43/200: Efficient Differentially Private Fine-Tuning of LLMs via Reinforcement Learning\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22565\n",
      "  Performing OCR on: 2507.22565.pdf\n",
      "    Processing page 1/43\n",
      "    Processing page 2/43\n",
      "    Processing page 3/43\n",
      "    Processing page 4/43\n",
      "    Processing page 5/43\n",
      "    Processing page 6/43\n",
      "    Processing page 7/43\n",
      "    Processing page 8/43\n",
      "    Processing page 9/43\n",
      "    Processing page 10/43\n",
      "    Processing page 11/43\n",
      "    Processing page 12/43\n",
      "    Processing page 13/43\n",
      "    Processing page 14/43\n",
      "    Processing page 15/43\n",
      "    Processing page 16/43\n",
      "    Processing page 17/43\n",
      "    Processing page 18/43\n",
      "    Processing page 19/43\n",
      "    Processing page 20/43\n",
      "    Processing page 21/43\n",
      "    Processing page 22/43\n",
      "    Processing page 23/43\n",
      "    Processing page 24/43\n",
      "    Processing page 25/43\n",
      "    Processing page 26/43\n",
      "    Processing page 27/43\n",
      "    Processing page 28/43\n",
      "    Processing page 29/43\n",
      "    Processing page 30/43\n",
      "    Processing page 31/43\n",
      "    Processing page 32/43\n",
      "    Processing page 33/43\n",
      "    Processing page 34/43\n",
      "    Processing page 35/43\n",
      "    Processing page 36/43\n",
      "    Processing page 37/43\n",
      "    Processing page 38/43\n",
      "    Processing page 39/43\n",
      "    Processing page 40/43\n",
      "    Processing page 41/43\n",
      "    Processing page 42/43\n",
      "    Processing page 43/43\n",
      "  OCR complete. Text saved to: 2507.22565.txt\n",
      "\n",
      "Processing paper 44/200: Pre-trained Models Perform the Best When Token Distributions Follow Zipf's Law\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22543\n",
      "  Performing OCR on: 2507.22543.pdf\n",
      "    Processing page 1/12\n",
      "    Processing page 2/12\n",
      "    Processing page 3/12\n",
      "    Processing page 4/12\n",
      "    Processing page 5/12\n",
      "    Processing page 6/12\n",
      "    Processing page 7/12\n",
      "    Processing page 8/12\n",
      "    Processing page 9/12\n",
      "    Processing page 10/12\n",
      "    Processing page 11/12\n",
      "    Processing page 12/12\n",
      "  OCR complete. Text saved to: 2507.22543.txt\n",
      "\n",
      "Processing paper 45/200: LLM-Crowdsourced: A Benchmark-Free Paradigm for Mutual Evaluation of Large Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22359\n",
      "  Performing OCR on: 2507.22359.pdf\n",
      "    Processing page 1/9\n",
      "    Processing page 2/9\n",
      "    Processing page 3/9\n",
      "    Processing page 4/9\n",
      "    Processing page 5/9\n",
      "    Processing page 6/9\n",
      "    Processing page 7/9\n",
      "    Processing page 8/9\n",
      "    Processing page 9/9\n",
      "  OCR complete. Text saved to: 2507.22359.txt\n",
      "\n",
      "Processing paper 46/200: CoEx -- Co-evolving World-model and Exploration\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22281\n",
      "  Performing OCR on: 2507.22281.pdf\n",
      "    Processing page 1/22\n",
      "    Processing page 2/22\n",
      "    Processing page 3/22\n",
      "    Processing page 4/22\n",
      "    Processing page 5/22\n",
      "    Processing page 6/22\n",
      "    Processing page 7/22\n",
      "    Processing page 8/22\n",
      "    Processing page 9/22\n",
      "    Processing page 10/22\n",
      "    Processing page 11/22\n",
      "    Processing page 12/22\n",
      "    Processing page 13/22\n",
      "    Processing page 14/22\n",
      "    Processing page 15/22\n",
      "    Processing page 16/22\n",
      "    Processing page 17/22\n",
      "    Processing page 18/22\n",
      "    Processing page 19/22\n",
      "    Processing page 20/22\n",
      "    Processing page 21/22\n",
      "    Processing page 22/22\n",
      "  OCR complete. Text saved to: 2507.22281.txt\n",
      "\n",
      "Processing paper 47/200: Explainability Through Systematicity: The Hard Systematicity Challenge for Artificial Intelligence\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22197\n",
      "  Performing OCR on: 2507.22197.pdf\n",
      "    Processing page 1/39\n",
      "    Processing page 2/39\n",
      "    Processing page 3/39\n",
      "    Processing page 4/39\n",
      "    Processing page 5/39\n",
      "    Processing page 6/39\n",
      "    Processing page 7/39\n",
      "    Processing page 8/39\n",
      "    Processing page 9/39\n",
      "    Processing page 10/39\n",
      "    Processing page 11/39\n",
      "    Processing page 12/39\n",
      "    Processing page 13/39\n",
      "    Processing page 14/39\n",
      "    Processing page 15/39\n",
      "    Processing page 16/39\n",
      "    Processing page 17/39\n",
      "    Processing page 18/39\n",
      "    Processing page 19/39\n",
      "    Processing page 20/39\n",
      "    Processing page 21/39\n",
      "    Processing page 22/39\n",
      "    Processing page 23/39\n",
      "    Processing page 24/39\n",
      "    Processing page 25/39\n",
      "    Processing page 26/39\n",
      "    Processing page 27/39\n",
      "    Processing page 28/39\n",
      "    Processing page 29/39\n",
      "    Processing page 30/39\n",
      "    Processing page 31/39\n",
      "    Processing page 32/39\n",
      "    Processing page 33/39\n",
      "    Processing page 34/39\n",
      "    Processing page 35/39\n",
      "    Processing page 36/39\n",
      "    Processing page 37/39\n",
      "    Processing page 38/39\n",
      "    Processing page 39/39\n",
      "  OCR complete. Text saved to: 2507.22197.txt\n",
      "\n",
      "Processing paper 48/200: Strategic Deflection: Defending LLMs from Logit Manipulation\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22160\n",
      "  Performing OCR on: 2507.22160.pdf\n",
      "    Processing page 1/20\n",
      "    Processing page 2/20\n",
      "    Processing page 3/20\n",
      "    Processing page 4/20\n",
      "    Processing page 5/20\n",
      "    Processing page 6/20\n",
      "    Processing page 7/20\n",
      "    Processing page 8/20\n",
      "    Processing page 9/20\n",
      "    Processing page 10/20\n",
      "    Processing page 11/20\n",
      "    Processing page 12/20\n",
      "    Processing page 13/20\n",
      "    Processing page 14/20\n",
      "    Processing page 15/20\n",
      "    Processing page 16/20\n",
      "    Processing page 17/20\n",
      "    Processing page 18/20\n",
      "    Processing page 19/20\n",
      "    Processing page 20/20\n",
      "  OCR complete. Text saved to: 2507.22160.txt\n",
      "\n",
      "Processing paper 49/200: Prompt Optimization and Evaluation for LLM Automated Red Teaming\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22133\n",
      "  Performing OCR on: 2507.22133.pdf\n",
      "    Processing page 1/9\n",
      "    Processing page 2/9\n",
      "    Processing page 3/9\n",
      "    Processing page 4/9\n",
      "    Processing page 5/9\n",
      "    Processing page 6/9\n",
      "    Processing page 7/9\n",
      "    Processing page 8/9\n",
      "    Processing page 9/9\n",
      "  OCR complete. Text saved to: 2507.22133.txt\n",
      "\n",
      "Processing paper 50/200: CodeEvo: Interaction-Driven Synthesis of Code-centric Data through Hybrid and Iterative Feedback\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22080\n",
      "  Performing OCR on: 2507.22080.pdf\n",
      "    Processing page 1/18\n",
      "    Processing page 2/18\n",
      "    Processing page 3/18\n",
      "    Processing page 4/18\n",
      "    Processing page 5/18\n",
      "    Processing page 6/18\n",
      "    Processing page 7/18\n",
      "    Processing page 8/18\n",
      "    Processing page 9/18\n",
      "    Processing page 10/18\n",
      "    Processing page 11/18\n",
      "    Processing page 12/18\n",
      "    Processing page 13/18\n",
      "    Processing page 14/18\n",
      "    Processing page 15/18\n",
      "    Processing page 16/18\n",
      "    Processing page 17/18\n",
      "    Processing page 18/18\n",
      "  OCR complete. Text saved to: 2507.22080.txt\n",
      "\n",
      "Processing paper 51/200: CIMR: Contextualized Iterative Multimodal Reasoning for Robust Instruction Following in LVLMs\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22074\n",
      "  Performing OCR on: 2507.22074.pdf\n",
      "    Processing page 1/9\n",
      "    Processing page 2/9\n",
      "    Processing page 3/9\n",
      "    Processing page 4/9\n",
      "    Processing page 5/9\n",
      "    Processing page 6/9\n",
      "    Processing page 7/9\n",
      "    Processing page 8/9\n",
      "    Processing page 9/9\n",
      "  OCR complete. Text saved to: 2507.22074.txt\n",
      "\n",
      "Processing paper 52/200: DeepSieve: Information Sieving via LLM-as-a-Knowledge-Router\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22050\n",
      "  Performing OCR on: 2507.22050.pdf\n",
      "    Processing page 1/22\n",
      "    Processing page 2/22\n",
      "    Processing page 3/22\n",
      "    Processing page 4/22\n",
      "    Processing page 5/22\n",
      "    Processing page 6/22\n",
      "    Processing page 7/22\n",
      "    Processing page 8/22\n",
      "    Processing page 9/22\n",
      "    Processing page 10/22\n",
      "    Processing page 11/22\n",
      "    Processing page 12/22\n",
      "    Processing page 13/22\n",
      "    Processing page 14/22\n",
      "    Processing page 15/22\n",
      "    Processing page 16/22\n",
      "    Processing page 17/22\n",
      "    Processing page 18/22\n",
      "    Processing page 19/22\n",
      "    Processing page 20/22\n",
      "    Processing page 21/22\n",
      "    Processing page 22/22\n",
      "  OCR complete. Text saved to: 2507.22050.txt\n",
      "\n",
      "Processing paper 53/200: Predicting Microbial Ontology and Pathogen Risk from Environmental Metadata with Large Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21980\n",
      "  Performing OCR on: 2507.21980.pdf\n",
      "    Processing page 1/13\n",
      "    Processing page 2/13\n",
      "    Processing page 3/13\n",
      "    Processing page 4/13\n",
      "    Processing page 5/13\n",
      "    Processing page 6/13\n",
      "    Processing page 7/13\n",
      "    Processing page 8/13\n",
      "    Processing page 9/13\n",
      "    Processing page 10/13\n",
      "    Processing page 11/13\n",
      "    Processing page 12/13\n",
      "    Processing page 13/13\n",
      "  OCR complete. Text saved to: 2507.21980.txt\n",
      "\n",
      "Processing paper 54/200: Culinary Crossroads: A RAG Framework for Enhancing Diversity in Cross-Cultural Recipe Adaptation\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21934\n",
      "  Performing OCR on: 2507.21934.pdf\n",
      "    Processing page 1/15\n",
      "    Processing page 2/15\n",
      "    Processing page 3/15\n",
      "    Processing page 4/15\n",
      "    Processing page 5/15\n",
      "    Processing page 6/15\n",
      "    Processing page 7/15\n",
      "    Processing page 8/15\n",
      "    Processing page 9/15\n",
      "    Processing page 10/15\n",
      "    Processing page 11/15\n",
      "    Processing page 12/15\n",
      "    Processing page 13/15\n",
      "    Processing page 14/15\n",
      "    Processing page 15/15\n",
      "  OCR complete. Text saved to: 2507.21934.txt\n",
      "\n",
      "Processing paper 55/200: Post-Training Large Language Models via Reinforcement Learning from Self-Feedback\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21931\n",
      "  Performing OCR on: 2507.21931.pdf\n",
      "    Processing page 1/16\n",
      "    Processing page 2/16\n",
      "    Processing page 3/16\n",
      "    Processing page 4/16\n",
      "    Processing page 5/16\n",
      "    Processing page 6/16\n",
      "    Processing page 7/16\n",
      "    Processing page 8/16\n",
      "    Processing page 9/16\n",
      "    Processing page 10/16\n",
      "    Processing page 11/16\n",
      "    Processing page 12/16\n",
      "    Processing page 13/16\n",
      "    Processing page 14/16\n",
      "    Processing page 15/16\n",
      "    Processing page 16/16\n",
      "  OCR complete. Text saved to: 2507.21931.txt\n",
      "\n",
      "Processing paper 56/200: Training language models to be warm and empathetic makes them less reliable and more sycophantic\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21919\n",
      "  Performing OCR on: 2507.21919.pdf\n",
      "    Processing page 1/27\n",
      "    Processing page 2/27\n",
      "    Processing page 3/27\n",
      "    Processing page 4/27\n",
      "    Processing page 5/27\n",
      "    Processing page 6/27\n",
      "    Processing page 7/27\n",
      "    Processing page 8/27\n",
      "    Processing page 9/27\n",
      "    Processing page 10/27\n",
      "    Processing page 11/27\n",
      "    Processing page 12/27\n",
      "    Processing page 13/27\n",
      "    Processing page 14/27\n",
      "    Processing page 15/27\n",
      "    Processing page 16/27\n",
      "    Processing page 17/27\n",
      "    Processing page 18/27\n",
      "    Processing page 19/27\n",
      "    Processing page 20/27\n",
      "    Processing page 21/27\n",
      "    Processing page 22/27\n",
      "    Processing page 23/27\n",
      "    Processing page 24/27\n",
      "    Processing page 25/27\n",
      "    Processing page 26/27\n",
      "    Processing page 27/27\n",
      "  OCR complete. Text saved to: 2507.21919.txt\n",
      "\n",
      "Processing paper 57/200: Rote Learning Considered Useful: Generalizing over Memorized Data in LLMs\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21914\n",
      "  Performing OCR on: 2507.21914.pdf\n",
      "    Processing page 1/35\n",
      "    Processing page 2/35\n",
      "    Processing page 3/35\n",
      "    Processing page 4/35\n",
      "    Processing page 5/35\n",
      "    Processing page 6/35\n",
      "    Processing page 7/35\n",
      "    Processing page 8/35\n",
      "    Processing page 9/35\n",
      "    Processing page 10/35\n",
      "    Processing page 11/35\n",
      "    Processing page 12/35\n",
      "    Processing page 13/35\n",
      "    Processing page 14/35\n",
      "    Processing page 15/35\n",
      "    Processing page 16/35\n",
      "    Processing page 17/35\n",
      "    Processing page 18/35\n",
      "    Processing page 19/35\n",
      "    Processing page 20/35\n",
      "    Processing page 21/35\n",
      "    Processing page 22/35\n",
      "    Processing page 23/35\n",
      "    Processing page 24/35\n",
      "    Processing page 25/35\n",
      "    Processing page 26/35\n",
      "    Processing page 27/35\n",
      "    Processing page 28/35\n",
      "    Processing page 29/35\n",
      "    Processing page 30/35\n",
      "    Processing page 31/35\n",
      "    Processing page 32/35\n",
      "    Processing page 33/35\n",
      "    Processing page 34/35\n",
      "    Processing page 35/35\n",
      "  OCR complete. Text saved to: 2507.21914.txt\n",
      "\n",
      "Processing paper 58/200: Graph-R1: Towards Agentic GraphRAG Framework via End-to-end Reinforcement Learning\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21892\n",
      "  Performing OCR on: 2507.21892.pdf\n",
      "    Processing page 1/20\n",
      "    Processing page 2/20\n",
      "    Processing page 3/20\n",
      "    Processing page 4/20\n",
      "    Processing page 5/20\n",
      "    Processing page 6/20\n",
      "    Processing page 7/20\n",
      "    Processing page 8/20\n",
      "    Processing page 9/20\n",
      "    Processing page 10/20\n",
      "    Processing page 11/20\n",
      "    Processing page 12/20\n",
      "    Processing page 13/20\n",
      "    Processing page 14/20\n",
      "    Processing page 15/20\n",
      "    Processing page 16/20\n",
      "    Processing page 17/20\n",
      "    Processing page 18/20\n",
      "    Processing page 19/20\n",
      "    Processing page 20/20\n",
      "  OCR complete. Text saved to: 2507.21892.txt\n",
      "\n",
      "Processing paper 59/200: AutoTIR: Autonomous Tools Integrated Reasoning via Reinforcement Learning\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21836\n",
      "  Performing OCR on: 2507.21836.pdf\n",
      "    Processing page 1/13\n",
      "    Processing page 2/13\n",
      "    Processing page 3/13\n",
      "    Processing page 4/13\n",
      "    Processing page 5/13\n",
      "    Processing page 6/13\n",
      "    Processing page 7/13\n",
      "    Processing page 8/13\n",
      "    Processing page 9/13\n",
      "    Processing page 10/13\n",
      "    Processing page 11/13\n",
      "    Processing page 12/13\n",
      "    Processing page 13/13\n",
      "  OCR complete. Text saved to: 2507.21836.txt\n",
      "\n",
      "Processing paper 60/200: Introducing HALC: A general pipeline for finding optimal prompting strategies for automated coding with LLMs in the computational social sciences\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21831\n",
      "  Performing OCR on: 2507.21831.pdf\n",
      "    Processing page 1/48\n",
      "    Processing page 2/48\n",
      "    Processing page 3/48\n",
      "    Processing page 4/48\n",
      "    Processing page 5/48\n",
      "    Processing page 6/48\n",
      "    Processing page 7/48\n",
      "    Processing page 8/48\n",
      "    Processing page 9/48\n",
      "    Processing page 10/48\n",
      "    Processing page 11/48\n",
      "    Processing page 12/48\n",
      "    Processing page 13/48\n",
      "    Processing page 14/48\n",
      "    Processing page 15/48\n",
      "    Processing page 16/48\n",
      "    Processing page 17/48\n",
      "    Processing page 18/48\n",
      "    Processing page 19/48\n",
      "    Processing page 20/48\n",
      "    Processing page 21/48\n",
      "    Processing page 22/48\n",
      "    Processing page 23/48\n",
      "    Processing page 24/48\n",
      "    Processing page 25/48\n",
      "    Processing page 26/48\n",
      "    Processing page 27/48\n",
      "    Processing page 28/48\n",
      "    Processing page 29/48\n",
      "    Processing page 30/48\n",
      "    Processing page 31/48\n",
      "    Processing page 32/48\n",
      "    Processing page 33/48\n",
      "    Processing page 34/48\n",
      "    Processing page 35/48\n",
      "    Processing page 36/48\n",
      "    Processing page 37/48\n",
      "    Processing page 38/48\n",
      "    Processing page 39/48\n",
      "    Processing page 40/48\n",
      "    Processing page 41/48\n",
      "    Processing page 42/48\n",
      "    Processing page 43/48\n",
      "    Processing page 44/48\n",
      "    Processing page 45/48\n",
      "    Processing page 46/48\n",
      "    Processing page 47/48\n",
      "    Processing page 48/48\n",
      "  OCR complete. Text saved to: 2507.21831.txt\n",
      "\n",
      "Processing paper 61/200: Modelling Adjectival Modification Effects on Semantic Plausibility\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21828\n",
      "  Performing OCR on: 2507.21828.pdf\n",
      "    Processing page 1/11\n",
      "    Processing page 2/11\n",
      "    Processing page 3/11\n",
      "    Processing page 4/11\n",
      "    Processing page 5/11\n",
      "    Processing page 6/11\n",
      "    Processing page 7/11\n",
      "    Processing page 8/11\n",
      "    Processing page 9/11\n",
      "    Processing page 10/11\n",
      "    Processing page 11/11\n",
      "  OCR complete. Text saved to: 2507.21828.txt\n",
      "\n",
      "Processing paper 62/200: HRIPBench: Benchmarking LLMs in Harm Reduction Information Provision to Support People Who Use Drugs\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21815\n",
      "  Performing OCR on: 2507.21815.pdf\n",
      "    Processing page 1/14\n",
      "    Processing page 2/14\n",
      "    Processing page 3/14\n",
      "    Processing page 4/14\n",
      "    Processing page 5/14\n",
      "    Processing page 6/14\n",
      "    Processing page 7/14\n",
      "    Processing page 8/14\n",
      "    Processing page 9/14\n",
      "    Processing page 10/14\n",
      "    Processing page 11/14\n",
      "    Processing page 12/14\n",
      "    Processing page 13/14\n",
      "    Processing page 14/14\n",
      "  OCR complete. Text saved to: 2507.21815.txt\n",
      "\n",
      "Processing paper 63/200: Overview of ADoBo at IberLEF 2025: Automatic Detection of Anglicisms in Spanish\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21813\n",
      "  Performing OCR on: 2507.21813.pdf\n",
      "    Processing page 1/11\n",
      "    Processing page 2/11\n",
      "    Processing page 3/11\n",
      "    Processing page 4/11\n",
      "    Processing page 5/11\n",
      "    Processing page 6/11\n",
      "    Processing page 7/11\n",
      "    Processing page 8/11\n",
      "    Processing page 9/11\n",
      "    Processing page 10/11\n",
      "    Processing page 11/11\n",
      "  OCR complete. Text saved to: 2507.21813.txt\n",
      "\n",
      "Processing paper 64/200: ChartMark: A Structured Grammar for Chart Annotation\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21810\n",
      "  Performing OCR on: 2507.21810.pdf\n",
      "    Processing page 1/5\n",
      "    Processing page 2/5\n",
      "    Processing page 3/5\n",
      "    Processing page 4/5\n",
      "    Processing page 5/5\n",
      "  OCR complete. Text saved to: 2507.21810.txt\n",
      "\n",
      "Processing paper 65/200: The Problem with Safety Classification is not just the Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21782\n",
      "  Performing OCR on: 2507.21782.pdf\n",
      "    Processing page 1/8\n",
      "    Processing page 2/8\n",
      "    Processing page 3/8\n",
      "    Processing page 4/8\n",
      "    Processing page 5/8\n",
      "    Processing page 6/8\n",
      "    Processing page 7/8\n",
      "    Processing page 8/8\n",
      "  OCR complete. Text saved to: 2507.21782.txt\n",
      "\n",
      "Processing paper 66/200: AgriEval: A Comprehensive Chinese Agricultural Benchmark for Large Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21773\n",
      "  Performing OCR on: 2507.21773.pdf\n",
      "    Processing page 1/36\n",
      "    Processing page 2/36\n",
      "    Processing page 3/36\n",
      "    Processing page 4/36\n",
      "    Processing page 5/36\n",
      "    Processing page 6/36\n",
      "    Processing page 7/36\n",
      "    Processing page 8/36\n",
      "    Processing page 9/36\n",
      "    Processing page 10/36\n",
      "    Processing page 11/36\n",
      "    Processing page 12/36\n",
      "    Processing page 13/36\n",
      "    Processing page 14/36\n",
      "    Processing page 15/36\n",
      "    Processing page 16/36\n",
      "    Processing page 17/36\n",
      "    Processing page 18/36\n",
      "    Processing page 19/36\n",
      "    Processing page 20/36\n",
      "    Processing page 21/36\n",
      "    Processing page 22/36\n",
      "    Processing page 23/36\n",
      "    Processing page 24/36\n",
      "    Processing page 25/36\n",
      "    Processing page 26/36\n",
      "    Processing page 27/36\n",
      "    Processing page 28/36\n",
      "    Processing page 29/36\n",
      "    Processing page 30/36\n",
      "    Processing page 31/36\n",
      "    Processing page 32/36\n",
      "    Processing page 33/36\n",
      "    Processing page 34/36\n",
      "    Processing page 35/36\n",
      "    Processing page 36/36\n",
      "  OCR complete. Text saved to: 2507.21773.txt\n",
      "\n",
      "Processing paper 67/200: Adversarial Defence without Adversarial Defence: Enhancing Language Model Robustness via Instance-level Principal Component Removal\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21750\n",
      "  Performing OCR on: 2507.21750.pdf\n",
      "    Processing page 1/27\n",
      "    Processing page 2/27\n",
      "    Processing page 3/27\n",
      "    Processing page 4/27\n",
      "    Processing page 5/27\n",
      "    Processing page 6/27\n",
      "    Processing page 7/27\n",
      "    Processing page 8/27\n",
      "    Processing page 9/27\n",
      "    Processing page 10/27\n",
      "    Processing page 11/27\n",
      "    Processing page 12/27\n",
      "    Processing page 13/27\n",
      "    Processing page 14/27\n",
      "    Processing page 15/27\n",
      "    Processing page 16/27\n",
      "    Processing page 17/27\n",
      "    Processing page 18/27\n",
      "    Processing page 19/27\n",
      "    Processing page 20/27\n",
      "    Processing page 21/27\n",
      "    Processing page 22/27\n",
      "    Processing page 23/27\n",
      "    Processing page 24/27\n",
      "    Processing page 25/27\n",
      "    Processing page 26/27\n",
      "    Processing page 27/27\n",
      "  OCR complete. Text saved to: 2507.21750.txt\n",
      "\n",
      "Processing paper 68/200: UnsafeChain: Enhancing Reasoning Model Safety via Hard Cases\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21652\n",
      "  Performing OCR on: 2507.21652.pdf\n",
      "    Processing page 1/14\n",
      "    Processing page 2/14\n",
      "    Processing page 3/14\n",
      "    Processing page 4/14\n",
      "    Processing page 5/14\n",
      "    Processing page 6/14\n",
      "    Processing page 7/14\n",
      "    Processing page 8/14\n",
      "    Processing page 9/14\n",
      "    Processing page 10/14\n",
      "    Processing page 11/14\n",
      "    Processing page 12/14\n",
      "    Processing page 13/14\n",
      "    Processing page 14/14\n",
      "  OCR complete. Text saved to: 2507.21652.txt\n",
      "\n",
      "Processing paper 69/200: Libra: Assessing and Improving Reward Model by Learning to Think\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21645\n",
      "  Performing OCR on: 2507.21645.pdf\n",
      "    Processing page 1/28\n",
      "    Processing page 2/28\n",
      "    Processing page 3/28\n",
      "    Processing page 4/28\n",
      "    Processing page 5/28\n",
      "    Processing page 6/28\n",
      "    Processing page 7/28\n",
      "    Processing page 8/28\n",
      "    Processing page 9/28\n",
      "    Processing page 10/28\n",
      "    Processing page 11/28\n",
      "    Processing page 12/28\n",
      "    Processing page 13/28\n",
      "    Processing page 14/28\n",
      "    Processing page 15/28\n",
      "    Processing page 16/28\n",
      "    Processing page 17/28\n",
      "    Processing page 18/28\n",
      "    Processing page 19/28\n",
      "    Processing page 20/28\n",
      "    Processing page 21/28\n",
      "    Processing page 22/28\n",
      "    Processing page 23/28\n",
      "    Processing page 24/28\n",
      "    Processing page 25/28\n",
      "    Processing page 26/28\n",
      "    Processing page 27/28\n",
      "    Processing page 28/28\n",
      "  OCR complete. Text saved to: 2507.21645.txt\n",
      "\n",
      "Processing paper 70/200: Multilingual JobBERT for Cross-Lingual Job Title Matching\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21609\n",
      "  Performing OCR on: 2507.21609.pdf\n",
      "    Processing page 1/10\n",
      "    Processing page 2/10\n",
      "    Processing page 3/10\n",
      "    Processing page 4/10\n",
      "    Processing page 5/10\n",
      "    Processing page 6/10\n",
      "    Processing page 7/10\n",
      "    Processing page 8/10\n",
      "    Processing page 9/10\n",
      "    Processing page 10/10\n",
      "  OCR complete. Text saved to: 2507.21609.txt\n",
      "\n",
      "Processing paper 71/200: Multi-Hypothesis Distillation of Multilingual Neural Translation Models for Low-Resource Languages\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21568\n",
      "  Performing OCR on: 2507.21568.pdf\n",
      "    Processing page 1/29\n",
      "    Processing page 2/29\n",
      "    Processing page 3/29\n",
      "    Processing page 4/29\n",
      "    Processing page 5/29\n",
      "    Processing page 6/29\n",
      "    Processing page 7/29\n",
      "    Processing page 8/29\n",
      "    Processing page 9/29\n",
      "    Processing page 10/29\n",
      "    Processing page 11/29\n",
      "    Processing page 12/29\n",
      "    Processing page 13/29\n",
      "    Processing page 14/29\n",
      "    Processing page 15/29\n",
      "    Processing page 16/29\n",
      "    Processing page 17/29\n",
      "    Processing page 18/29\n",
      "    Processing page 19/29\n",
      "    Processing page 20/29\n",
      "    Processing page 21/29\n",
      "    Processing page 22/29\n",
      "    Processing page 23/29\n",
      "    Processing page 24/29\n",
      "    Processing page 25/29\n",
      "    Processing page 26/29\n",
      "    Processing page 27/29\n",
      "    Processing page 28/29\n",
      "    Processing page 29/29\n",
      "  OCR complete. Text saved to: 2507.21568.txt\n",
      "\n",
      "Processing paper 72/200: Evaluating the cognitive reality of Spanish irregular morphomic patterns: Humans vs. Transformers\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21556\n",
      "  Performing OCR on: 2507.21556.pdf\n",
      "    Processing page 1/12\n",
      "    Processing page 2/12\n",
      "    Processing page 3/12\n",
      "    Processing page 4/12\n",
      "    Processing page 5/12\n",
      "    Processing page 6/12\n",
      "    Processing page 7/12\n",
      "    Processing page 8/12\n",
      "    Processing page 9/12\n",
      "    Processing page 10/12\n",
      "    Processing page 11/12\n",
      "    Processing page 12/12\n",
      "  OCR complete. Text saved to: 2507.21556.txt\n",
      "\n",
      "Processing paper 73/200: MAGIC: A Multi-Hop and Graph-Based Benchmark for Inter-Context Conflicts in Retrieval-Augmented Generation\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21544\n",
      "  Performing OCR on: 2507.21544.pdf\n",
      "    Processing page 1/19\n",
      "    Processing page 2/19\n",
      "    Processing page 3/19\n",
      "    Processing page 4/19\n",
      "    Processing page 5/19\n",
      "    Processing page 6/19\n",
      "    Processing page 7/19\n",
      "    Processing page 8/19\n",
      "    Processing page 9/19\n",
      "    Processing page 10/19\n",
      "    Processing page 11/19\n",
      "    Processing page 12/19\n",
      "    Processing page 13/19\n",
      "    Processing page 14/19\n",
      "    Processing page 15/19\n",
      "    Processing page 16/19\n",
      "    Processing page 17/19\n",
      "    Processing page 18/19\n",
      "    Processing page 19/19\n",
      "  OCR complete. Text saved to: 2507.21544.txt\n",
      "\n",
      "Processing paper 74/200: Modern Uyghur Dependency Treebank (MUDT): An Integrated Morphosyntactic Framework for a Low-Resource Language\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21536\n",
      "  Performing OCR on: 2507.21536.pdf\n",
      "    Processing page 1/15\n",
      "    Processing page 2/15\n",
      "    Processing page 3/15\n",
      "    Processing page 4/15\n",
      "    Processing page 5/15\n",
      "    Processing page 6/15\n",
      "    Processing page 7/15\n",
      "    Processing page 8/15\n",
      "    Processing page 9/15\n",
      "    Processing page 10/15\n",
      "    Processing page 11/15\n",
      "    Processing page 12/15\n",
      "    Processing page 13/15\n",
      "    Processing page 14/15\n",
      "    Processing page 15/15\n",
      "  OCR complete. Text saved to: 2507.21536.txt\n",
      "\n",
      "Processing paper 75/200: Automatic Classification of User Requirements from Online Feedback -- A Replication Study\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21532\n",
      "  Performing OCR on: 2507.21532.pdf\n",
      "    Processing page 1/10\n",
      "    Processing page 2/10\n",
      "    Processing page 3/10\n",
      "    Processing page 4/10\n",
      "    Processing page 5/10\n",
      "    Processing page 6/10\n",
      "    Processing page 7/10\n",
      "    Processing page 8/10\n",
      "    Processing page 9/10\n",
      "    Processing page 10/10\n",
      "  OCR complete. Text saved to: 2507.21532.txt\n",
      "\n",
      "Processing paper 76/200: TriangleMix: A Lossless and Efficient Attention Pattern for Long Context Prefilling\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21526\n",
      "  Performing OCR on: 2507.21526.pdf\n",
      "    Processing page 1/13\n",
      "    Processing page 2/13\n",
      "    Processing page 3/13\n",
      "    Processing page 4/13\n",
      "    Processing page 5/13\n",
      "    Processing page 6/13\n",
      "    Processing page 7/13\n",
      "    Processing page 8/13\n",
      "    Processing page 9/13\n",
      "    Processing page 10/13\n",
      "    Processing page 11/13\n",
      "    Processing page 12/13\n",
      "    Processing page 13/13\n",
      "  OCR complete. Text saved to: 2507.21526.txt\n",
      "\n",
      "Processing paper 77/200: Model-free Speculative Decoding for Transformer-based ASR with Token Map Drafting\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21522\n",
      "  Performing OCR on: 2507.21522.pdf\n",
      "    Processing page 1/5\n",
      "    Processing page 2/5\n",
      "    Processing page 3/5\n",
      "    Processing page 4/5\n",
      "    Processing page 5/5\n",
      "  OCR complete. Text saved to: 2507.21522.txt\n",
      "\n",
      "Processing paper 78/200: Persona Vectors: Monitoring and Controlling Character Traits in Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21509\n",
      "  Performing OCR on: 2507.21509.pdf\n",
      "    Processing page 1/60\n",
      "    Processing page 2/60\n",
      "    Processing page 3/60\n",
      "    Processing page 4/60\n",
      "    Processing page 5/60\n",
      "    Processing page 6/60\n",
      "    Processing page 7/60\n",
      "    Processing page 8/60\n",
      "    Processing page 9/60\n",
      "    Processing page 10/60\n",
      "    Processing page 11/60\n",
      "    Processing page 12/60\n",
      "    Processing page 13/60\n",
      "    Processing page 14/60\n",
      "    Processing page 15/60\n",
      "    Processing page 16/60\n",
      "    Processing page 17/60\n",
      "    Processing page 18/60\n",
      "    Processing page 19/60\n",
      "    Processing page 20/60\n",
      "    Processing page 21/60\n",
      "    Processing page 22/60\n",
      "    Processing page 23/60\n",
      "    Processing page 24/60\n",
      "    Processing page 25/60\n",
      "    Processing page 26/60\n",
      "    Processing page 27/60\n",
      "    Processing page 28/60\n",
      "    Processing page 29/60\n",
      "    Processing page 30/60\n",
      "    Processing page 31/60\n",
      "    Processing page 32/60\n",
      "    Processing page 33/60\n",
      "    Processing page 34/60\n",
      "    Processing page 35/60\n",
      "    Processing page 36/60\n",
      "    Processing page 37/60\n",
      "    Processing page 38/60\n",
      "    Processing page 39/60\n",
      "    Processing page 40/60\n",
      "    Processing page 41/60\n",
      "    Processing page 42/60\n",
      "    Processing page 43/60\n",
      "    Processing page 44/60\n",
      "    Processing page 45/60\n",
      "    Processing page 46/60\n",
      "    Processing page 47/60\n",
      "    Processing page 48/60\n",
      "    Processing page 49/60\n",
      "    Processing page 50/60\n",
      "    Processing page 51/60\n",
      "    Processing page 52/60\n",
      "    Processing page 53/60\n",
      "    Processing page 54/60\n",
      "    Processing page 55/60\n",
      "    Processing page 56/60\n",
      "    Processing page 57/60\n",
      "    Processing page 58/60\n",
      "    Processing page 59/60\n",
      "    Processing page 60/60\n",
      "  OCR complete. Text saved to: 2507.21509.txt\n",
      "\n",
      "Processing paper 79/200: VN-MTEB: Vietnamese Massive Text Embedding Benchmark\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21500\n",
      "  Performing OCR on: 2507.21500.pdf\n",
      "    Processing page 1/19\n",
      "    Processing page 2/19\n",
      "    Processing page 3/19\n",
      "    Processing page 4/19\n",
      "    Processing page 5/19\n",
      "    Processing page 6/19\n",
      "    Processing page 7/19\n",
      "    Processing page 8/19\n",
      "    Processing page 9/19\n",
      "    Processing page 10/19\n",
      "    Processing page 11/19\n",
      "    Processing page 12/19\n",
      "    Processing page 13/19\n",
      "    Processing page 14/19\n",
      "    Processing page 15/19\n",
      "    Processing page 16/19\n",
      "    Processing page 17/19\n",
      "    Processing page 18/19\n",
      "    Processing page 19/19\n",
      "  OCR complete. Text saved to: 2507.21500.txt\n",
      "\n",
      "Processing paper 80/200: Improving Task Diversity in Label Efficient Supervised Finetuning of LLMs\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21482\n",
      "  Performing OCR on: 2507.21482.pdf\n",
      "    Processing page 1/13\n",
      "    Processing page 2/13\n",
      "    Processing page 3/13\n",
      "    Processing page 4/13\n",
      "    Processing page 5/13\n",
      "    Processing page 6/13\n",
      "    Processing page 7/13\n",
      "    Processing page 8/13\n",
      "    Processing page 9/13\n",
      "    Processing page 10/13\n",
      "    Processing page 11/13\n",
      "    Processing page 12/13\n",
      "    Processing page 13/13\n",
      "  OCR complete. Text saved to: 2507.21482.txt\n",
      "\n",
      "Processing paper 81/200: Which LLMs Get the Joke? Probing Non-STEM Reasoning Abilities with HumorBench\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21476\n",
      "  Performing OCR on: 2507.21476.pdf\n",
      "    Processing page 1/14\n",
      "    Processing page 2/14\n",
      "    Processing page 3/14\n",
      "    Processing page 4/14\n",
      "    Processing page 5/14\n",
      "    Processing page 6/14\n",
      "    Processing page 7/14\n",
      "    Processing page 8/14\n",
      "    Processing page 9/14\n",
      "    Processing page 10/14\n",
      "    Processing page 11/14\n",
      "    Processing page 12/14\n",
      "    Processing page 13/14\n",
      "    Processing page 14/14\n",
      "  OCR complete. Text saved to: 2507.21476.txt\n",
      "\n",
      "Processing paper 82/200: Towards Locally Deployable Fine-Tuned Causal Large Language Models for Mode Choice Behaviour\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21432\n",
      "  Performing OCR on: 2507.21432.pdf\n",
      "    Processing page 1/34\n",
      "    Processing page 2/34\n",
      "    Processing page 3/34\n",
      "    Processing page 4/34\n",
      "    Processing page 5/34\n",
      "    Processing page 6/34\n",
      "    Processing page 7/34\n",
      "    Processing page 8/34\n",
      "    Processing page 9/34\n",
      "    Processing page 10/34\n",
      "    Processing page 11/34\n",
      "    Processing page 12/34\n",
      "    Processing page 13/34\n",
      "    Processing page 14/34\n",
      "    Processing page 15/34\n",
      "    Processing page 16/34\n",
      "    Processing page 17/34\n",
      "    Processing page 18/34\n",
      "    Processing page 19/34\n",
      "    Processing page 20/34\n",
      "    Processing page 21/34\n",
      "    Processing page 22/34\n",
      "    Processing page 23/34\n",
      "    Processing page 24/34\n",
      "    Processing page 25/34\n",
      "    Processing page 26/34\n",
      "    Processing page 27/34\n",
      "    Processing page 28/34\n",
      "    Processing page 29/34\n",
      "    Processing page 30/34\n",
      "    Processing page 31/34\n",
      "    Processing page 32/34\n",
      "    Processing page 33/34\n",
      "    Processing page 34/34\n",
      "  OCR complete. Text saved to: 2507.21432.txt\n",
      "\n",
      "Processing paper 83/200: MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21428\n",
      "  Performing OCR on: 2507.21428.pdf\n",
      "    Processing page 1/23\n",
      "    Processing page 2/23\n",
      "    Processing page 3/23\n",
      "    Processing page 4/23\n",
      "    Processing page 5/23\n",
      "    Processing page 6/23\n",
      "    Processing page 7/23\n",
      "    Processing page 8/23\n",
      "    Processing page 9/23\n",
      "    Processing page 10/23\n",
      "    Processing page 11/23\n",
      "    Processing page 12/23\n",
      "    Processing page 13/23\n",
      "    Processing page 14/23\n",
      "    Processing page 15/23\n",
      "    Processing page 16/23\n",
      "    Processing page 17/23\n",
      "    Processing page 18/23\n",
      "    Processing page 19/23\n",
      "    Processing page 20/23\n",
      "    Processing page 21/23\n",
      "    Processing page 22/23\n",
      "    Processing page 23/23\n",
      "  OCR complete. Text saved to: 2507.21428.txt\n",
      "\n",
      "Processing paper 84/200: Turbocharging Web Automation: The Impact of Compressed History States\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21369\n",
      "  Performing OCR on: 2507.21369.pdf\n",
      "    Processing page 1/8\n",
      "    Processing page 2/8\n",
      "    Processing page 3/8\n",
      "    Processing page 4/8\n",
      "    Processing page 5/8\n",
      "    Processing page 6/8\n",
      "    Processing page 7/8\n",
      "    Processing page 8/8\n",
      "  OCR complete. Text saved to: 2507.21369.txt\n",
      "\n",
      "Processing paper 85/200: StructText: A Synthetic Table-to-Text Approach for Benchmark Generation with Multi-Dimensional Evaluation\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21340\n",
      "  Performing OCR on: 2507.21340.pdf\n",
      "    Processing page 1/11\n",
      "    Processing page 2/11\n",
      "    Processing page 3/11\n",
      "    Processing page 4/11\n",
      "    Processing page 5/11\n",
      "    Processing page 6/11\n",
      "    Processing page 7/11\n",
      "    Processing page 8/11\n",
      "    Processing page 9/11\n",
      "    Processing page 10/11\n",
      "    Processing page 11/11\n",
      "  OCR complete. Text saved to: 2507.21340.txt\n",
      "\n",
      "Processing paper 86/200: A Deep Learning Automatic Speech Recognition Model for Shona Language\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21331\n",
      "  Performing OCR on: 2507.21331.pdf\n",
      "    Processing page 1/9\n",
      "    Processing page 2/9\n",
      "    Processing page 3/9\n",
      "    Processing page 4/9\n",
      "    Processing page 5/9\n",
      "    Processing page 6/9\n",
      "    Processing page 7/9\n",
      "    Processing page 8/9\n",
      "    Processing page 9/9\n",
      "  OCR complete. Text saved to: 2507.21331.txt\n",
      "\n",
      "Processing paper 87/200: Do Large Language Models Understand Morality Across Cultures?\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21319\n",
      "  Performing OCR on: 2507.21319.pdf\n",
      "    Processing page 1/10\n",
      "    Processing page 2/10\n",
      "    Processing page 3/10\n",
      "    Processing page 4/10\n",
      "    Processing page 5/10\n",
      "    Processing page 6/10\n",
      "    Processing page 7/10\n",
      "    Processing page 8/10\n",
      "    Processing page 9/10\n",
      "    Processing page 10/10\n",
      "  OCR complete. Text saved to: 2507.21319.txt\n",
      "\n",
      "Processing paper 88/200: Can human clinical rationales improve the performance and explainability of clinical text classification models?\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21302\n",
      "  Performing OCR on: 2507.21302.pdf\n",
      "    Processing page 1/26\n",
      "    Processing page 2/26\n",
      "    Processing page 3/26\n",
      "    Processing page 4/26\n",
      "    Processing page 5/26\n",
      "    Processing page 6/26\n",
      "    Processing page 7/26\n",
      "    Processing page 8/26\n",
      "    Processing page 9/26\n",
      "    Processing page 10/26\n",
      "    Processing page 11/26\n",
      "    Processing page 12/26\n",
      "    Processing page 13/26\n",
      "    Processing page 14/26\n",
      "    Processing page 15/26\n",
      "    Processing page 16/26\n",
      "    Processing page 17/26\n",
      "    Processing page 18/26\n",
      "    Processing page 19/26\n",
      "    Processing page 20/26\n",
      "    Processing page 21/26\n",
      "    Processing page 22/26\n",
      "    Processing page 23/26\n",
      "    Processing page 24/26\n",
      "    Processing page 25/26\n",
      "    Processing page 26/26\n",
      "  OCR complete. Text saved to: 2507.21302.txt\n",
      "\n",
      "Processing paper 89/200: Bangla BERT for Hyperpartisan News Detection: A Semi-Supervised and Explainable AI Approach\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21242\n",
      "  Performing OCR on: 2507.21242.pdf\n",
      "    Processing page 1/6\n",
      "    Processing page 2/6\n",
      "    Processing page 3/6\n",
      "    Processing page 4/6\n",
      "    Processing page 5/6\n",
      "    Processing page 6/6\n",
      "  OCR complete. Text saved to: 2507.21242.txt\n",
      "\n",
      "Processing paper 90/200: Understanding Public Perception of Crime in Bangladesh: A Transformer-Based Approach with Explainability\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21234\n",
      "  Performing OCR on: 2507.21234.pdf\n",
      "    Processing page 1/6\n",
      "    Processing page 2/6\n",
      "    Processing page 3/6\n",
      "    Processing page 4/6\n",
      "    Processing page 5/6\n",
      "    Processing page 6/6\n",
      "  OCR complete. Text saved to: 2507.21234.txt\n",
      "\n",
      "Processing paper 91/200: Contrast-CAT: Contrasting Activations for Enhanced Interpretability in Transformer-based Text Classifiers\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21186\n",
      "  Performing OCR on: 2507.21186.pdf\n",
      "    Processing page 1/20\n",
      "    Processing page 2/20\n",
      "    Processing page 3/20\n",
      "    Processing page 4/20\n",
      "    Processing page 5/20\n",
      "    Processing page 6/20\n",
      "    Processing page 7/20\n",
      "    Processing page 8/20\n",
      "    Processing page 9/20\n",
      "    Processing page 10/20\n",
      "    Processing page 11/20\n",
      "    Processing page 12/20\n",
      "    Processing page 13/20\n",
      "    Processing page 14/20\n",
      "    Processing page 15/20\n",
      "    Processing page 16/20\n",
      "    Processing page 17/20\n",
      "    Processing page 18/20\n",
      "    Processing page 19/20\n",
      "    Processing page 20/20\n",
      "  OCR complete. Text saved to: 2507.21186.txt\n",
      "\n",
      "Processing paper 92/200: Diverse LLMs or Diverse Question Interpretations? That is the Ensembling Question\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21168\n",
      "  Performing OCR on: 2507.21168.pdf\n",
      "    Processing page 1/11\n",
      "    Processing page 2/11\n",
      "    Processing page 3/11\n",
      "    Processing page 4/11\n",
      "    Processing page 5/11\n",
      "    Processing page 6/11\n",
      "    Processing page 7/11\n",
      "    Processing page 8/11\n",
      "    Processing page 9/11\n",
      "    Processing page 10/11\n",
      "    Processing page 11/11\n",
      "  OCR complete. Text saved to: 2507.21168.txt\n",
      "\n",
      "Processing paper 93/200: TTS-1 Technical Report\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21138\n",
      "  Performing OCR on: 2507.21138.pdf\n",
      "    Processing page 1/20\n",
      "    Processing page 2/20\n",
      "    Processing page 3/20\n",
      "    Processing page 4/20\n",
      "    Processing page 5/20\n",
      "    Processing page 6/20\n",
      "    Processing page 7/20\n",
      "    Processing page 8/20\n",
      "    Processing page 9/20\n",
      "    Processing page 10/20\n",
      "    Processing page 11/20\n",
      "    Processing page 12/20\n",
      "    Processing page 13/20\n",
      "    Processing page 14/20\n",
      "    Processing page 15/20\n",
      "    Processing page 16/20\n",
      "    Processing page 17/20\n",
      "    Processing page 18/20\n",
      "    Processing page 19/20\n",
      "    Processing page 20/20\n",
      "  OCR complete. Text saved to: 2507.21138.txt\n",
      "\n",
      "Processing paper 94/200: TRIDENT: Benchmarking LLM Safety in Finance, Medicine, and Law\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21134\n",
      "  Performing OCR on: 2507.21134.pdf\n",
      "    Processing page 1/32\n",
      "    Processing page 2/32\n",
      "    Processing page 3/32\n",
      "    Processing page 4/32\n",
      "    Processing page 5/32\n",
      "    Processing page 6/32\n",
      "    Processing page 7/32\n",
      "    Processing page 8/32\n",
      "    Processing page 9/32\n",
      "    Processing page 10/32\n",
      "    Processing page 11/32\n",
      "    Processing page 12/32\n",
      "    Processing page 13/32\n",
      "    Processing page 14/32\n",
      "    Processing page 15/32\n",
      "    Processing page 16/32\n",
      "    Processing page 17/32\n",
      "    Processing page 18/32\n",
      "    Processing page 19/32\n",
      "    Processing page 20/32\n",
      "    Processing page 21/32\n",
      "    Processing page 22/32\n",
      "    Processing page 23/32\n",
      "    Processing page 24/32\n",
      "    Processing page 25/32\n",
      "    Processing page 26/32\n",
      "    Processing page 27/32\n",
      "    Processing page 28/32\n",
      "    Processing page 29/32\n",
      "    Processing page 30/32\n",
      "    Processing page 31/32\n",
      "    Processing page 32/32\n",
      "  OCR complete. Text saved to: 2507.21134.txt\n",
      "\n",
      "Processing paper 95/200: InsurTech innovation using natural language processing\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21112\n",
      "  Performing OCR on: 2507.21112.pdf\n",
      "    Processing page 1/29\n",
      "    Processing page 2/29\n",
      "    Processing page 3/29\n",
      "    Processing page 4/29\n",
      "    Processing page 5/29\n",
      "    Processing page 6/29\n",
      "    Processing page 7/29\n",
      "    Processing page 8/29\n",
      "    Processing page 9/29\n",
      "    Processing page 10/29\n",
      "    Processing page 11/29\n",
      "    Processing page 12/29\n",
      "    Processing page 13/29\n",
      "    Processing page 14/29\n",
      "    Processing page 15/29\n",
      "    Processing page 16/29\n",
      "    Processing page 17/29\n",
      "    Processing page 18/29\n",
      "    Processing page 19/29\n",
      "    Processing page 20/29\n",
      "    Processing page 21/29\n",
      "    Processing page 22/29\n",
      "    Processing page 23/29\n",
      "    Processing page 24/29\n",
      "    Processing page 25/29\n",
      "    Processing page 26/29\n",
      "    Processing page 27/29\n",
      "    Processing page 28/29\n",
      "    Processing page 29/29\n",
      "  OCR complete. Text saved to: 2507.21112.txt\n",
      "\n",
      "Processing paper 96/200: SemRAG: Semantic Knowledge-Augmented RAG for Improved Question-Answering\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21110\n",
      "  Performing OCR on: 2507.21110.pdf\n",
      "    Processing page 1/16\n",
      "    Processing page 2/16\n",
      "    Processing page 3/16\n",
      "    Processing page 4/16\n",
      "    Processing page 5/16\n",
      "    Processing page 6/16\n",
      "    Processing page 7/16\n",
      "    Processing page 8/16\n",
      "    Processing page 9/16\n",
      "    Processing page 10/16\n",
      "    Processing page 11/16\n",
      "    Processing page 12/16\n",
      "    Processing page 13/16\n",
      "    Processing page 14/16\n",
      "    Processing page 15/16\n",
      "    Processing page 16/16\n",
      "  OCR complete. Text saved to: 2507.21110.txt\n",
      "\n",
      "Processing paper 97/200: A Survey of Classification Tasks and Approaches for Legal Contracts\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21108\n",
      "  Performing OCR on: 2507.21108.pdf\n",
      "    Processing page 1/59\n",
      "    Processing page 2/59\n",
      "    Processing page 3/59\n",
      "    Processing page 4/59\n",
      "    Processing page 5/59\n",
      "    Processing page 6/59\n",
      "    Processing page 7/59\n",
      "    Processing page 8/59\n",
      "    Processing page 9/59\n",
      "    Processing page 10/59\n",
      "    Processing page 11/59\n",
      "    Processing page 12/59\n",
      "    Processing page 13/59\n",
      "    Processing page 14/59\n",
      "    Processing page 15/59\n",
      "    Processing page 16/59\n",
      "    Processing page 17/59\n",
      "    Processing page 18/59\n",
      "    Processing page 19/59\n",
      "    Processing page 20/59\n",
      "    Processing page 21/59\n",
      "    Processing page 22/59\n",
      "    Processing page 23/59\n",
      "    Processing page 24/59\n",
      "    Processing page 25/59\n",
      "    Processing page 26/59\n",
      "    Processing page 27/59\n",
      "    Processing page 28/59\n",
      "    Processing page 29/59\n",
      "    Processing page 30/59\n",
      "    Processing page 31/59\n",
      "    Processing page 32/59\n",
      "    Processing page 33/59\n",
      "    Processing page 34/59\n",
      "    Processing page 35/59\n",
      "    Processing page 36/59\n",
      "    Processing page 37/59\n",
      "    Processing page 38/59\n",
      "    Processing page 39/59\n",
      "    Processing page 40/59\n",
      "    Processing page 41/59\n",
      "    Processing page 42/59\n",
      "    Processing page 43/59\n",
      "    Processing page 44/59\n",
      "    Processing page 45/59\n",
      "    Processing page 46/59\n",
      "    Processing page 47/59\n",
      "    Processing page 48/59\n",
      "    Processing page 49/59\n",
      "    Processing page 50/59\n",
      "    Processing page 51/59\n",
      "    Processing page 52/59\n",
      "    Processing page 53/59\n",
      "    Processing page 54/59\n",
      "    Processing page 55/59\n",
      "    Processing page 56/59\n",
      "    Processing page 57/59\n",
      "    Processing page 58/59\n",
      "    Processing page 59/59\n",
      "  OCR complete. Text saved to: 2507.21108.txt\n",
      "\n",
      "Processing paper 98/200: Curved Inference: Concern-Sensitive Geometry in Large Language Model Residual Streams\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21107\n",
      "  Performing OCR on: 2507.21107.pdf\n",
      "    Processing page 1/29\n",
      "    Processing page 2/29\n",
      "    Processing page 3/29\n",
      "    Processing page 4/29\n",
      "    Processing page 5/29\n",
      "    Processing page 6/29\n",
      "    Processing page 7/29\n",
      "    Processing page 8/29\n",
      "    Processing page 9/29\n",
      "    Processing page 10/29\n",
      "    Processing page 11/29\n",
      "    Processing page 12/29\n",
      "    Processing page 13/29\n",
      "    Processing page 14/29\n",
      "    Processing page 15/29\n",
      "    Processing page 16/29\n",
      "    Processing page 17/29\n",
      "    Processing page 18/29\n",
      "    Processing page 19/29\n",
      "    Processing page 20/29\n",
      "    Processing page 21/29\n",
      "    Processing page 22/29\n",
      "    Processing page 23/29\n",
      "    Processing page 24/29\n",
      "    Processing page 25/29\n",
      "    Processing page 26/29\n",
      "    Processing page 27/29\n",
      "    Processing page 28/29\n",
      "    Processing page 29/29\n",
      "  OCR complete. Text saved to: 2507.21107.txt\n",
      "\n",
      "Processing paper 99/200: Creation of a Numerical Scoring System to Objectively Measure and Compare the Level of Rhetoric in Arabic Texts: A Feasibility Study, and A Working Prototype\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21106\n",
      "  Performing OCR on: 2507.21106.pdf\n",
      "    Processing page 1/105\n",
      "    Processing page 2/105\n",
      "    Processing page 3/105\n",
      "    Processing page 4/105\n",
      "    Processing page 5/105\n",
      "    Processing page 6/105\n",
      "    Processing page 7/105\n",
      "    Processing page 8/105\n",
      "    Processing page 9/105\n",
      "    Processing page 10/105\n",
      "    Processing page 11/105\n",
      "    Processing page 12/105\n",
      "    Processing page 13/105\n",
      "    Processing page 14/105\n",
      "    Processing page 15/105\n",
      "    Processing page 16/105\n",
      "    Processing page 17/105\n",
      "    Processing page 18/105\n",
      "    Processing page 19/105\n",
      "    Processing page 20/105\n",
      "    Processing page 21/105\n",
      "    Processing page 22/105\n",
      "    Processing page 23/105\n",
      "    Processing page 24/105\n",
      "    Processing page 25/105\n",
      "    Processing page 26/105\n",
      "    Processing page 27/105\n",
      "    Processing page 28/105\n",
      "    Processing page 29/105\n",
      "    Processing page 30/105\n",
      "    Processing page 31/105\n",
      "    Processing page 32/105\n",
      "    Processing page 33/105\n",
      "    Processing page 34/105\n",
      "    Processing page 35/105\n",
      "    Processing page 36/105\n",
      "    Processing page 37/105\n",
      "    Processing page 38/105\n",
      "    Processing page 39/105\n",
      "    Processing page 40/105\n",
      "    Processing page 41/105\n",
      "    Processing page 42/105\n",
      "    Processing page 43/105\n",
      "    Processing page 44/105\n",
      "    Processing page 45/105\n",
      "    Processing page 46/105\n",
      "    Processing page 47/105\n",
      "    Processing page 48/105\n",
      "    Processing page 49/105\n",
      "    Processing page 50/105\n",
      "    Processing page 51/105\n",
      "    Processing page 52/105\n",
      "    Processing page 53/105\n",
      "    Processing page 54/105\n",
      "    Processing page 55/105\n",
      "    Processing page 56/105\n",
      "    Processing page 57/105\n",
      "    Processing page 58/105\n",
      "    Processing page 59/105\n",
      "    Processing page 60/105\n",
      "    Processing page 61/105\n",
      "    Processing page 62/105\n",
      "    Processing page 63/105\n",
      "    Processing page 64/105\n",
      "    Processing page 65/105\n",
      "    Processing page 66/105\n",
      "    Processing page 67/105\n",
      "    Processing page 68/105\n",
      "    Processing page 69/105\n",
      "    Processing page 70/105\n",
      "    Processing page 71/105\n",
      "    Processing page 72/105\n",
      "    Processing page 73/105\n",
      "    Processing page 74/105\n",
      "    Processing page 75/105\n",
      "    Processing page 76/105\n",
      "    Processing page 77/105\n",
      "    Processing page 78/105\n",
      "    Processing page 79/105\n",
      "    Processing page 80/105\n",
      "    Processing page 81/105\n",
      "    Processing page 82/105\n",
      "    Processing page 83/105\n",
      "    Processing page 84/105\n",
      "    Processing page 85/105\n",
      "    Processing page 86/105\n",
      "    Processing page 87/105\n",
      "    Processing page 88/105\n",
      "    Processing page 89/105\n",
      "    Processing page 90/105\n",
      "    Processing page 91/105\n",
      "    Processing page 92/105\n",
      "    Processing page 93/105\n",
      "    Processing page 94/105\n",
      "    Processing page 95/105\n",
      "    Processing page 96/105\n",
      "    Processing page 97/105\n",
      "    Processing page 98/105\n",
      "    Processing page 99/105\n",
      "    Processing page 100/105\n",
      "    Processing page 101/105\n",
      "    Processing page 102/105\n",
      "    Processing page 103/105\n",
      "    Processing page 104/105\n",
      "    Processing page 105/105\n",
      "  OCR complete. Text saved to: 2507.21106.txt\n",
      "\n",
      "Processing paper 100/200: iLSU-T: an Open Dataset for Uruguayan Sign Language Translation\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21104\n",
      "  Performing OCR on: 2507.21104.pdf\n",
      "    Processing page 1/10\n",
      "    Processing page 2/10\n",
      "    Processing page 3/10\n",
      "    Processing page 4/10\n",
      "    Processing page 5/10\n",
      "    Processing page 6/10\n",
      "    Processing page 7/10\n",
      "    Processing page 8/10\n",
      "    Processing page 9/10\n",
      "    Processing page 10/10\n",
      "  OCR complete. Text saved to: 2507.21104.txt\n",
      "\n",
      "Processing paper 101/200: Rewrite-to-Rank: Optimizing Ad Visibility via Retrieval-Aware Text Rewriting\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21099\n",
      "  Performing OCR on: 2507.21099.pdf\n",
      "    Processing page 1/13\n",
      "    Processing page 2/13\n",
      "    Processing page 3/13\n",
      "    Processing page 4/13\n",
      "    Processing page 5/13\n",
      "    Processing page 6/13\n",
      "    Processing page 7/13\n",
      "    Processing page 8/13\n",
      "    Processing page 9/13\n",
      "    Processing page 10/13\n",
      "    Processing page 11/13\n",
      "    Processing page 12/13\n",
      "    Processing page 13/13\n",
      "  OCR complete. Text saved to: 2507.21099.txt\n",
      "\n",
      "Processing paper 102/200: QU-NLP at CheckThat! 2025: Multilingual Subjectivity in News Articles Detection using Feature-Augmented Transformer Models with Sequential Cross-Lingual Fine-Tuning\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21095\n",
      "  Performing OCR on: 2507.21095.pdf\n",
      "    Processing page 1/12\n",
      "    Processing page 2/12\n",
      "    Processing page 3/12\n",
      "    Processing page 4/12\n",
      "    Processing page 5/12\n",
      "    Processing page 6/12\n",
      "    Processing page 7/12\n",
      "    Processing page 8/12\n",
      "    Processing page 9/12\n",
      "    Processing page 10/12\n",
      "    Processing page 11/12\n",
      "    Processing page 12/12\n",
      "  OCR complete. Text saved to: 2507.21095.txt\n",
      "\n",
      "Processing paper 103/200: Multi-Amateur Contrastive Decoding for Text Generation\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21086\n",
      "  Performing OCR on: 2507.21086.pdf\n",
      "    Processing page 1/11\n",
      "    Processing page 2/11\n",
      "    Processing page 3/11\n",
      "    Processing page 4/11\n",
      "    Processing page 5/11\n",
      "    Processing page 6/11\n",
      "    Processing page 7/11\n",
      "    Processing page 8/11\n",
      "    Processing page 9/11\n",
      "    Processing page 10/11\n",
      "    Processing page 11/11\n",
      "  OCR complete. Text saved to: 2507.21086.txt\n",
      "\n",
      "Processing paper 104/200: Reviving Your MNEME: Predicting The Side Effects of LLM Unlearning and Fine-Tuning via Sparse Model Diffing\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21084\n",
      "  Performing OCR on: 2507.21084.pdf\n",
      "    Processing page 1/12\n",
      "    Processing page 2/12\n",
      "    Processing page 3/12\n",
      "    Processing page 4/12\n",
      "    Processing page 5/12\n",
      "    Processing page 6/12\n",
      "    Processing page 7/12\n",
      "    Processing page 8/12\n",
      "    Processing page 9/12\n",
      "    Processing page 10/12\n",
      "    Processing page 11/12\n",
      "    Processing page 12/12\n",
      "  OCR complete. Text saved to: 2507.21084.txt\n",
      "\n",
      "Processing paper 105/200: ChatGPT Reads Your Tone and Responds Accordingly -- Until It Does Not -- Emotional Framing Induces Bias in LLM Outputs\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21083\n",
      "  Performing OCR on: 2507.21083.pdf\n",
      "    Processing page 1/14\n",
      "    Processing page 2/14\n",
      "    Processing page 3/14\n",
      "    Processing page 4/14\n",
      "    Processing page 5/14\n",
      "    Processing page 6/14\n",
      "    Processing page 7/14\n",
      "    Processing page 8/14\n",
      "    Processing page 9/14\n",
      "    Processing page 10/14\n",
      "    Processing page 11/14\n",
      "    Processing page 12/14\n",
      "    Processing page 13/14\n",
      "    Processing page 14/14\n",
      "  OCR complete. Text saved to: 2507.21083.txt\n",
      "\n",
      "Processing paper 106/200: Which symbol grounding problem should we try to solve?\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21080\n",
      "  Performing OCR on: 2507.21080.pdf\n",
      "    Processing page 1/10\n",
      "    Processing page 2/10\n",
      "    Processing page 3/10\n",
      "    Processing page 4/10\n",
      "    Processing page 5/10\n",
      "    Processing page 6/10\n",
      "    Processing page 7/10\n",
      "    Processing page 8/10\n",
      "    Processing page 9/10\n",
      "    Processing page 10/10\n",
      "  OCR complete. Text saved to: 2507.21080.txt\n",
      "\n",
      "Processing paper 107/200: Product vs. Process: Exploring EFL Students' Editing of AI-Generated Text for Expository Writing\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21073\n",
      "  Performing OCR on: 2507.21073.pdf\n",
      "    Processing page 1/45\n",
      "    Processing page 2/45\n",
      "    Processing page 3/45\n",
      "    Processing page 4/45\n",
      "    Processing page 5/45\n",
      "    Processing page 6/45\n",
      "    Processing page 7/45\n",
      "    Processing page 8/45\n",
      "    Processing page 9/45\n",
      "    Processing page 10/45\n",
      "    Processing page 11/45\n",
      "    Processing page 12/45\n",
      "    Processing page 13/45\n",
      "    Processing page 14/45\n",
      "    Processing page 15/45\n",
      "    Processing page 16/45\n",
      "    Processing page 17/45\n",
      "    Processing page 18/45\n",
      "    Processing page 19/45\n",
      "    Processing page 20/45\n",
      "    Processing page 21/45\n",
      "    Processing page 22/45\n",
      "    Processing page 23/45\n",
      "    Processing page 24/45\n",
      "    Processing page 25/45\n",
      "    Processing page 26/45\n",
      "    Processing page 27/45\n",
      "    Processing page 28/45\n",
      "    Processing page 29/45\n",
      "    Processing page 30/45\n",
      "    Processing page 31/45\n",
      "    Processing page 32/45\n",
      "    Processing page 33/45\n",
      "    Processing page 34/45\n",
      "    Processing page 35/45\n",
      "    Processing page 36/45\n",
      "    Processing page 37/45\n",
      "    Processing page 38/45\n",
      "    Processing page 39/45\n",
      "    Processing page 40/45\n",
      "    Processing page 41/45\n",
      "    Processing page 42/45\n",
      "    Processing page 43/45\n",
      "    Processing page 44/45\n",
      "    Processing page 45/45\n",
      "  OCR complete. Text saved to: 2507.21073.txt\n",
      "\n",
      "Processing paper 108/200: Dialogic Social Learning for Artificial Agents: Enhancing LLM Ontology Acquisition through Mixed-Initiative Educational Interactions\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21065\n",
      "  Performing OCR on: 2507.21065.pdf\n",
      "    Processing page 1/14\n",
      "    Processing page 2/14\n",
      "    Processing page 3/14\n",
      "    Processing page 4/14\n",
      "    Processing page 5/14\n",
      "    Processing page 6/14\n",
      "    Processing page 7/14\n",
      "    Processing page 8/14\n",
      "    Processing page 9/14\n",
      "    Processing page 10/14\n",
      "    Processing page 11/14\n",
      "    Processing page 12/14\n",
      "    Processing page 13/14\n",
      "    Processing page 14/14\n",
      "  OCR complete. Text saved to: 2507.21065.txt\n",
      "\n",
      "Processing paper 109/200: Categorical Classification of Book Summaries Using Word Embedding Techniques\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21058\n",
      "  Performing OCR on: 2507.21058.pdf\n",
      "    Processing page 1/10\n",
      "    Processing page 2/10\n",
      "    Processing page 3/10\n",
      "    Processing page 4/10\n",
      "    Processing page 5/10\n",
      "    Processing page 6/10\n",
      "    Processing page 7/10\n",
      "    Processing page 8/10\n",
      "    Processing page 9/10\n",
      "    Processing page 10/10\n",
      "  OCR complete. Text saved to: 2507.21058.txt\n",
      "\n",
      "Processing paper 110/200: MetaCLIP 2: A Worldwide Scaling Recipe\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22062\n",
      "  Performing OCR on: 2507.22062.pdf\n",
      "    Processing page 1/16\n",
      "    Processing page 2/16\n",
      "    Processing page 3/16\n",
      "    Processing page 4/16\n",
      "    Processing page 5/16\n",
      "    Processing page 6/16\n",
      "    Processing page 7/16\n",
      "    Processing page 8/16\n",
      "    Processing page 9/16\n",
      "    Processing page 10/16\n",
      "    Processing page 11/16\n",
      "    Processing page 12/16\n",
      "    Processing page 13/16\n",
      "    Processing page 14/16\n",
      "    Processing page 15/16\n",
      "    Processing page 16/16\n",
      "  OCR complete. Text saved to: 2507.22062.txt\n",
      "\n",
      "Processing paper 111/200: UserBench: An Interactive Gym Environment for User-Centric Agents\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22034\n",
      "  Performing OCR on: 2507.22034.pdf\n",
      "    Processing page 1/25\n",
      "    Processing page 2/25\n",
      "    Processing page 3/25\n",
      "    Processing page 4/25\n",
      "    Processing page 5/25\n",
      "    Processing page 6/25\n",
      "    Processing page 7/25\n",
      "    Processing page 8/25\n",
      "    Processing page 9/25\n",
      "    Processing page 10/25\n",
      "    Processing page 11/25\n",
      "    Processing page 12/25\n",
      "    Processing page 13/25\n",
      "    Processing page 14/25\n",
      "    Processing page 15/25\n",
      "    Processing page 16/25\n",
      "    Processing page 17/25\n",
      "    Processing page 18/25\n",
      "    Processing page 19/25\n",
      "    Processing page 20/25\n",
      "    Processing page 21/25\n",
      "    Processing page 22/25\n",
      "    Processing page 23/25\n",
      "    Processing page 24/25\n",
      "    Processing page 25/25\n",
      "  OCR complete. Text saved to: 2507.22034.txt\n",
      "\n",
      "Processing paper 112/200: UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.22025\n",
      "  Performing OCR on: 2507.22025.pdf\n",
      "    Processing page 1/10\n",
      "    Processing page 2/10\n",
      "    Processing page 3/10\n",
      "    Processing page 4/10\n",
      "    Processing page 5/10\n",
      "    Processing page 6/10\n",
      "    Processing page 7/10\n",
      "    Processing page 8/10\n",
      "    Processing page 9/10\n",
      "    Processing page 10/10\n",
      "  OCR complete. Text saved to: 2507.22025.txt\n",
      "\n",
      "Processing paper 113/200: Who's important? -- SUnSET: Synergistic Understanding of Stakeholder, Events and Time for Timeline Generation\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21903\n",
      "  Performing OCR on: 2507.21903.pdf\n",
      "    Processing page 1/24\n",
      "    Processing page 2/24\n",
      "    Processing page 3/24\n",
      "    Processing page 4/24\n",
      "    Processing page 5/24\n",
      "    Processing page 6/24\n",
      "    Processing page 7/24\n",
      "    Processing page 8/24\n",
      "    Processing page 9/24\n",
      "    Processing page 10/24\n",
      "    Processing page 11/24\n",
      "    Processing page 12/24\n",
      "    Processing page 13/24\n",
      "    Processing page 14/24\n",
      "    Processing page 15/24\n",
      "    Processing page 16/24\n",
      "    Processing page 17/24\n",
      "    Processing page 18/24\n",
      "    Processing page 19/24\n",
      "    Processing page 20/24\n",
      "    Processing page 21/24\n",
      "    Processing page 22/24\n",
      "    Processing page 23/24\n",
      "    Processing page 24/24\n",
      "  OCR complete. Text saved to: 2507.21903.txt\n",
      "\n",
      "Processing paper 114/200: What Does it Mean for a Neural Network to Learn a \"World Model\"?\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21513\n",
      "  Performing OCR on: 2507.21513.pdf\n",
      "    Processing page 1/15\n",
      "    Processing page 2/15\n",
      "    Processing page 3/15\n",
      "    Processing page 4/15\n",
      "    Processing page 5/15\n",
      "    Processing page 6/15\n",
      "    Processing page 7/15\n",
      "    Processing page 8/15\n",
      "    Processing page 9/15\n",
      "    Processing page 10/15\n",
      "    Processing page 11/15\n",
      "    Processing page 12/15\n",
      "    Processing page 13/15\n",
      "    Processing page 14/15\n",
      "    Processing page 15/15\n",
      "  OCR complete. Text saved to: 2507.21513.txt\n",
      "\n",
      "Processing paper 115/200: ReGATE: Learning Faster and Better with Fewer Tokens in MLLMs\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21420\n",
      "  Performing OCR on: 2507.21420.pdf\n",
      "    Processing page 1/13\n",
      "    Processing page 2/13\n",
      "    Processing page 3/13\n",
      "    Processing page 4/13\n",
      "    Processing page 5/13\n",
      "    Processing page 6/13\n",
      "    Processing page 7/13\n",
      "    Processing page 8/13\n",
      "    Processing page 9/13\n",
      "    Processing page 10/13\n",
      "    Processing page 11/13\n",
      "    Processing page 12/13\n",
      "    Processing page 13/13\n",
      "  OCR complete. Text saved to: 2507.21420.txt\n",
      "\n",
      "Processing paper 116/200: Multimodal LLMs as Customized Reward Models for Text-to-Image Generation\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21391\n",
      "  Performing OCR on: 2507.21391.pdf\n",
      "    Processing page 1/15\n",
      "    Processing page 2/15\n",
      "    Processing page 3/15\n",
      "    Processing page 4/15\n",
      "    Processing page 5/15\n",
      "    Processing page 6/15\n",
      "    Processing page 7/15\n",
      "    Processing page 8/15\n",
      "    Processing page 9/15\n",
      "    Processing page 10/15\n",
      "    Processing page 11/15\n",
      "    Processing page 12/15\n",
      "    Processing page 13/15\n",
      "    Processing page 14/15\n",
      "    Processing page 15/15\n",
      "  OCR complete. Text saved to: 2507.21391.txt\n",
      "\n",
      "Processing paper 117/200: Teaching Language Models To Gather Information Proactively\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21389\n",
      "  Performing OCR on: 2507.21389.pdf\n",
      "    Processing page 1/12\n",
      "    Processing page 2/12\n",
      "    Processing page 3/12\n",
      "    Processing page 4/12\n",
      "    Processing page 5/12\n",
      "    Processing page 6/12\n",
      "    Processing page 7/12\n",
      "    Processing page 8/12\n",
      "    Processing page 9/12\n",
      "    Processing page 10/12\n",
      "    Processing page 11/12\n",
      "    Processing page 12/12\n",
      "  OCR complete. Text saved to: 2507.21389.txt\n",
      "\n",
      "Processing paper 118/200: LeMix: Unified Scheduling for LLM Training and Inference on Multi-GPU Systems\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21276\n",
      "  Performing OCR on: 2507.21276.pdf\n",
      "    Processing page 1/14\n",
      "    Processing page 2/14\n",
      "    Processing page 3/14\n",
      "    Processing page 4/14\n",
      "    Processing page 5/14\n",
      "    Processing page 6/14\n",
      "    Processing page 7/14\n",
      "    Processing page 8/14\n",
      "    Processing page 9/14\n",
      "    Processing page 10/14\n",
      "    Processing page 11/14\n",
      "    Processing page 12/14\n",
      "    Processing page 13/14\n",
      "    Processing page 14/14\n",
      "  OCR complete. Text saved to: 2507.21276.txt\n",
      "\n",
      "Processing paper 119/200: CompoST: A Benchmark for Analyzing the Ability of LLMs To Compositionally Interpret Questions in a QALD Setting\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21257\n",
      "  Performing OCR on: 2507.21257.pdf\n",
      "    Processing page 1/24\n",
      "    Processing page 2/24\n",
      "    Processing page 3/24\n",
      "    Processing page 4/24\n",
      "    Processing page 5/24\n",
      "    Processing page 6/24\n",
      "    Processing page 7/24\n",
      "    Processing page 8/24\n",
      "    Processing page 9/24\n",
      "    Processing page 10/24\n",
      "    Processing page 11/24\n",
      "    Processing page 12/24\n",
      "    Processing page 13/24\n",
      "    Processing page 14/24\n",
      "    Processing page 15/24\n",
      "    Processing page 16/24\n",
      "    Processing page 17/24\n",
      "    Processing page 18/24\n",
      "    Processing page 19/24\n",
      "    Processing page 20/24\n",
      "    Processing page 21/24\n",
      "    Processing page 22/24\n",
      "    Processing page 23/24\n",
      "    Processing page 24/24\n",
      "  OCR complete. Text saved to: 2507.21257.txt\n",
      "\n",
      "Processing paper 120/200: EvoSLD: Automated Neural Scaling Law Discovery With Large Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21184\n",
      "  Performing OCR on: 2507.21184.pdf\n",
      "    Processing page 1/12\n",
      "    Processing page 2/12\n",
      "    Processing page 3/12\n",
      "    Processing page 4/12\n",
      "    Processing page 5/12\n",
      "    Processing page 6/12\n",
      "    Processing page 7/12\n",
      "    Processing page 8/12\n",
      "    Processing page 9/12\n",
      "    Processing page 10/12\n",
      "    Processing page 11/12\n",
      "    Processing page 12/12\n",
      "  OCR complete. Text saved to: 2507.21184.txt\n",
      "\n",
      "Processing paper 121/200: MaPPO: Maximum a Posteriori Preference Optimization with Prior Knowledge\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21183\n",
      "  Performing OCR on: 2507.21183.pdf\n",
      "    Processing page 1/20\n",
      "    Processing page 2/20\n",
      "    Processing page 3/20\n",
      "    Processing page 4/20\n",
      "    Processing page 5/20\n",
      "    Processing page 6/20\n",
      "    Processing page 7/20\n",
      "    Processing page 8/20\n",
      "    Processing page 9/20\n",
      "    Processing page 10/20\n",
      "    Processing page 11/20\n",
      "    Processing page 12/20\n",
      "    Processing page 13/20\n",
      "    Processing page 14/20\n",
      "    Processing page 15/20\n",
      "    Processing page 16/20\n",
      "    Processing page 17/20\n",
      "    Processing page 18/20\n",
      "    Processing page 19/20\n",
      "    Processing page 20/20\n",
      "  OCR complete. Text saved to: 2507.21183.txt\n",
      "\n",
      "Processing paper 122/200: OneShield -- the Next Generation of LLM Guardrails\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21170\n",
      "  Performing OCR on: 2507.21170.pdf\n",
      "    Processing page 1/9\n",
      "    Processing page 2/9\n",
      "    Processing page 3/9\n",
      "    Processing page 4/9\n",
      "    Processing page 5/9\n",
      "    Processing page 6/9\n",
      "    Processing page 7/9\n",
      "    Processing page 8/9\n",
      "    Processing page 9/9\n",
      "  OCR complete. Text saved to: 2507.21170.txt\n",
      "\n",
      "Processing paper 123/200: AgentMaster: A Multi-Agent Conversational Framework Using A2A and MCP Protocols for Multimodal Information Retrieval and Analysis\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21105\n",
      "  Performing OCR on: 2507.21105.pdf\n",
      "    Processing page 1/16\n",
      "    Processing page 2/16\n",
      "    Processing page 3/16\n",
      "    Processing page 4/16\n",
      "    Processing page 5/16\n",
      "    Processing page 6/16\n",
      "    Processing page 7/16\n",
      "    Processing page 8/16\n",
      "    Processing page 9/16\n",
      "    Processing page 10/16\n",
      "    Processing page 11/16\n",
      "    Processing page 12/16\n",
      "    Processing page 13/16\n",
      "    Processing page 14/16\n",
      "    Processing page 15/16\n",
      "    Processing page 16/16\n",
      "  OCR complete. Text saved to: 2507.21105.txt\n",
      "\n",
      "Processing paper 124/200: Analise Semantica Automatizada com LLM e RAG para Bulas Farmaceuticas\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21103\n",
      "  Performing OCR on: 2507.21103.pdf\n",
      "    Processing page 1/18\n",
      "    Processing page 2/18\n",
      "    Processing page 3/18\n",
      "    Processing page 4/18\n",
      "    Processing page 5/18\n",
      "    Processing page 6/18\n",
      "    Processing page 7/18\n",
      "    Processing page 8/18\n",
      "    Processing page 9/18\n",
      "    Processing page 10/18\n",
      "    Processing page 11/18\n",
      "    Processing page 12/18\n",
      "    Processing page 13/18\n",
      "    Processing page 14/18\n",
      "    Processing page 15/18\n",
      "    Processing page 16/18\n",
      "    Processing page 17/18\n",
      "    Processing page 18/18\n",
      "  OCR complete. Text saved to: 2507.21103.txt\n",
      "\n",
      "Processing paper 125/200: Emotionally Aware Moderation: The Potential of Emotion Monitoring in Shaping Healthier Social Media Conversations\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21089\n",
      "  Performing OCR on: 2507.21089.pdf\n",
      "    Processing page 1/28\n",
      "    Processing page 2/28\n",
      "    Processing page 3/28\n",
      "    Processing page 4/28\n",
      "    Processing page 5/28\n",
      "    Processing page 6/28\n",
      "    Processing page 7/28\n",
      "    Processing page 8/28\n",
      "    Processing page 9/28\n",
      "    Processing page 10/28\n",
      "    Processing page 11/28\n",
      "    Processing page 12/28\n",
      "    Processing page 13/28\n",
      "    Processing page 14/28\n",
      "    Processing page 15/28\n",
      "    Processing page 16/28\n",
      "    Processing page 17/28\n",
      "    Processing page 18/28\n",
      "    Processing page 19/28\n",
      "    Processing page 20/28\n",
      "    Processing page 21/28\n",
      "    Processing page 22/28\n",
      "    Processing page 23/28\n",
      "    Processing page 24/28\n",
      "    Processing page 25/28\n",
      "    Processing page 26/28\n",
      "    Processing page 27/28\n",
      "    Processing page 28/28\n",
      "  OCR complete. Text saved to: 2507.21089.txt\n",
      "\n",
      "Processing paper 126/200: Can LLMs Reason About Trust?: A Pilot Study\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21075\n",
      "  Performing OCR on: 2507.21075.pdf\n",
      "    Processing page 1/17\n",
      "    Processing page 2/17\n",
      "    Processing page 3/17\n",
      "    Processing page 4/17\n",
      "    Processing page 5/17\n",
      "    Processing page 6/17\n",
      "    Processing page 7/17\n",
      "    Processing page 8/17\n",
      "    Processing page 9/17\n",
      "    Processing page 10/17\n",
      "    Processing page 11/17\n",
      "    Processing page 12/17\n",
      "    Processing page 13/17\n",
      "    Processing page 14/17\n",
      "    Processing page 15/17\n",
      "    Processing page 16/17\n",
      "    Processing page 17/17\n",
      "  OCR complete. Text saved to: 2507.21075.txt\n",
      "\n",
      "Processing paper 127/200: R-Stitch: Dynamic Trajectory Stitching for Efficient Reasoning\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.17307\n",
      "  Performing OCR on: 2507.17307.pdf\n",
      "    Processing page 1/9\n",
      "    Processing page 2/9\n",
      "    Processing page 3/9\n",
      "    Processing page 4/9\n",
      "    Processing page 5/9\n",
      "    Processing page 6/9\n",
      "    Processing page 7/9\n",
      "    Processing page 8/9\n",
      "    Processing page 9/9\n",
      "  OCR complete. Text saved to: 2507.17307.txt\n",
      "\n",
      "Processing paper 128/200: Multi-Agent-as-Judge: Aligning LLM-Agent-Based Automated Evaluation with Multi-Dimensional Human Evaluation\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21028\n",
      "  Performing OCR on: 2507.21028.pdf\n",
      "    Processing page 1/28\n",
      "    Processing page 2/28\n",
      "    Processing page 3/28\n",
      "    Processing page 4/28\n",
      "    Processing page 5/28\n",
      "    Processing page 6/28\n",
      "    Processing page 7/28\n",
      "    Processing page 8/28\n",
      "    Processing page 9/28\n",
      "    Processing page 10/28\n",
      "    Processing page 11/28\n",
      "    Processing page 12/28\n",
      "    Processing page 13/28\n",
      "    Processing page 14/28\n",
      "    Processing page 15/28\n",
      "    Processing page 16/28\n",
      "    Processing page 17/28\n",
      "    Processing page 18/28\n",
      "    Processing page 19/28\n",
      "    Processing page 20/28\n",
      "    Processing page 21/28\n",
      "    Processing page 22/28\n",
      "    Processing page 23/28\n",
      "    Processing page 24/28\n",
      "    Processing page 25/28\n",
      "    Processing page 26/28\n",
      "    Processing page 27/28\n",
      "    Processing page 28/28\n",
      "  OCR complete. Text saved to: 2507.21028.txt\n",
      "\n",
      "Processing paper 129/200: Memorization in Fine-Tuned Large Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.21009\n",
      "  Performing OCR on: 2507.21009.pdf\n",
      "    Processing page 1/30\n",
      "    Processing page 2/30\n",
      "    Processing page 3/30\n",
      "    Processing page 4/30\n",
      "    Processing page 5/30\n",
      "    Processing page 6/30\n",
      "    Processing page 7/30\n",
      "    Processing page 8/30\n",
      "    Processing page 9/30\n",
      "    Processing page 10/30\n",
      "    Processing page 11/30\n",
      "    Processing page 12/30\n",
      "    Processing page 13/30\n",
      "    Processing page 14/30\n",
      "    Processing page 15/30\n",
      "    Processing page 16/30\n",
      "    Processing page 17/30\n",
      "    Processing page 18/30\n",
      "    Processing page 19/30\n",
      "    Processing page 20/30\n",
      "    Processing page 21/30\n",
      "    Processing page 22/30\n",
      "    Processing page 23/30\n",
      "    Processing page 24/30\n",
      "    Processing page 25/30\n",
      "    Processing page 26/30\n",
      "    Processing page 27/30\n",
      "    Processing page 28/30\n",
      "    Processing page 29/30\n",
      "    Processing page 30/30\n",
      "  OCR complete. Text saved to: 2507.21009.txt\n",
      "\n",
      "Processing paper 130/200: Mind the Gap: Conformative Decoding to Improve Output Diversity of Instruction-Tuned Large Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20956\n",
      "  Performing OCR on: 2507.20956.pdf\n",
      "    Processing page 1/12\n",
      "    Processing page 2/12\n",
      "    Processing page 3/12\n",
      "    Processing page 4/12\n",
      "    Processing page 5/12\n",
      "    Processing page 6/12\n",
      "    Processing page 7/12\n",
      "    Processing page 8/12\n",
      "    Processing page 9/12\n",
      "    Processing page 10/12\n",
      "    Processing page 11/12\n",
      "    Processing page 12/12\n",
      "  OCR complete. Text saved to: 2507.20956.txt\n",
      "\n",
      "Processing paper 131/200: FRED: Financial Retrieval-Enhanced Detection and Editing of Hallucinations in Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20930\n",
      "  Performing OCR on: 2507.20930.pdf\n",
      "    Processing page 1/14\n",
      "    Processing page 2/14\n",
      "    Processing page 3/14\n",
      "    Processing page 4/14\n",
      "    Processing page 5/14\n",
      "    Processing page 6/14\n",
      "    Processing page 7/14\n",
      "    Processing page 8/14\n",
      "    Processing page 9/14\n",
      "    Processing page 10/14\n",
      "    Processing page 11/14\n",
      "    Processing page 12/14\n",
      "    Processing page 13/14\n",
      "    Processing page 14/14\n",
      "  OCR complete. Text saved to: 2507.20930.txt\n",
      "\n",
      "Processing paper 132/200: FHSTP@EXIST 2025 Benchmark: Sexism Detection with Transparent Speech Concept Bottleneck Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20924\n",
      "  Performing OCR on: 2507.20924.pdf\n",
      "    Processing page 1/12\n",
      "    Processing page 2/12\n",
      "    Processing page 3/12\n",
      "    Processing page 4/12\n",
      "    Processing page 5/12\n",
      "    Processing page 6/12\n",
      "    Processing page 7/12\n",
      "    Processing page 8/12\n",
      "    Processing page 9/12\n",
      "    Processing page 10/12\n",
      "    Processing page 11/12\n",
      "    Processing page 12/12\n",
      "  OCR complete. Text saved to: 2507.20924.txt\n",
      "\n",
      "Processing paper 133/200: MediQAl: A French Medical Question Answering Dataset for Knowledge and Reasoning Evaluation\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20917\n",
      "  Performing OCR on: 2507.20917.pdf\n",
      "    Processing page 1/18\n",
      "    Processing page 2/18\n",
      "    Processing page 3/18\n",
      "    Processing page 4/18\n",
      "    Processing page 5/18\n",
      "    Processing page 6/18\n",
      "    Processing page 7/18\n",
      "    Processing page 8/18\n",
      "    Processing page 9/18\n",
      "    Processing page 10/18\n",
      "    Processing page 11/18\n",
      "    Processing page 12/18\n",
      "    Processing page 13/18\n",
      "    Processing page 14/18\n",
      "    Processing page 15/18\n",
      "    Processing page 16/18\n",
      "    Processing page 17/18\n",
      "    Processing page 18/18\n",
      "  OCR complete. Text saved to: 2507.20917.txt\n",
      "\n",
      "Processing paper 134/200: Soft Injection of Task Embeddings Outperforms Prompt-Based In-Context Learning\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20906\n",
      "  Performing OCR on: 2507.20906.pdf\n",
      "    Processing page 1/40\n",
      "    Processing page 2/40\n",
      "    Processing page 3/40\n",
      "    Processing page 4/40\n",
      "    Processing page 5/40\n",
      "    Processing page 6/40\n",
      "    Processing page 7/40\n",
      "    Processing page 8/40\n",
      "    Processing page 9/40\n",
      "    Processing page 10/40\n",
      "    Processing page 11/40\n",
      "    Processing page 12/40\n",
      "    Processing page 13/40\n",
      "    Processing page 14/40\n",
      "    Processing page 15/40\n",
      "    Processing page 16/40\n",
      "    Processing page 17/40\n",
      "    Processing page 18/40\n",
      "    Processing page 19/40\n",
      "    Processing page 20/40\n",
      "    Processing page 21/40\n",
      "    Processing page 22/40\n",
      "    Processing page 23/40\n",
      "    Processing page 24/40\n",
      "    Processing page 25/40\n",
      "    Processing page 26/40\n",
      "    Processing page 27/40\n",
      "    Processing page 28/40\n",
      "    Processing page 29/40\n",
      "    Processing page 30/40\n",
      "    Processing page 31/40\n",
      "    Processing page 32/40\n",
      "    Processing page 33/40\n",
      "    Processing page 34/40\n",
      "    Processing page 35/40\n",
      "    Processing page 36/40\n",
      "    Processing page 37/40\n",
      "    Processing page 38/40\n",
      "    Processing page 39/40\n",
      "    Processing page 40/40\n",
      "  OCR complete. Text saved to: 2507.20906.txt\n",
      "\n",
      "Processing paper 135/200: Leveraging Open-Source Large Language Models for Clinical Information Extraction in Resource-Constrained Settings\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20859\n",
      "  Performing OCR on: 2507.20859.pdf\n",
      "    Processing page 1/34\n",
      "    Processing page 2/34\n",
      "    Processing page 3/34\n",
      "    Processing page 4/34\n",
      "    Processing page 5/34\n",
      "    Processing page 6/34\n",
      "    Processing page 7/34\n",
      "    Processing page 8/34\n",
      "    Processing page 9/34\n",
      "    Processing page 10/34\n",
      "    Processing page 11/34\n",
      "    Processing page 12/34\n",
      "    Processing page 13/34\n",
      "    Processing page 14/34\n",
      "    Processing page 15/34\n",
      "    Processing page 16/34\n",
      "    Processing page 17/34\n",
      "    Processing page 18/34\n",
      "    Processing page 19/34\n",
      "    Processing page 20/34\n",
      "    Processing page 21/34\n",
      "    Processing page 22/34\n",
      "    Processing page 23/34\n",
      "    Processing page 24/34\n",
      "    Processing page 25/34\n",
      "    Processing page 26/34\n",
      "    Processing page 27/34\n",
      "    Processing page 28/34\n",
      "    Processing page 29/34\n",
      "    Processing page 30/34\n",
      "    Processing page 31/34\n",
      "    Processing page 32/34\n",
      "    Processing page 33/34\n",
      "    Processing page 34/34\n",
      "  OCR complete. Text saved to: 2507.20859.txt\n",
      "\n",
      "Processing paper 136/200: A survey of diversity quantification in natural language processing: The why, what, where and how\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20858\n",
      "  Performing OCR on: 2507.20858.pdf\n",
      "    Processing page 1/20\n",
      "    Processing page 2/20\n",
      "    Processing page 3/20\n",
      "    Processing page 4/20\n",
      "    Processing page 5/20\n",
      "    Processing page 6/20\n",
      "    Processing page 7/20\n",
      "    Processing page 8/20\n",
      "    Processing page 9/20\n",
      "    Processing page 10/20\n",
      "    Processing page 11/20\n",
      "    Processing page 12/20\n",
      "    Processing page 13/20\n",
      "    Processing page 14/20\n",
      "    Processing page 15/20\n",
      "    Processing page 16/20\n",
      "    Processing page 17/20\n",
      "    Processing page 18/20\n",
      "    Processing page 19/20\n",
      "    Processing page 20/20\n",
      "  OCR complete. Text saved to: 2507.20858.txt\n",
      "\n",
      "Processing paper 137/200: Latent Inter-User Difference Modeling for LLM Personalization\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20849\n",
      "  Performing OCR on: 2507.20849.pdf\n",
      "    Processing page 1/18\n",
      "    Processing page 2/18\n",
      "    Processing page 3/18\n",
      "    Processing page 4/18\n",
      "    Processing page 5/18\n",
      "    Processing page 6/18\n",
      "    Processing page 7/18\n",
      "    Processing page 8/18\n",
      "    Processing page 9/18\n",
      "    Processing page 10/18\n",
      "    Processing page 11/18\n",
      "    Processing page 12/18\n",
      "    Processing page 13/18\n",
      "    Processing page 14/18\n",
      "    Processing page 15/18\n",
      "    Processing page 16/18\n",
      "    Processing page 17/18\n",
      "    Processing page 18/18\n",
      "  OCR complete. Text saved to: 2507.20849.txt\n",
      "\n",
      "Processing paper 138/200: Automating Thematic Review of Prevention of Future Deaths Reports: Replicating the ONS Child Suicide Study using Large Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20786\n",
      "  Performing OCR on: 2507.20786.pdf\n",
      "    Processing page 1/8\n",
      "    Processing page 2/8\n",
      "    Processing page 3/8\n",
      "    Processing page 4/8\n",
      "    Processing page 5/8\n",
      "    Processing page 6/8\n",
      "    Processing page 7/8\n",
      "    Processing page 8/8\n",
      "  OCR complete. Text saved to: 2507.20786.txt\n",
      "\n",
      "Processing paper 139/200: On The Role of Pretrained Language Models in General-Purpose Text Embeddings: A Survey\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20783\n",
      "  Performing OCR on: 2507.20783.pdf\n",
      "    Processing page 1/45\n",
      "    Processing page 2/45\n",
      "    Processing page 3/45\n",
      "    Processing page 4/45\n",
      "    Processing page 5/45\n",
      "    Processing page 6/45\n",
      "    Processing page 7/45\n",
      "    Processing page 8/45\n",
      "    Processing page 9/45\n",
      "    Processing page 10/45\n",
      "    Processing page 11/45\n",
      "    Processing page 12/45\n",
      "    Processing page 13/45\n",
      "    Processing page 14/45\n",
      "    Processing page 15/45\n",
      "    Processing page 16/45\n",
      "    Processing page 17/45\n",
      "    Processing page 18/45\n",
      "    Processing page 19/45\n",
      "    Processing page 20/45\n",
      "    Processing page 21/45\n",
      "    Processing page 22/45\n",
      "    Processing page 23/45\n",
      "    Processing page 24/45\n",
      "    Processing page 25/45\n",
      "    Processing page 26/45\n",
      "    Processing page 27/45\n",
      "    Processing page 28/45\n",
      "    Processing page 29/45\n",
      "    Processing page 30/45\n",
      "    Processing page 31/45\n",
      "    Processing page 32/45\n",
      "    Processing page 33/45\n",
      "    Processing page 34/45\n",
      "    Processing page 35/45\n",
      "    Processing page 36/45\n",
      "    Processing page 37/45\n",
      "    Processing page 38/45\n",
      "    Processing page 39/45\n",
      "    Processing page 40/45\n",
      "    Processing page 41/45\n",
      "    Processing page 42/45\n",
      "    Processing page 43/45\n",
      "    Processing page 44/45\n",
      "    Processing page 45/45\n",
      "  OCR complete. Text saved to: 2507.20783.txt\n",
      "\n",
      "Processing paper 140/200: Multilingual Self-Taught Faithfulness Evaluators\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20752\n",
      "  Performing OCR on: 2507.20752.pdf\n",
      "    Processing page 1/17\n",
      "    Processing page 2/17\n",
      "    Processing page 3/17\n",
      "    Processing page 4/17\n",
      "    Processing page 5/17\n",
      "    Processing page 6/17\n",
      "    Processing page 7/17\n",
      "    Processing page 8/17\n",
      "    Processing page 9/17\n",
      "    Processing page 10/17\n",
      "    Processing page 11/17\n",
      "    Processing page 12/17\n",
      "    Processing page 13/17\n",
      "    Processing page 14/17\n",
      "    Processing page 15/17\n",
      "    Processing page 16/17\n",
      "    Processing page 17/17\n",
      "  OCR complete. Text saved to: 2507.20752.txt\n",
      "\n",
      "Processing paper 141/200: Investigating Structural Pruning and Recovery Techniques for Compressing Multimodal Large Language Models: An Empirical Study\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20749\n",
      "  Performing OCR on: 2507.20749.pdf\n",
      "    Processing page 1/23\n",
      "    Processing page 2/23\n",
      "    Processing page 3/23\n",
      "    Processing page 4/23\n",
      "    Processing page 5/23\n",
      "    Processing page 6/23\n",
      "    Processing page 7/23\n",
      "    Processing page 8/23\n",
      "    Processing page 9/23\n",
      "    Processing page 10/23\n",
      "    Processing page 11/23\n",
      "    Processing page 12/23\n",
      "    Processing page 13/23\n",
      "    Processing page 14/23\n",
      "    Processing page 15/23\n",
      "    Processing page 16/23\n",
      "    Processing page 17/23\n",
      "    Processing page 18/23\n",
      "    Processing page 19/23\n",
      "    Processing page 20/23\n",
      "    Processing page 21/23\n",
      "    Processing page 22/23\n",
      "    Processing page 23/23\n",
      "  OCR complete. Text saved to: 2507.20749.txt\n",
      "\n",
      "Processing paper 142/200: Text2VLM: Adapting Text-Only Datasets to Evaluate Alignment Training in Visual Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20704\n",
      "  Performing OCR on: 2507.20704.pdf\n",
      "    Processing page 1/9\n",
      "    Processing page 2/9\n",
      "    Processing page 3/9\n",
      "    Processing page 4/9\n",
      "    Processing page 5/9\n",
      "    Processing page 6/9\n",
      "    Processing page 7/9\n",
      "    Processing page 8/9\n",
      "    Processing page 9/9\n",
      "  OCR complete. Text saved to: 2507.20704.txt\n",
      "\n",
      "Processing paper 143/200: When Scale Meets Diversity: Evaluating Language Models on Fine-Grained Multilingual Claim Verification\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20700\n",
      "  Performing OCR on: 2507.20700.pdf\n",
      "    Processing page 1/16\n",
      "    Processing page 2/16\n",
      "    Processing page 3/16\n",
      "    Processing page 4/16\n",
      "    Processing page 5/16\n",
      "    Processing page 6/16\n",
      "    Processing page 7/16\n",
      "    Processing page 8/16\n",
      "    Processing page 9/16\n",
      "    Processing page 10/16\n",
      "    Processing page 11/16\n",
      "    Processing page 12/16\n",
      "    Processing page 13/16\n",
      "    Processing page 14/16\n",
      "    Processing page 15/16\n",
      "    Processing page 16/16\n",
      "  OCR complete. Text saved to: 2507.20700.txt\n",
      "\n",
      "Processing paper 144/200: Geometric-Mean Policy Optimization\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20673\n",
      "  Performing OCR on: 2507.20673.pdf\n",
      "    Processing page 1/12\n",
      "    Processing page 2/12\n",
      "    Processing page 3/12\n",
      "    Processing page 4/12\n",
      "    Processing page 5/12\n",
      "    Processing page 6/12\n",
      "    Processing page 7/12\n",
      "    Processing page 8/12\n",
      "    Processing page 9/12\n",
      "    Processing page 10/12\n",
      "    Processing page 11/12\n",
      "    Processing page 12/12\n",
      "  OCR complete. Text saved to: 2507.20673.txt\n",
      "\n",
      "Processing paper 145/200: Ontology-Enhanced Knowledge Graph Completion using Large Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20643\n",
      "  Performing OCR on: 2507.20643.pdf\n",
      "    Processing page 1/19\n",
      "    Processing page 2/19\n",
      "    Processing page 3/19\n",
      "    Processing page 4/19\n",
      "    Processing page 5/19\n",
      "    Processing page 6/19\n",
      "    Processing page 7/19\n",
      "    Processing page 8/19\n",
      "    Processing page 9/19\n",
      "    Processing page 10/19\n",
      "    Processing page 11/19\n",
      "    Processing page 12/19\n",
      "    Processing page 13/19\n",
      "    Processing page 14/19\n",
      "    Processing page 15/19\n",
      "    Processing page 16/19\n",
      "    Processing page 17/19\n",
      "    Processing page 18/19\n",
      "    Processing page 19/19\n",
      "  OCR complete. Text saved to: 2507.20643.txt\n",
      "\n",
      "Processing paper 146/200: Before the Outrage: Challenges and Advances in Predicting Online Antisocial Behavior\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20614\n",
      "  Performing OCR on: 2507.20614.pdf\n",
      "    Processing page 1/34\n",
      "    Processing page 2/34\n",
      "    Processing page 3/34\n",
      "    Processing page 4/34\n",
      "    Processing page 5/34\n",
      "    Processing page 6/34\n",
      "    Processing page 7/34\n",
      "    Processing page 8/34\n",
      "    Processing page 9/34\n",
      "    Processing page 10/34\n",
      "    Processing page 11/34\n",
      "    Processing page 12/34\n",
      "    Processing page 13/34\n",
      "    Processing page 14/34\n",
      "    Processing page 15/34\n",
      "    Processing page 16/34\n",
      "    Processing page 17/34\n",
      "    Processing page 18/34\n",
      "    Processing page 19/34\n",
      "    Processing page 20/34\n",
      "    Processing page 21/34\n",
      "    Processing page 22/34\n",
      "    Processing page 23/34\n",
      "    Processing page 24/34\n",
      "    Processing page 25/34\n",
      "    Processing page 26/34\n",
      "    Processing page 27/34\n",
      "    Processing page 28/34\n",
      "    Processing page 29/34\n",
      "    Processing page 30/34\n",
      "    Processing page 31/34\n",
      "    Processing page 32/34\n",
      "    Processing page 33/34\n",
      "    Processing page 34/34\n",
      "  OCR complete. Text saved to: 2507.20614.txt\n",
      "\n",
      "Processing paper 147/200: ZSE-Cap: A Zero-Shot Ensemble for Image Retrieval and Prompt-Guided Captioning\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20564\n",
      "  Performing OCR on: 2507.20564.pdf\n",
      "    Processing page 1/7\n",
      "    Processing page 2/7\n",
      "    Processing page 3/7\n",
      "    Processing page 4/7\n",
      "    Processing page 5/7\n",
      "    Processing page 6/7\n",
      "    Processing page 7/7\n",
      "  OCR complete. Text saved to: 2507.20564.txt\n",
      "\n",
      "Processing paper 148/200: Enhancing Hallucination Detection via Future Context\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20546\n",
      "  Performing OCR on: 2507.20546.pdf\n",
      "    Processing page 1/19\n",
      "    Processing page 2/19\n",
      "    Processing page 3/19\n",
      "    Processing page 4/19\n",
      "    Processing page 5/19\n",
      "    Processing page 6/19\n",
      "    Processing page 7/19\n",
      "    Processing page 8/19\n",
      "    Processing page 9/19\n",
      "    Processing page 10/19\n",
      "    Processing page 11/19\n",
      "    Processing page 12/19\n",
      "    Processing page 13/19\n",
      "    Processing page 14/19\n",
      "    Processing page 15/19\n",
      "    Processing page 16/19\n",
      "    Processing page 17/19\n",
      "    Processing page 18/19\n",
      "    Processing page 19/19\n",
      "  OCR complete. Text saved to: 2507.20546.txt\n",
      "\n",
      "Processing paper 149/200: Dialogues of Dissent: Thematic and Rhetorical Dimensions of Hate and Counter-Hate Speech in Social Media Conversations\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20528\n",
      "  Performing OCR on: 2507.20528.pdf\n",
      "    Processing page 1/10\n",
      "    Processing page 2/10\n",
      "    Processing page 3/10\n",
      "    Processing page 4/10\n",
      "    Processing page 5/10\n",
      "    Processing page 6/10\n",
      "    Processing page 7/10\n",
      "    Processing page 8/10\n",
      "    Processing page 9/10\n",
      "    Processing page 10/10\n",
      "  OCR complete. Text saved to: 2507.20528.txt\n",
      "\n",
      "Processing paper 150/200: SAND-Math: Using LLMs to Generate Novel, Difficult and Useful Mathematics Questions and Answers\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20527\n",
      "  Performing OCR on: 2507.20527.pdf\n",
      "    Processing page 1/42\n",
      "    Processing page 2/42\n",
      "    Processing page 3/42\n",
      "    Processing page 4/42\n",
      "    Processing page 5/42\n",
      "    Processing page 6/42\n",
      "    Processing page 7/42\n",
      "    Processing page 8/42\n",
      "    Processing page 9/42\n",
      "    Processing page 10/42\n",
      "    Processing page 11/42\n",
      "    Processing page 12/42\n",
      "    Processing page 13/42\n",
      "    Processing page 14/42\n",
      "    Processing page 15/42\n",
      "    Processing page 16/42\n",
      "    Processing page 17/42\n",
      "    Processing page 18/42\n",
      "    Processing page 19/42\n",
      "    Processing page 20/42\n",
      "    Processing page 21/42\n",
      "    Processing page 22/42\n",
      "    Processing page 23/42\n",
      "    Processing page 24/42\n",
      "    Processing page 25/42\n",
      "    Processing page 26/42\n",
      "    Processing page 27/42\n",
      "    Processing page 28/42\n",
      "    Processing page 29/42\n",
      "    Processing page 30/42\n",
      "    Processing page 31/42\n",
      "    Processing page 32/42\n",
      "    Processing page 33/42\n",
      "    Processing page 34/42\n",
      "    Processing page 35/42\n",
      "    Processing page 36/42\n",
      "    Processing page 37/42\n",
      "    Processing page 38/42\n",
      "    Processing page 39/42\n",
      "    Processing page 40/42\n",
      "    Processing page 41/42\n",
      "    Processing page 42/42\n",
      "  OCR complete. Text saved to: 2507.20527.txt\n",
      "\n",
      "Processing paper 151/200: AQUA: A Large Language Model for Aquaculture & Fisheries\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20520\n",
      "  Performing OCR on: 2507.20520.pdf\n",
      "    Processing page 1/17\n",
      "    Processing page 2/17\n",
      "    Processing page 3/17\n",
      "    Processing page 4/17\n",
      "    Processing page 5/17\n",
      "    Processing page 6/17\n",
      "    Processing page 7/17\n",
      "    Processing page 8/17\n",
      "    Processing page 9/17\n",
      "    Processing page 10/17\n",
      "    Processing page 11/17\n",
      "    Processing page 12/17\n",
      "    Processing page 13/17\n",
      "    Processing page 14/17\n",
      "    Processing page 15/17\n",
      "    Processing page 16/17\n",
      "    Processing page 17/17\n",
      "  OCR complete. Text saved to: 2507.20520.txt\n",
      "\n",
      "Processing paper 152/200: Speaking in Words, Thinking in Logic: A Dual-Process Framework in QA Systems\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20491\n",
      "  Performing OCR on: 2507.20491.pdf\n",
      "    Processing page 1/8\n",
      "    Processing page 2/8\n",
      "    Processing page 3/8\n",
      "    Processing page 4/8\n",
      "    Processing page 5/8\n",
      "    Processing page 6/8\n",
      "    Processing page 7/8\n",
      "    Processing page 8/8\n",
      "  OCR complete. Text saved to: 2507.20491.txt\n",
      "\n",
      "Processing paper 153/200: CodeNER: Code Prompting for Named Entity Recognition\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20423\n",
      "  Performing OCR on: 2507.20423.pdf\n",
      "    Processing page 1/18\n",
      "    Processing page 2/18\n",
      "    Processing page 3/18\n",
      "    Processing page 4/18\n",
      "    Processing page 5/18\n",
      "    Processing page 6/18\n",
      "    Processing page 7/18\n",
      "    Processing page 8/18\n",
      "    Processing page 9/18\n",
      "    Processing page 10/18\n",
      "    Processing page 11/18\n",
      "    Processing page 12/18\n",
      "    Processing page 13/18\n",
      "    Processing page 14/18\n",
      "    Processing page 15/18\n",
      "    Processing page 16/18\n",
      "    Processing page 17/18\n",
      "    Processing page 18/18\n",
      "  OCR complete. Text saved to: 2507.20423.txt\n",
      "\n",
      "Processing paper 154/200: Survey of NLU Benchmarks Diagnosing Linguistic Phenomena: Why not Standardize Diagnostics Benchmarks?\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20419\n",
      "  Performing OCR on: 2507.20419.pdf\n",
      "    Processing page 1/24\n",
      "    Processing page 2/24\n",
      "    Processing page 3/24\n",
      "    Processing page 4/24\n",
      "    Processing page 5/24\n",
      "    Processing page 6/24\n",
      "    Processing page 7/24\n",
      "    Processing page 8/24\n",
      "    Processing page 9/24\n",
      "    Processing page 10/24\n",
      "    Processing page 11/24\n",
      "    Processing page 12/24\n",
      "    Processing page 13/24\n",
      "    Processing page 14/24\n",
      "    Processing page 15/24\n",
      "    Processing page 16/24\n",
      "    Processing page 17/24\n",
      "    Processing page 18/24\n",
      "    Processing page 19/24\n",
      "    Processing page 20/24\n",
      "    Processing page 21/24\n",
      "    Processing page 22/24\n",
      "    Processing page 23/24\n",
      "    Processing page 24/24\n",
      "  OCR complete. Text saved to: 2507.20419.txt\n",
      "\n",
      "Processing paper 155/200: CONCAP: Seeing Beyond English with Concepts Retrieval-Augmented Captioning\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20411\n",
      "  Performing OCR on: 2507.20411.pdf\n",
      "    Processing page 1/20\n",
      "    Processing page 2/20\n",
      "    Processing page 3/20\n",
      "    Processing page 4/20\n",
      "    Processing page 5/20\n",
      "    Processing page 6/20\n",
      "    Processing page 7/20\n",
      "    Processing page 8/20\n",
      "    Processing page 9/20\n",
      "    Processing page 10/20\n",
      "    Processing page 11/20\n",
      "    Processing page 12/20\n",
      "    Processing page 13/20\n",
      "    Processing page 14/20\n",
      "    Processing page 15/20\n",
      "    Processing page 16/20\n",
      "    Processing page 17/20\n",
      "    Processing page 18/20\n",
      "    Processing page 19/20\n",
      "    Processing page 20/20\n",
      "  OCR complete. Text saved to: 2507.20411.txt\n",
      "\n",
      "Processing paper 156/200: Cognitive Chain-of-Thought: Structured Multimodal Reasoning about Social Situations\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20409\n",
      "  Performing OCR on: 2507.20409.pdf\n",
      "    Processing page 1/17\n",
      "    Processing page 2/17\n",
      "    Processing page 3/17\n",
      "    Processing page 4/17\n",
      "    Processing page 5/17\n",
      "    Processing page 6/17\n",
      "    Processing page 7/17\n",
      "    Processing page 8/17\n",
      "    Processing page 9/17\n",
      "    Processing page 10/17\n",
      "    Processing page 11/17\n",
      "    Processing page 12/17\n",
      "    Processing page 13/17\n",
      "    Processing page 14/17\n",
      "    Processing page 15/17\n",
      "    Processing page 16/17\n",
      "    Processing page 17/17\n",
      "  OCR complete. Text saved to: 2507.20409.txt\n",
      "\n",
      "Processing paper 157/200: Length Representations in Large Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20398\n",
      "  Performing OCR on: 2507.20398.pdf\n",
      "    Processing page 1/19\n",
      "    Processing page 2/19\n",
      "    Processing page 3/19\n",
      "    Processing page 4/19\n",
      "    Processing page 5/19\n",
      "    Processing page 6/19\n",
      "    Processing page 7/19\n",
      "    Processing page 8/19\n",
      "    Processing page 9/19\n",
      "    Processing page 10/19\n",
      "    Processing page 11/19\n",
      "    Processing page 12/19\n",
      "    Processing page 13/19\n",
      "    Processing page 14/19\n",
      "    Processing page 15/19\n",
      "    Processing page 16/19\n",
      "    Processing page 17/19\n",
      "    Processing page 18/19\n",
      "    Processing page 19/19\n",
      "  OCR complete. Text saved to: 2507.20398.txt\n",
      "\n",
      "Processing paper 158/200: RMTBench: Benchmarking LLMs Through Multi-Turn User-Centric Role-Playing\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20352\n",
      "  Performing OCR on: 2507.20352.pdf\n",
      "    Processing page 1/17\n",
      "    Processing page 2/17\n",
      "    Processing page 3/17\n",
      "    Processing page 4/17\n",
      "    Processing page 5/17\n",
      "    Processing page 6/17\n",
      "    Processing page 7/17\n",
      "    Processing page 8/17\n",
      "    Processing page 9/17\n",
      "    Processing page 10/17\n",
      "    Processing page 11/17\n",
      "    Processing page 12/17\n",
      "    Processing page 13/17\n",
      "    Processing page 14/17\n",
      "    Processing page 15/17\n",
      "    Processing page 16/17\n",
      "    Processing page 17/17\n",
      "  OCR complete. Text saved to: 2507.20352.txt\n",
      "\n",
      "Processing paper 159/200: DYNARTmo: A Dynamic Articulatory Model for Visualization of Speech Movement Patterns\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20343\n",
      "  Performing OCR on: 2507.20343.pdf\n",
      "    Processing page 1/10\n",
      "    Processing page 2/10\n",
      "    Processing page 3/10\n",
      "    Processing page 4/10\n",
      "    Processing page 5/10\n",
      "    Processing page 6/10\n",
      "    Processing page 7/10\n",
      "    Processing page 8/10\n",
      "    Processing page 9/10\n",
      "    Processing page 10/10\n",
      "  OCR complete. Text saved to: 2507.20343.txt\n",
      "\n",
      "Processing paper 160/200: Advancing Dialectal Arabic to Modern Standard Arabic Machine Translation\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20301\n",
      "  Performing OCR on: 2507.20301.pdf\n",
      "    Processing page 1/35\n",
      "    Processing page 2/35\n",
      "    Processing page 3/35\n",
      "    Processing page 4/35\n",
      "    Processing page 5/35\n",
      "    Processing page 6/35\n",
      "    Processing page 7/35\n",
      "    Processing page 8/35\n",
      "    Processing page 9/35\n",
      "    Processing page 10/35\n",
      "    Processing page 11/35\n",
      "    Processing page 12/35\n",
      "    Processing page 13/35\n",
      "    Processing page 14/35\n",
      "    Processing page 15/35\n",
      "    Processing page 16/35\n",
      "    Processing page 17/35\n",
      "    Processing page 18/35\n",
      "    Processing page 19/35\n",
      "    Processing page 20/35\n",
      "    Processing page 21/35\n",
      "    Processing page 22/35\n",
      "    Processing page 23/35\n",
      "    Processing page 24/35\n",
      "    Processing page 25/35\n",
      "    Processing page 26/35\n",
      "    Processing page 27/35\n",
      "    Processing page 28/35\n",
      "    Processing page 29/35\n",
      "    Processing page 30/35\n",
      "    Processing page 31/35\n",
      "    Processing page 32/35\n",
      "    Processing page 33/35\n",
      "    Processing page 34/35\n",
      "    Processing page 35/35\n",
      "  OCR complete. Text saved to: 2507.20301.txt\n",
      "\n",
      "Processing paper 161/200: What Language(s) Does Aya-23 Think In? How Multilinguality Affects Internal Language Representations\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20279\n",
      "  Performing OCR on: 2507.20279.pdf\n",
      "    Processing page 1/12\n",
      "    Processing page 2/12\n",
      "    Processing page 3/12\n",
      "    Processing page 4/12\n",
      "    Processing page 5/12\n",
      "    Processing page 6/12\n",
      "    Processing page 7/12\n",
      "    Processing page 8/12\n",
      "    Processing page 9/12\n",
      "    Processing page 10/12\n",
      "    Processing page 11/12\n",
      "    Processing page 12/12\n",
      "  OCR complete. Text saved to: 2507.20279.txt\n",
      "\n",
      "Processing paper 162/200: MoL-RL: Distilling Multi-Step Environmental Feedback into LLMs for Feedback-Independent Reasoning\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20278\n",
      "  Performing OCR on: 2507.20278.pdf\n",
      "    Processing page 1/12\n",
      "    Processing page 2/12\n",
      "    Processing page 3/12\n",
      "    Processing page 4/12\n",
      "    Processing page 5/12\n",
      "    Processing page 6/12\n",
      "    Processing page 7/12\n",
      "    Processing page 8/12\n",
      "    Processing page 9/12\n",
      "    Processing page 10/12\n",
      "    Processing page 11/12\n",
      "    Processing page 12/12\n",
      "  OCR complete. Text saved to: 2507.20278.txt\n",
      "\n",
      "Processing paper 163/200: EMBRACE: Shaping Inclusive Opinion Representation by Aligning Implicit Conversations with Social Norms\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20264\n",
      "  Performing OCR on: 2507.20264.pdf\n",
      "    Processing page 1/17\n",
      "    Processing page 2/17\n",
      "    Processing page 3/17\n",
      "    Processing page 4/17\n",
      "    Processing page 5/17\n",
      "    Processing page 6/17\n",
      "    Processing page 7/17\n",
      "    Processing page 8/17\n",
      "    Processing page 9/17\n",
      "    Processing page 10/17\n",
      "    Processing page 11/17\n",
      "    Processing page 12/17\n",
      "    Processing page 13/17\n",
      "    Processing page 14/17\n",
      "    Processing page 15/17\n",
      "    Processing page 16/17\n",
      "    Processing page 17/17\n",
      "  OCR complete. Text saved to: 2507.20264.txt\n",
      "\n",
      "Processing paper 164/200: Post-Completion Learning for Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20252\n",
      "  Performing OCR on: 2507.20252.pdf\n",
      "    Processing page 1/10\n",
      "    Processing page 2/10\n",
      "    Processing page 3/10\n",
      "    Processing page 4/10\n",
      "    Processing page 5/10\n",
      "    Processing page 6/10\n",
      "    Processing page 7/10\n",
      "    Processing page 8/10\n",
      "    Processing page 9/10\n",
      "    Processing page 10/10\n",
      "  OCR complete. Text saved to: 2507.20252.txt\n",
      "\n",
      "Processing paper 165/200: Modeling Professionalism in Expert Questioning through Linguistic Differentiation\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20249\n",
      "  Performing OCR on: 2507.20249.pdf\n",
      "    Processing page 1/6\n",
      "    Processing page 2/6\n",
      "    Processing page 3/6\n",
      "    Processing page 4/6\n",
      "    Processing page 5/6\n",
      "    Processing page 6/6\n",
      "  OCR complete. Text saved to: 2507.20249.txt\n",
      "\n",
      "Processing paper 166/200: Reframe Your Life Story: Interactive Narrative Therapist and Innovative Moment Assessment with Large Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20241\n",
      "  Performing OCR on: 2507.20241.pdf\n",
      "    Processing page 1/25\n",
      "    Processing page 2/25\n",
      "    Processing page 3/25\n",
      "    Processing page 4/25\n",
      "    Processing page 5/25\n",
      "    Processing page 6/25\n",
      "    Processing page 7/25\n",
      "    Processing page 8/25\n",
      "    Processing page 9/25\n",
      "    Processing page 10/25\n",
      "    Processing page 11/25\n",
      "    Processing page 12/25\n",
      "    Processing page 13/25\n",
      "    Processing page 14/25\n",
      "    Processing page 15/25\n",
      "    Processing page 16/25\n",
      "    Processing page 17/25\n",
      "    Processing page 18/25\n",
      "    Processing page 19/25\n",
      "    Processing page 20/25\n",
      "    Processing page 21/25\n",
      "    Processing page 22/25\n",
      "    Processing page 23/25\n",
      "    Processing page 24/25\n",
      "    Processing page 25/25\n",
      "  OCR complete. Text saved to: 2507.20241.txt\n",
      "\n",
      "Processing paper 167/200: Co-NAML-LSTUR: A Combined Model with Attentive Multi-View Learning and Long- and Short-term User Representations for News Recommendation\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20210\n",
      "  Performing OCR on: 2507.20210.pdf\n",
      "    Processing page 1/11\n",
      "    Processing page 2/11\n",
      "    Processing page 3/11\n",
      "    Processing page 4/11\n",
      "    Processing page 5/11\n",
      "    Processing page 6/11\n",
      "    Processing page 7/11\n",
      "    Processing page 8/11\n",
      "    Processing page 9/11\n",
      "    Processing page 10/11\n",
      "    Processing page 11/11\n",
      "  OCR complete. Text saved to: 2507.20210.txt\n",
      "\n",
      "Processing paper 168/200: IQ Test for LLMs: An Evaluation Framework for Uncovering Core Skills in LLMs\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20208\n",
      "  Performing OCR on: 2507.20208.pdf\n",
      "    Processing page 1/30\n",
      "    Processing page 2/30\n",
      "    Processing page 3/30\n",
      "    Processing page 4/30\n",
      "    Processing page 5/30\n",
      "    Processing page 6/30\n",
      "    Processing page 7/30\n",
      "    Processing page 8/30\n",
      "    Processing page 9/30\n",
      "    Processing page 10/30\n",
      "    Processing page 11/30\n",
      "    Processing page 12/30\n",
      "    Processing page 13/30\n",
      "    Processing page 14/30\n",
      "    Processing page 15/30\n",
      "    Processing page 16/30\n",
      "    Processing page 17/30\n",
      "    Processing page 18/30\n",
      "    Processing page 19/30\n",
      "    Processing page 20/30\n",
      "    Processing page 21/30\n",
      "    Processing page 22/30\n",
      "    Processing page 23/30\n",
      "    Processing page 24/30\n",
      "    Processing page 25/30\n",
      "    Processing page 26/30\n",
      "    Processing page 27/30\n",
      "    Processing page 28/30\n",
      "    Processing page 29/30\n",
      "    Processing page 30/30\n",
      "  OCR complete. Text saved to: 2507.20208.txt\n",
      "\n",
      "Processing paper 169/200: Diversity-Enhanced Reasoning for Subjective Questions\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20187\n",
      "  Performing OCR on: 2507.20187.pdf\n",
      "    Processing page 1/22\n",
      "    Processing page 2/22\n",
      "    Processing page 3/22\n",
      "    Processing page 4/22\n",
      "    Processing page 5/22\n",
      "    Processing page 6/22\n",
      "    Processing page 7/22\n",
      "    Processing page 8/22\n",
      "    Processing page 9/22\n",
      "    Processing page 10/22\n",
      "    Processing page 11/22\n",
      "    Processing page 12/22\n",
      "    Processing page 13/22\n",
      "    Processing page 14/22\n",
      "    Processing page 15/22\n",
      "    Processing page 16/22\n",
      "    Processing page 17/22\n",
      "    Processing page 18/22\n",
      "    Processing page 19/22\n",
      "    Processing page 20/22\n",
      "    Processing page 21/22\n",
      "    Processing page 22/22\n",
      "  OCR complete. Text saved to: 2507.20187.txt\n",
      "\n",
      "Processing paper 170/200: SessionIntentBench: A Multi-task Inter-session Intention-shift Modeling Benchmark for E-commerce Customer Behavior Understanding\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20185\n",
      "  Performing OCR on: 2507.20185.pdf\n",
      "    Processing page 1/27\n",
      "    Processing page 2/27\n",
      "    Processing page 3/27\n",
      "    Processing page 4/27\n",
      "    Processing page 5/27\n",
      "    Processing page 6/27\n",
      "    Processing page 7/27\n",
      "    Processing page 8/27\n",
      "    Processing page 9/27\n",
      "    Processing page 10/27\n",
      "    Processing page 11/27\n",
      "    Processing page 12/27\n",
      "    Processing page 13/27\n",
      "    Processing page 14/27\n",
      "    Processing page 15/27\n",
      "    Processing page 16/27\n",
      "    Processing page 17/27\n",
      "    Processing page 18/27\n",
      "    Processing page 19/27\n",
      "    Processing page 20/27\n",
      "    Processing page 21/27\n",
      "    Processing page 22/27\n",
      "    Processing page 23/27\n",
      "    Processing page 24/27\n",
      "    Processing page 25/27\n",
      "    Processing page 26/27\n",
      "    Processing page 27/27\n",
      "  OCR complete. Text saved to: 2507.20185.txt\n",
      "\n",
      "Processing paper 171/200: SGPO: Self-Generated Preference Optimization based on Self-Improver\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20181\n",
      "  Performing OCR on: 2507.20181.pdf\n",
      "    Processing page 1/25\n",
      "    Processing page 2/25\n",
      "    Processing page 3/25\n",
      "    Processing page 4/25\n",
      "    Processing page 5/25\n",
      "    Processing page 6/25\n",
      "    Processing page 7/25\n",
      "    Processing page 8/25\n",
      "    Processing page 9/25\n",
      "    Processing page 10/25\n",
      "    Processing page 11/25\n",
      "    Processing page 12/25\n",
      "    Processing page 13/25\n",
      "    Processing page 14/25\n",
      "    Processing page 15/25\n",
      "    Processing page 16/25\n",
      "    Processing page 17/25\n",
      "    Processing page 18/25\n",
      "    Processing page 19/25\n",
      "    Processing page 20/25\n",
      "    Processing page 21/25\n",
      "    Processing page 22/25\n",
      "    Processing page 23/25\n",
      "    Processing page 24/25\n",
      "    Processing page 25/25\n",
      "  OCR complete. Text saved to: 2507.20181.txt\n",
      "\n",
      "Processing paper 172/200: Goal Alignment in LLM-Based User Simulators for Conversational AI\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20152\n",
      "  Performing OCR on: 2507.20152.pdf\n",
      "    Processing page 1/23\n",
      "    Processing page 2/23\n",
      "    Processing page 3/23\n",
      "    Processing page 4/23\n",
      "    Processing page 5/23\n",
      "    Processing page 6/23\n",
      "    Processing page 7/23\n",
      "    Processing page 8/23\n",
      "    Processing page 9/23\n",
      "    Processing page 10/23\n",
      "    Processing page 11/23\n",
      "    Processing page 12/23\n",
      "    Processing page 13/23\n",
      "    Processing page 14/23\n",
      "    Processing page 15/23\n",
      "    Processing page 16/23\n",
      "    Processing page 17/23\n",
      "    Processing page 18/23\n",
      "    Processing page 19/23\n",
      "    Processing page 20/23\n",
      "    Processing page 21/23\n",
      "    Processing page 22/23\n",
      "    Processing page 23/23\n",
      "  OCR complete. Text saved to: 2507.20152.txt\n",
      "\n",
      "Processing paper 173/200: Multi-Agent Interactive Question Generation Framework for Long Document Understanding\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20145\n",
      "  Performing OCR on: 2507.20145.pdf\n",
      "    Processing page 1/6\n",
      "    Processing page 2/6\n",
      "    Processing page 3/6\n",
      "    Processing page 4/6\n",
      "    Processing page 5/6\n",
      "    Processing page 6/6\n",
      "  OCR complete. Text saved to: 2507.20145.txt\n",
      "\n",
      "Processing paper 174/200: Multi-Stage Verification-Centric Framework for Mitigating Hallucination in Multi-Modal RAG\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20136\n",
      "  Performing OCR on: 2507.20136.pdf\n",
      "    Processing page 1/8\n",
      "    Processing page 2/8\n",
      "    Processing page 3/8\n",
      "    Processing page 4/8\n",
      "    Processing page 5/8\n",
      "    Processing page 6/8\n",
      "    Processing page 7/8\n",
      "    Processing page 8/8\n",
      "  OCR complete. Text saved to: 2507.20136.txt\n",
      "\n",
      "Processing paper 175/200: Sem-DPO: Mitigating Semantic Inconsistency in Preference Optimization for Prompt Engineering\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20133\n",
      "  Performing OCR on: 2507.20133.pdf\n",
      "    Processing page 1/13\n",
      "    Processing page 2/13\n",
      "    Processing page 3/13\n",
      "    Processing page 4/13\n",
      "    Processing page 5/13\n",
      "    Processing page 6/13\n",
      "    Processing page 7/13\n",
      "    Processing page 8/13\n",
      "    Processing page 9/13\n",
      "    Processing page 10/13\n",
      "    Processing page 11/13\n",
      "    Processing page 12/13\n",
      "    Processing page 13/13\n",
      "  OCR complete. Text saved to: 2507.20133.txt\n",
      "\n",
      "Processing paper 176/200: AI-Driven Generation of Old English: A Framework for Low-Resource Languages\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20111\n",
      "  Performing OCR on: 2507.20111.pdf\n",
      "    Processing page 1/10\n",
      "    Processing page 2/10\n",
      "    Processing page 3/10\n",
      "    Processing page 4/10\n",
      "    Processing page 5/10\n",
      "    Processing page 6/10\n",
      "    Processing page 7/10\n",
      "    Processing page 8/10\n",
      "    Processing page 9/10\n",
      "    Processing page 10/10\n",
      "  OCR complete. Text saved to: 2507.20111.txt\n",
      "\n",
      "Processing paper 177/200: ProsodyLM: Uncovering the Emerging Prosody Processing Capabilities in Speech Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20091\n",
      "  Performing OCR on: 2507.20091.pdf\n",
      "    Processing page 1/24\n",
      "    Processing page 2/24\n",
      "    Processing page 3/24\n",
      "    Processing page 4/24\n",
      "    Processing page 5/24\n",
      "    Processing page 6/24\n",
      "    Processing page 7/24\n",
      "    Processing page 8/24\n",
      "    Processing page 9/24\n",
      "    Processing page 10/24\n",
      "    Processing page 11/24\n",
      "    Processing page 12/24\n",
      "    Processing page 13/24\n",
      "    Processing page 14/24\n",
      "    Processing page 15/24\n",
      "    Processing page 16/24\n",
      "    Processing page 17/24\n",
      "    Processing page 18/24\n",
      "    Processing page 19/24\n",
      "    Processing page 20/24\n",
      "    Processing page 21/24\n",
      "    Processing page 22/24\n",
      "    Processing page 23/24\n",
      "    Processing page 24/24\n",
      "  OCR complete. Text saved to: 2507.20091.txt\n",
      "\n",
      "Processing paper 178/200: RAG in the Wild: On the (In)effectiveness of LLMs with Mixture-of-Knowledge Retrieval Augmentation\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20059\n",
      "  Performing OCR on: 2507.20059.pdf\n",
      "    Processing page 1/14\n",
      "    Processing page 2/14\n",
      "    Processing page 3/14\n",
      "    Processing page 4/14\n",
      "    Processing page 5/14\n",
      "    Processing page 6/14\n",
      "    Processing page 7/14\n",
      "    Processing page 8/14\n",
      "    Processing page 9/14\n",
      "    Processing page 10/14\n",
      "    Processing page 11/14\n",
      "    Processing page 12/14\n",
      "    Processing page 13/14\n",
      "    Processing page 14/14\n",
      "  OCR complete. Text saved to: 2507.20059.txt\n",
      "\n",
      "Processing paper 179/200: A Tensor-Based Compiler and a Runtime for Neuron-Level DNN Certifier Specifications\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20055\n",
      "  Performing OCR on: 2507.20055.pdf\n",
      "    Processing page 1/52\n",
      "    Processing page 2/52\n",
      "    Processing page 3/52\n",
      "    Processing page 4/52\n",
      "    Processing page 5/52\n",
      "    Processing page 6/52\n",
      "    Processing page 7/52\n",
      "    Processing page 8/52\n",
      "    Processing page 9/52\n",
      "    Processing page 10/52\n",
      "    Processing page 11/52\n",
      "    Processing page 12/52\n",
      "    Processing page 13/52\n",
      "    Processing page 14/52\n",
      "    Processing page 15/52\n",
      "    Processing page 16/52\n",
      "    Processing page 17/52\n",
      "    Processing page 18/52\n",
      "    Processing page 19/52\n",
      "    Processing page 20/52\n",
      "    Processing page 21/52\n",
      "    Processing page 22/52\n",
      "    Processing page 23/52\n",
      "    Processing page 24/52\n",
      "    Processing page 25/52\n",
      "    Processing page 26/52\n",
      "    Processing page 27/52\n",
      "    Processing page 28/52\n",
      "    Processing page 29/52\n",
      "    Processing page 30/52\n",
      "    Processing page 31/52\n",
      "    Processing page 32/52\n",
      "    Processing page 33/52\n",
      "    Processing page 34/52\n",
      "    Processing page 35/52\n",
      "    Processing page 36/52\n",
      "    Processing page 37/52\n",
      "    Processing page 38/52\n",
      "    Processing page 39/52\n",
      "    Processing page 40/52\n",
      "    Processing page 41/52\n",
      "    Processing page 42/52\n",
      "    Processing page 43/52\n",
      "    Processing page 44/52\n",
      "    Processing page 45/52\n",
      "    Processing page 46/52\n",
      "    Processing page 47/52\n",
      "    Processing page 48/52\n",
      "    Processing page 49/52\n",
      "    Processing page 50/52\n",
      "    Processing page 51/52\n",
      "    Processing page 52/52\n",
      "  OCR complete. Text saved to: 2507.20055.txt\n",
      "\n",
      "Processing paper 180/200: Infogen: Generating Complex Statistical Infographics from Documents\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20046\n",
      "  Performing OCR on: 2507.20046.pdf\n",
      "    Processing page 1/19\n",
      "    Processing page 2/19\n",
      "    Processing page 3/19\n",
      "    Processing page 4/19\n",
      "    Processing page 5/19\n",
      "    Processing page 6/19\n",
      "    Processing page 7/19\n",
      "    Processing page 8/19\n",
      "    Processing page 9/19\n",
      "    Processing page 10/19\n",
      "    Processing page 11/19\n",
      "    Processing page 12/19\n",
      "    Processing page 13/19\n",
      "    Processing page 14/19\n",
      "    Processing page 15/19\n",
      "    Processing page 16/19\n",
      "    Processing page 17/19\n",
      "    Processing page 18/19\n",
      "    Processing page 19/19\n",
      "  OCR complete. Text saved to: 2507.20046.txt\n",
      "\n",
      "Processing paper 181/200: FAEDKV: Infinite-Window Fourier Transform for Unbiased KV Cache Compression\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20030\n",
      "  Performing OCR on: 2507.20030.pdf\n",
      "    Processing page 1/11\n",
      "    Processing page 2/11\n",
      "    Processing page 3/11\n",
      "    Processing page 4/11\n",
      "    Processing page 5/11\n",
      "    Processing page 6/11\n",
      "    Processing page 7/11\n",
      "    Processing page 8/11\n",
      "    Processing page 9/11\n",
      "    Processing page 10/11\n",
      "    Processing page 11/11\n",
      "  OCR complete. Text saved to: 2507.20030.txt\n",
      "\n",
      "Processing paper 182/200: Anomaly Detection in Human Language via Meta-Learning: A Few-Shot Approach\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.20019\n",
      "  Performing OCR on: 2507.20019.pdf\n",
      "    Processing page 1/35\n",
      "    Processing page 2/35\n",
      "    Processing page 3/35\n",
      "    Processing page 4/35\n",
      "    Processing page 5/35\n",
      "    Processing page 6/35\n",
      "    Processing page 7/35\n",
      "    Processing page 8/35\n",
      "    Processing page 9/35\n",
      "    Processing page 10/35\n",
      "    Processing page 11/35\n",
      "    Processing page 12/35\n",
      "    Processing page 13/35\n",
      "    Processing page 14/35\n",
      "    Processing page 15/35\n",
      "    Processing page 16/35\n",
      "    Processing page 17/35\n",
      "    Processing page 18/35\n",
      "    Processing page 19/35\n",
      "    Processing page 20/35\n",
      "    Processing page 21/35\n",
      "    Processing page 22/35\n",
      "    Processing page 23/35\n",
      "    Processing page 24/35\n",
      "    Processing page 25/35\n",
      "    Processing page 26/35\n",
      "    Processing page 27/35\n",
      "    Processing page 28/35\n",
      "    Processing page 29/35\n",
      "    Processing page 30/35\n",
      "    Processing page 31/35\n",
      "    Processing page 32/35\n",
      "    Processing page 33/35\n",
      "    Processing page 34/35\n",
      "    Processing page 35/35\n",
      "  OCR complete. Text saved to: 2507.20019.txt\n",
      "\n",
      "Processing paper 183/200: VLQA: The First Comprehensive, Large, and High-Quality Vietnamese Dataset for Legal Question Answering\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.19995\n",
      "  Performing OCR on: 2507.19995.pdf\n",
      "    Processing page 1/26\n",
      "    Processing page 2/26\n",
      "    Processing page 3/26\n",
      "    Processing page 4/26\n",
      "    Processing page 5/26\n",
      "    Processing page 6/26\n",
      "    Processing page 7/26\n",
      "    Processing page 8/26\n",
      "    Processing page 9/26\n",
      "    Processing page 10/26\n",
      "    Processing page 11/26\n",
      "    Processing page 12/26\n",
      "    Processing page 13/26\n",
      "    Processing page 14/26\n",
      "    Processing page 15/26\n",
      "    Processing page 16/26\n",
      "    Processing page 17/26\n",
      "    Processing page 18/26\n",
      "    Processing page 19/26\n",
      "    Processing page 20/26\n",
      "    Processing page 21/26\n",
      "    Processing page 22/26\n",
      "    Processing page 23/26\n",
      "    Processing page 24/26\n",
      "    Processing page 25/26\n",
      "    Processing page 26/26\n",
      "  OCR complete. Text saved to: 2507.19995.txt\n",
      "\n",
      "Processing paper 184/200: Exploring LLM Autoscoring Reliability in Large-Scale Writing Assessments Using Generalizability Theory\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.19980\n",
      "  Performing OCR on: 2507.19980.pdf\n",
      "    Processing page 1/38\n",
      "    Processing page 2/38\n",
      "    Processing page 3/38\n",
      "    Processing page 4/38\n",
      "    Processing page 5/38\n",
      "    Processing page 6/38\n",
      "    Processing page 7/38\n",
      "    Processing page 8/38\n",
      "    Processing page 9/38\n",
      "    Processing page 10/38\n",
      "    Processing page 11/38\n",
      "    Processing page 12/38\n",
      "    Processing page 13/38\n",
      "    Processing page 14/38\n",
      "    Processing page 15/38\n",
      "    Processing page 16/38\n",
      "    Processing page 17/38\n",
      "    Processing page 18/38\n",
      "    Processing page 19/38\n",
      "    Processing page 20/38\n",
      "    Processing page 21/38\n",
      "    Processing page 22/38\n",
      "    Processing page 23/38\n",
      "    Processing page 24/38\n",
      "    Processing page 25/38\n",
      "    Processing page 26/38\n",
      "    Processing page 27/38\n",
      "    Processing page 28/38\n",
      "    Processing page 29/38\n",
      "    Processing page 30/38\n",
      "    Processing page 31/38\n",
      "    Processing page 32/38\n",
      "    Processing page 33/38\n",
      "    Processing page 34/38\n",
      "    Processing page 35/38\n",
      "    Processing page 36/38\n",
      "    Processing page 37/38\n",
      "    Processing page 38/38\n",
      "  OCR complete. Text saved to: 2507.19980.txt\n",
      "\n",
      "Processing paper 185/200: Text2Vis: A Challenging and Diverse Benchmark for Generating Multimodal Visualizations from Text\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.19969\n",
      "  Performing OCR on: 2507.19969.pdf\n",
      "    Processing page 1/25\n",
      "    Processing page 2/25\n",
      "    Processing page 3/25\n",
      "    Processing page 4/25\n",
      "    Processing page 5/25\n",
      "    Processing page 6/25\n",
      "    Processing page 7/25\n",
      "    Processing page 8/25\n",
      "    Processing page 9/25\n",
      "    Processing page 10/25\n",
      "    Processing page 11/25\n",
      "    Processing page 12/25\n",
      "    Processing page 13/25\n",
      "    Processing page 14/25\n",
      "    Processing page 15/25\n",
      "    Processing page 16/25\n",
      "    Processing page 17/25\n",
      "    Processing page 18/25\n",
      "    Processing page 19/25\n",
      "    Processing page 20/25\n",
      "    Processing page 21/25\n",
      "    Processing page 22/25\n",
      "    Processing page 23/25\n",
      "    Processing page 24/25\n",
      "    Processing page 25/25\n",
      "  OCR complete. Text saved to: 2507.19969.txt\n",
      "\n",
      "Processing paper 186/200: KLAAD: Refining Attention Mechanisms to Reduce Societal Bias in Generative Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.19962\n",
      "  Performing OCR on: 2507.19962.pdf\n",
      "    Processing page 1/22\n",
      "    Processing page 2/22\n",
      "    Processing page 3/22\n",
      "    Processing page 4/22\n",
      "    Processing page 5/22\n",
      "    Processing page 6/22\n",
      "    Processing page 7/22\n",
      "    Processing page 8/22\n",
      "    Processing page 9/22\n",
      "    Processing page 10/22\n",
      "    Processing page 11/22\n",
      "    Processing page 12/22\n",
      "    Processing page 13/22\n",
      "    Processing page 14/22\n",
      "    Processing page 15/22\n",
      "    Processing page 16/22\n",
      "    Processing page 17/22\n",
      "    Processing page 18/22\n",
      "    Processing page 19/22\n",
      "    Processing page 20/22\n",
      "    Processing page 21/22\n",
      "    Processing page 22/22\n",
      "  OCR complete. Text saved to: 2507.19962.txt\n",
      "\n",
      "Processing paper 187/200: CaliDrop: KV Cache Compression with Calibration\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.19906\n",
      "  Performing OCR on: 2507.19906.pdf\n",
      "    Processing page 1/22\n",
      "    Processing page 2/22\n",
      "    Processing page 3/22\n",
      "    Processing page 4/22\n",
      "    Processing page 5/22\n",
      "    Processing page 6/22\n",
      "    Processing page 7/22\n",
      "    Processing page 8/22\n",
      "    Processing page 9/22\n",
      "    Processing page 10/22\n",
      "    Processing page 11/22\n",
      "    Processing page 12/22\n",
      "    Processing page 13/22\n",
      "    Processing page 14/22\n",
      "    Processing page 15/22\n",
      "    Processing page 16/22\n",
      "    Processing page 17/22\n",
      "    Processing page 18/22\n",
      "    Processing page 19/22\n",
      "    Processing page 20/22\n",
      "    Processing page 21/22\n",
      "    Processing page 22/22\n",
      "  OCR complete. Text saved to: 2507.19906.txt\n",
      "\n",
      "Processing paper 188/200: A Gold Standard Dataset and Evaluation Framework for Depression Detection and Explanation in Social Media using LLMs\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.19899\n",
      "  Performing OCR on: 2507.19899.pdf\n",
      "    Processing page 1/14\n",
      "    Processing page 2/14\n",
      "    Processing page 3/14\n",
      "    Processing page 4/14\n",
      "    Processing page 5/14\n",
      "    Processing page 6/14\n",
      "    Processing page 7/14\n",
      "    Processing page 8/14\n",
      "    Processing page 9/14\n",
      "    Processing page 10/14\n",
      "    Processing page 11/14\n",
      "    Processing page 12/14\n",
      "    Processing page 13/14\n",
      "    Processing page 14/14\n",
      "  OCR complete. Text saved to: 2507.19899.txt\n",
      "\n",
      "Processing paper 189/200: Zero-shot Performance of Generative AI in Brazilian Portuguese Medical Exam\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.19885\n",
      "  Performing OCR on: 2507.19885.pdf\n",
      "    Processing page 1/26\n",
      "    Processing page 2/26\n",
      "    Processing page 3/26\n",
      "    Processing page 4/26\n",
      "    Processing page 5/26\n",
      "    Processing page 6/26\n",
      "    Processing page 7/26\n",
      "    Processing page 8/26\n",
      "    Processing page 9/26\n",
      "    Processing page 10/26\n",
      "    Processing page 11/26\n",
      "    Processing page 12/26\n",
      "    Processing page 13/26\n",
      "    Processing page 14/26\n",
      "    Processing page 15/26\n",
      "    Processing page 16/26\n",
      "    Processing page 17/26\n",
      "    Processing page 18/26\n",
      "    Processing page 19/26\n",
      "    Processing page 20/26\n",
      "    Processing page 21/26\n",
      "    Processing page 22/26\n",
      "    Processing page 23/26\n",
      "    Processing page 24/26\n",
      "    Processing page 25/26\n",
      "    Processing page 26/26\n",
      "  OCR complete. Text saved to: 2507.19885.txt\n",
      "\n",
      "Processing paper 190/200: The Polish Vocabulary Size Test: A Novel Adaptive Test for Receptive Vocabulary Assessment\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.19869\n",
      "  Performing OCR on: 2507.19869.pdf\n",
      "    Processing page 1/29\n",
      "    Processing page 2/29\n",
      "    Processing page 3/29\n",
      "    Processing page 4/29\n",
      "    Processing page 5/29\n",
      "    Processing page 6/29\n",
      "    Processing page 7/29\n",
      "    Processing page 8/29\n",
      "    Processing page 9/29\n",
      "    Processing page 10/29\n",
      "    Processing page 11/29\n",
      "    Processing page 12/29\n",
      "    Processing page 13/29\n",
      "    Processing page 14/29\n",
      "    Processing page 15/29\n",
      "    Processing page 16/29\n",
      "    Processing page 17/29\n",
      "    Processing page 18/29\n",
      "    Processing page 19/29\n",
      "    Processing page 20/29\n",
      "    Processing page 21/29\n",
      "    Processing page 22/29\n",
      "    Processing page 23/29\n",
      "    Processing page 24/29\n",
      "    Processing page 25/29\n",
      "    Processing page 26/29\n",
      "    Processing page 27/29\n",
      "    Processing page 28/29\n",
      "    Processing page 29/29\n",
      "  OCR complete. Text saved to: 2507.19869.txt\n",
      "\n",
      "Processing paper 191/200: DRIVE: Disfluency-Rich Synthetic Dialog Data Generation Framework for Intelligent Vehicle Environments\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.19867\n",
      "  Performing OCR on: 2507.19867.pdf\n",
      "    Processing page 1/18\n",
      "    Processing page 2/18\n",
      "    Processing page 3/18\n",
      "    Processing page 4/18\n",
      "    Processing page 5/18\n",
      "    Processing page 6/18\n",
      "    Processing page 7/18\n",
      "    Processing page 8/18\n",
      "    Processing page 9/18\n",
      "    Processing page 10/18\n",
      "    Processing page 11/18\n",
      "    Processing page 12/18\n",
      "    Processing page 13/18\n",
      "    Processing page 14/18\n",
      "    Processing page 15/18\n",
      "    Processing page 16/18\n",
      "    Processing page 17/18\n",
      "    Processing page 18/18\n",
      "  OCR complete. Text saved to: 2507.19867.txt\n",
      "\n",
      "Processing paper 192/200: HCAttention: Extreme KV Cache Compression via Heterogeneous Attention Computing for LLMs\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.19823\n",
      "  Performing OCR on: 2507.19823.pdf\n",
      "    Processing page 1/14\n",
      "    Processing page 2/14\n",
      "    Processing page 3/14\n",
      "    Processing page 4/14\n",
      "    Processing page 5/14\n",
      "    Processing page 6/14\n",
      "    Processing page 7/14\n",
      "    Processing page 8/14\n",
      "    Processing page 9/14\n",
      "    Processing page 10/14\n",
      "    Processing page 11/14\n",
      "    Processing page 12/14\n",
      "    Processing page 13/14\n",
      "    Processing page 14/14\n",
      "  OCR complete. Text saved to: 2507.19823.txt\n",
      "\n",
      "Processing paper 193/200: Flora: Effortless Context Construction to Arbitrary Length and Scale\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.19786\n",
      "  Performing OCR on: 2507.19786.pdf\n",
      "    Processing page 1/13\n",
      "    Processing page 2/13\n",
      "    Processing page 3/13\n",
      "    Processing page 4/13\n",
      "    Processing page 5/13\n",
      "    Processing page 6/13\n",
      "    Processing page 7/13\n",
      "    Processing page 8/13\n",
      "    Processing page 9/13\n",
      "    Processing page 10/13\n",
      "    Processing page 11/13\n",
      "    Processing page 12/13\n",
      "    Processing page 13/13\n",
      "  OCR complete. Text saved to: 2507.19786.txt\n",
      "\n",
      "Processing paper 194/200: UloRL:An Ultra-Long Output Reinforcement Learning Approach for Advancing Large Language Models' Reasoning Abilities\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.19766\n",
      "  Performing OCR on: 2507.19766.pdf\n",
      "    Processing page 1/12\n",
      "    Processing page 2/12\n",
      "    Processing page 3/12\n",
      "    Processing page 4/12\n",
      "    Processing page 5/12\n",
      "    Processing page 6/12\n",
      "    Processing page 7/12\n",
      "    Processing page 8/12\n",
      "    Processing page 9/12\n",
      "    Processing page 10/12\n",
      "    Processing page 11/12\n",
      "    Processing page 12/12\n",
      "  OCR complete. Text saved to: 2507.19766.txt\n",
      "\n",
      "Processing paper 195/200: Are You There God? Lightweight Narrative Annotation of Christian Fiction with LMs\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.19756\n",
      "  Performing OCR on: 2507.19756.pdf\n",
      "    Processing page 1/23\n",
      "    Processing page 2/23\n",
      "    Processing page 3/23\n",
      "    Processing page 4/23\n",
      "    Processing page 5/23\n",
      "    Processing page 6/23\n",
      "    Processing page 7/23\n",
      "    Processing page 8/23\n",
      "    Processing page 9/23\n",
      "    Processing page 10/23\n",
      "    Processing page 11/23\n",
      "    Processing page 12/23\n",
      "    Processing page 13/23\n",
      "    Processing page 14/23\n",
      "    Processing page 15/23\n",
      "    Processing page 16/23\n",
      "    Processing page 17/23\n",
      "    Processing page 18/23\n",
      "    Processing page 19/23\n",
      "    Processing page 20/23\n",
      "    Processing page 21/23\n",
      "    Processing page 22/23\n",
      "    Processing page 23/23\n",
      "  OCR complete. Text saved to: 2507.19756.txt\n",
      "\n",
      "Processing paper 196/200: JT-Math: A Multi-Stage Framework for Advanced Mathematical Reasoning in Large Language Models\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.19748\n",
      "  Performing OCR on: 2507.19748.pdf\n",
      "    Processing page 1/18\n",
      "    Processing page 2/18\n",
      "    Processing page 3/18\n",
      "    Processing page 4/18\n",
      "    Processing page 5/18\n",
      "    Processing page 6/18\n",
      "    Processing page 7/18\n",
      "    Processing page 8/18\n",
      "    Processing page 9/18\n",
      "    Processing page 10/18\n",
      "    Processing page 11/18\n",
      "    Processing page 12/18\n",
      "    Processing page 13/18\n",
      "    Processing page 14/18\n",
      "    Processing page 15/18\n",
      "    Processing page 16/18\n",
      "    Processing page 17/18\n",
      "    Processing page 18/18\n",
      "  OCR complete. Text saved to: 2507.19748.txt\n",
      "\n",
      "Processing paper 197/200: Basic Reading Distillation\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.19741\n",
      "  Performing OCR on: 2507.19741.pdf\n",
      "    Processing page 1/14\n",
      "    Processing page 2/14\n",
      "    Processing page 3/14\n",
      "    Processing page 4/14\n",
      "    Processing page 5/14\n",
      "    Processing page 6/14\n",
      "    Processing page 7/14\n",
      "    Processing page 8/14\n",
      "    Processing page 9/14\n",
      "    Processing page 10/14\n",
      "    Processing page 11/14\n",
      "    Processing page 12/14\n",
      "    Processing page 13/14\n",
      "    Processing page 14/14\n",
      "  OCR complete. Text saved to: 2507.19741.txt\n",
      "\n",
      "Processing paper 198/200: Ta-G-T: Subjectivity Capture in Table to Text Generation via RDF Graphs\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.19710\n",
      "  Performing OCR on: 2507.19710.pdf\n",
      "    Processing page 1/13\n",
      "    Processing page 2/13\n",
      "    Processing page 3/13\n",
      "    Processing page 4/13\n",
      "    Processing page 5/13\n",
      "    Processing page 6/13\n",
      "    Processing page 7/13\n",
      "    Processing page 8/13\n",
      "    Processing page 9/13\n",
      "    Processing page 10/13\n",
      "    Processing page 11/13\n",
      "    Processing page 12/13\n",
      "    Processing page 13/13\n",
      "  OCR complete. Text saved to: 2507.19710.txt\n",
      "\n",
      "Processing paper 199/200: Towards Inclusive NLP: Assessing Compressed Multilingual Transformers across Diverse Language Benchmarks\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.19699\n",
      "  Performing OCR on: 2507.19699.pdf\n",
      "    Processing page 1/17\n",
      "    Processing page 2/17\n",
      "    Processing page 3/17\n",
      "    Processing page 4/17\n",
      "    Processing page 5/17\n",
      "    Processing page 6/17\n",
      "    Processing page 7/17\n",
      "    Processing page 8/17\n",
      "    Processing page 9/17\n",
      "    Processing page 10/17\n",
      "    Processing page 11/17\n",
      "    Processing page 12/17\n",
      "    Processing page 13/17\n",
      "    Processing page 14/17\n",
      "    Processing page 15/17\n",
      "    Processing page 16/17\n",
      "    Processing page 17/17\n",
      "  OCR complete. Text saved to: 2507.19699.txt\n",
      "\n",
      "Processing paper 200/200: RoD-TAL: A Benchmark for Answering Questions in Romanian Driving License Exams\n",
      "  Downloading PDF: https://arxiv.org/pdf/2507.19666\n",
      "  Performing OCR on: 2507.19666.pdf\n",
      "    Processing page 1/49\n",
      "    Processing page 2/49\n",
      "    Processing page 3/49\n",
      "    Processing page 4/49\n",
      "    Processing page 5/49\n",
      "    Processing page 6/49\n",
      "    Processing page 7/49\n",
      "    Processing page 8/49\n",
      "    Processing page 9/49\n",
      "    Processing page 10/49\n",
      "    Processing page 11/49\n",
      "    Processing page 12/49\n",
      "    Processing page 13/49\n",
      "    Processing page 14/49\n",
      "    Processing page 15/49\n",
      "    Processing page 16/49\n",
      "    Processing page 17/49\n",
      "    Processing page 18/49\n",
      "    Processing page 19/49\n",
      "    Processing page 20/49\n",
      "    Processing page 21/49\n",
      "    Processing page 22/49\n",
      "    Processing page 23/49\n",
      "    Processing page 24/49\n",
      "    Processing page 25/49\n",
      "    Processing page 26/49\n",
      "    Processing page 27/49\n",
      "    Processing page 28/49\n",
      "    Processing page 29/49\n",
      "    Processing page 30/49\n",
      "    Processing page 31/49\n",
      "    Processing page 32/49\n",
      "    Processing page 33/49\n",
      "    Processing page 34/49\n",
      "    Processing page 35/49\n",
      "    Processing page 36/49\n",
      "    Processing page 37/49\n",
      "    Processing page 38/49\n",
      "    Processing page 39/49\n",
      "    Processing page 40/49\n",
      "    Processing page 41/49\n",
      "    Processing page 42/49\n",
      "    Processing page 43/49\n",
      "    Processing page 44/49\n",
      "    Processing page 45/49\n",
      "    Processing page 46/49\n",
      "    Processing page 47/49\n",
      "    Processing page 48/49\n",
      "    Processing page 49/49\n",
      "  OCR complete. Text saved to: 2507.19666.txt\n",
      "\n",
      "Batch OCR process finished. Successfully OCR'd/processed 200 new PDFs.\n",
      "PDFs are in: C:\\Users\\ch939\\Downloads\\LLMBootCampCodes\\arxiv_pdfs\n",
      "OCR'd text files are in: C:\\Users\\ch939\\Downloads\\LLMBootCampCodes\\pdf_ocr\n",
      "\n",
      "Remember to install Poppler for pdf2image if on Windows/Linux and Tesseract OCR for pytesseract.\n",
      "Example Poppler installation (Windows): Download from https://github.com/oschwartz10612/poppler-windows/releases\n",
      "  Then add the 'bin' folder to your system PATH or specify in convert_from_path(pdf_path, poppler_path='path_to_bin')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "import time\n",
    "\n",
    "# --- Configuration ---\n",
    "# Set the path to the Tesseract executable if it's not in your PATH\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/tesseract' # Example for macOS\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' # Example for Windows\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# --- Constants ---\n",
    "# Directory to save downloaded PDFs\n",
    "PDF_DOWNLOAD_DIR = \"arxiv_pdfs\"\n",
    "# Directory to save OCR'd text files\n",
    "OCR_OUTPUT_DIR = \"pdf_ocr\"\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(PDF_DOWNLOAD_DIR, exist_ok=True)\n",
    "os.makedirs(OCR_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def download_pdf(pdf_url, filename):\n",
    "    \"\"\"Downloads a PDF from a given URL.\"\"\"\n",
    "    filepath = os.path.join(PDF_DOWNLOAD_DIR, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"  PDF already exists: {filename}\")\n",
    "        return filepath\n",
    "\n",
    "    print(f\"  Downloading PDF: {pdf_url}\")\n",
    "    try:\n",
    "        response = requests.get(pdf_url, headers=HEADERS, stream=True, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        with open(filepath, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        return filepath\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"  Error downloading {pdf_url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def ocr_pdf_to_text(pdf_path, output_filepath):\n",
    "    \"\"\"\n",
    "    Converts a PDF to text using Tesseract OCR.\n",
    "    Retains layout by performing OCR page by page.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"  PDF file not found for OCR: {pdf_path}\")\n",
    "        return False\n",
    "\n",
    "    print(f\"  Performing OCR on: {os.path.basename(pdf_path)}\")\n",
    "    try:\n",
    "        # Convert PDF pages to list of PIL images\n",
    "        # poppler_path might be needed on Windows.\n",
    "        # Example: poppler_path=r'C:\\Program Files\\poppler-23.08.0\\Library\\bin'\n",
    "        pages = convert_from_path(pdf_path, 300) # 300 DPI for better OCR accuracy\n",
    "\n",
    "        full_text = []\n",
    "        for i, page_image in enumerate(pages):\n",
    "            print(f\"    Processing page {i+1}/{len(pages)}\")\n",
    "            # Use image_to_string with output_type='text' for plain text\n",
    "            # and lang='eng' for English.\n",
    "            # config='--psm 1' might help with layout retention, 1 for OSD, 3 for default.\n",
    "            # For general document layout, PSM 6 or 3 are usually good.\n",
    "            # If layout retention is crucial, you might need to try different PSMs.\n",
    "            # Here, we'll try a common one for general documents.\n",
    "            text = pytesseract.image_to_string(page_image, lang='eng', config='--psm 3')\n",
    "            full_text.append(text)\n",
    "            time.sleep(0.1) # Small delay between pages\n",
    "\n",
    "        with open(output_filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"\\n\".join(full_text))\n",
    "\n",
    "        print(f\"  OCR complete. Text saved to: {os.path.basename(output_filepath)}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"  Error during OCR for {pdf_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- Main OCR Process ---\n",
    "\n",
    "def batch_ocr_arxiv_pdfs(json_filepath=\"arxiv_clean.json\"):\n",
    "    \"\"\"\n",
    "    Reads the arxiv_clean.json, downloads associated PDFs, and performs OCR.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(json_filepath):\n",
    "        print(f\"Error: {json_filepath} not found. Please run Module 1 first.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loading paper data from: {json_filepath}\")\n",
    "    try:\n",
    "        with open(json_filepath, 'r', encoding='utf-8') as f:\n",
    "            papers = json.load(f)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON from {json_filepath}: {e}\")\n",
    "        return\n",
    "\n",
    "    if not papers:\n",
    "        print(\"No papers found in the JSON file to process.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(papers)} papers to process for PDF OCR.\")\n",
    "\n",
    "    processed_count = 0\n",
    "    for i, paper in enumerate(papers):\n",
    "        paper_url = paper.get('url')\n",
    "        if not paper_url:\n",
    "            print(f\"Skipping paper {i+1}: No URL found.\")\n",
    "            continue\n",
    "\n",
    "        # Construct PDF URL: replace '/abs/' with '/pdf/'\n",
    "        pdf_url = paper_url.replace('/abs/', '/pdf/')\n",
    "        \n",
    "        # Extract paper ID to use as filename\n",
    "        paper_id = paper_url.split('/')[-1]\n",
    "        pdf_filename = f\"{paper_id}.pdf\"\n",
    "        txt_filename = f\"{paper_id}.txt\"\n",
    "        \n",
    "        pdf_filepath = os.path.join(PDF_DOWNLOAD_DIR, pdf_filename)\n",
    "        txt_filepath = os.path.join(OCR_OUTPUT_DIR, txt_filename)\n",
    "\n",
    "        print(f\"\\nProcessing paper {i+1}/{len(papers)}: {paper['title']}\")\n",
    "\n",
    "        # Step 1: Download PDF\n",
    "        downloaded_path = download_pdf(pdf_url, pdf_filename)\n",
    "        if not downloaded_path:\n",
    "            print(f\"  Failed to download PDF for {paper['title']}. Skipping OCR.\")\n",
    "            continue\n",
    "\n",
    "        # Step 2: Perform OCR if the text file doesn't already exist\n",
    "        if os.path.exists(txt_filepath) and os.path.getsize(txt_filepath) > 0:\n",
    "            print(f\"  OCR text file already exists and is not empty: {txt_filename}. Skipping OCR.\")\n",
    "        else:\n",
    "            ocr_success = ocr_pdf_to_text(downloaded_path, txt_filepath)\n",
    "            if ocr_success:\n",
    "                processed_count += 1\n",
    "            else:\n",
    "                print(f\"  OCR failed for {paper['title']}.\")\n",
    "        \n",
    "        time.sleep(0.5) # Be polite to the servers\n",
    "\n",
    "    print(f\"\\nBatch OCR process finished. Successfully OCR'd/processed {processed_count} new PDFs.\")\n",
    "    print(f\"PDFs are in: {os.path.abspath(PDF_DOWNLOAD_DIR)}\")\n",
    "    print(f\"OCR'd text files are in: {os.path.abspath(OCR_OUTPUT_DIR)}\")\n",
    "\n",
    "# --- Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure you have run Module 1 and 'arxiv_clean.json' exists in the same directory\n",
    "    # or specify its path if it's elsewhere.\n",
    "    batch_ocr_arxiv_pdfs(\"arxiv_clean.json\")\n",
    "\n",
    "    print(\"\\nRemember to install Poppler for pdf2image if on Windows/Linux and Tesseract OCR for pytesseract.\")\n",
    "    print(\"Example Poppler installation (Windows): Download from https://github.com/oschwartz10612/poppler-windows/releases\")\n",
    "    print(\"  Then add the 'bin' folder to your system PATH or specify in convert_from_path(pdf_path, poppler_path='path_to_bin')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Implement in Python Jupyter Notebook\n",
    "Module 3: Automatic Speech Recognition (ASR)\n",
    "Task Goal:\n",
    "Whisper Transcription Bot for 10 short NLP conference talks (~3 minutes each).\n",
    "‚Ä¢ Use yt dl to fetch YouTube audio.\n",
    "‚Ä¢ Transcribe with Tesseract for any OCR-based text in the transcript images.\n",
    "‚Ä¢ Save .jsonl with timestamps.\n",
    "Core Tools:\n",
    "yt-dlp, pytesseract\n",
    "Deliverables: \n",
    "talks_transcripts.jsonl + transcription script\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 3: Automatic Speech Recognition (ASR) - Conceptual Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task Goal:__ Whisper Transcription Bot for 10 short NLP conference talks (~3 minutes each).\n",
    "\n",
    "* Use yt-dl to fetch YouTube audio.\r\n",
    "* Transcribe with Tesseract for any OCR-based text in the transcript images.\r\n",
    "* Save .jsonl with timestamps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Core Tools:__\r\n",
    "yt-dlp, pytesserac\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Deliverables:__ talks_transcripts.jsonl + transcription script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jsonlines\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from jsonlines) (24.3.0)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Installing collected packages: jsonlines\n",
      "Successfully installed jsonlines-4.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Whisper Transcription Bot...\n",
      "\n",
      "Processing talk 1/10: NLP Talk 01 (https://www.youtube.com/watch?v=iXMh5_3IXww)\n",
      "  [EXTERNAL STEP] Downloading audio for https://www.youtube.com/watch?v=iXMh5_3IXww using yt-dlp...\n",
      "  Command example: yt-dlp -x --audio-format mp3 -o 'conference_talk_audio/%(title)s.%(ext)s' https://www.youtube.com/watch?v=iXMh5_3IXww\n",
      "  [ASR STEP] Transcribing audio file: conference_talk_audio\\iXMh5_3IXww.mp3 with Whisper...\n",
      "\n",
      "Processing talk 2/10: NLP Talk 02 (https://www.youtube.com/watch?v=HZyej-kFueA)\n",
      "  [EXTERNAL STEP] Downloading audio for https://www.youtube.com/watch?v=HZyej-kFueA using yt-dlp...\n",
      "  Command example: yt-dlp -x --audio-format mp3 -o 'conference_talk_audio/%(title)s.%(ext)s' https://www.youtube.com/watch?v=HZyej-kFueA\n",
      "  [ASR STEP] Transcribing audio file: conference_talk_audio\\HZyej-kFueA.mp3 with Whisper...\n",
      "\n",
      "Processing talk 3/10: NLP Talk 03 (https://www.youtube.com/watch?v=4BdcAGS1XRU)\n",
      "  [EXTERNAL STEP] Downloading audio for https://www.youtube.com/watch?v=4BdcAGS1XRU using yt-dlp...\n",
      "  Command example: yt-dlp -x --audio-format mp3 -o 'conference_talk_audio/%(title)s.%(ext)s' https://www.youtube.com/watch?v=4BdcAGS1XRU\n",
      "  [ASR STEP] Transcribing audio file: conference_talk_audio\\4BdcAGS1XRU.mp3 with Whisper...\n",
      "\n",
      "Processing talk 4/10: NLP Talk 04 (https://www.youtube.com/watch?v=Cr7NmDdB4_0)\n",
      "  [EXTERNAL STEP] Downloading audio for https://www.youtube.com/watch?v=Cr7NmDdB4_0 using yt-dlp...\n",
      "  Command example: yt-dlp -x --audio-format mp3 -o 'conference_talk_audio/%(title)s.%(ext)s' https://www.youtube.com/watch?v=Cr7NmDdB4_0\n",
      "  [ASR STEP] Transcribing audio file: conference_talk_audio\\Cr7NmDdB4_0.mp3 with Whisper...\n",
      "\n",
      "Processing talk 5/10: NLP Talk 05 (https://www.youtube.com/watch?v=6aFyaUZWDfs)\n",
      "  [EXTERNAL STEP] Downloading audio for https://www.youtube.com/watch?v=6aFyaUZWDfs using yt-dlp...\n",
      "  Command example: yt-dlp -x --audio-format mp3 -o 'conference_talk_audio/%(title)s.%(ext)s' https://www.youtube.com/watch?v=6aFyaUZWDfs\n",
      "  [ASR STEP] Transcribing audio file: conference_talk_audio\\6aFyaUZWDfs.mp3 with Whisper...\n",
      "\n",
      "Processing talk 6/10: NLP Talk 06 (https://www.youtube.com/watch?v=8rXEIQBhnwM)\n",
      "  [EXTERNAL STEP] Downloading audio for https://www.youtube.com/watch?v=8rXEIQBhnwM using yt-dlp...\n",
      "  Command example: yt-dlp -x --audio-format mp3 -o 'conference_talk_audio/%(title)s.%(ext)s' https://www.youtube.com/watch?v=8rXEIQBhnwM\n",
      "  [ASR STEP] Transcribing audio file: conference_talk_audio\\8rXEIQBhnwM.mp3 with Whisper...\n",
      "\n",
      "Processing talk 7/10: NLP Talk 07 (https://www.youtube.com/watch?v=5pBmF8-qK0Y)\n",
      "  [EXTERNAL STEP] Downloading audio for https://www.youtube.com/watch?v=5pBmF8-qK0Y using yt-dlp...\n",
      "  Command example: yt-dlp -x --audio-format mp3 -o 'conference_talk_audio/%(title)s.%(ext)s' https://www.youtube.com/watch?v=5pBmF8-qK0Y\n",
      "  [ASR STEP] Transcribing audio file: conference_talk_audio\\5pBmF8-qK0Y.mp3 with Whisper...\n",
      "\n",
      "Processing talk 8/10: NLP Talk 08 (https://www.youtube.com/watch?v=QEaYrGvGtFw)\n",
      "  [EXTERNAL STEP] Downloading audio for https://www.youtube.com/watch?v=QEaYrGvGtFw using yt-dlp...\n",
      "  Command example: yt-dlp -x --audio-format mp3 -o 'conference_talk_audio/%(title)s.%(ext)s' https://www.youtube.com/watch?v=QEaYrGvGtFw\n",
      "  [ASR STEP] Transcribing audio file: conference_talk_audio\\QEaYrGvGtFw.mp3 with Whisper...\n",
      "\n",
      "Processing talk 9/10: NLP Talk 09 (https://www.youtube.com/watch?v=IiYvOQZPxqg)\n",
      "  [EXTERNAL STEP] Downloading audio for https://www.youtube.com/watch?v=IiYvOQZPxqg using yt-dlp...\n",
      "  Command example: yt-dlp -x --audio-format mp3 -o 'conference_talk_audio/%(title)s.%(ext)s' https://www.youtube.com/watch?v=IiYvOQZPxqg\n",
      "  [ASR STEP] Transcribing audio file: conference_talk_audio\\IiYvOQZPxqg.mp3 with Whisper...\n",
      "\n",
      "Processing talk 10/10: NLP Talk 10 (https://www.youtube.com/watch?v=6Z3qGfZL1Y4)\n",
      "  [EXTERNAL STEP] Downloading audio for https://www.youtube.com/watch?v=6Z3qGfZL1Y4 using yt-dlp...\n",
      "  Command example: yt-dlp -x --audio-format mp3 -o 'conference_talk_audio/%(title)s.%(ext)s' https://www.youtube.com/watch?v=6Z3qGfZL1Y4\n",
      "  [ASR STEP] Transcribing audio file: conference_talk_audio\\6Z3qGfZL1Y4.mp3 with Whisper...\n",
      "\n",
      "Transcription process complete. Transcripts saved to: talks_transcripts.jsonl\n",
      "Total talks processed: 10\n",
      "\n",
      "--- Sample Transcribed Talk ---\n",
      "{'audio_file': 'iXMh5_3IXww.mp3',\n",
      " 'full_transcript': 'Hello, and welcome to this short talk on Natural Language '\n",
      "                    'Processing. Today, we will discuss the advancements in '\n",
      "                    \"large language models. Specifically, we'll look at their \"\n",
      "                    'impact on text generation.',\n",
      " 'segments': [{'end': 3.5,\n",
      "               'start': 0.0,\n",
      "               'text': 'Hello, and welcome to this short talk on Natural '\n",
      "                       'Language Processing.'},\n",
      "              {'end': 8.2,\n",
      "               'start': 4.0,\n",
      "               'text': 'Today, we will discuss the advancements in large '\n",
      "                       'language models.'},\n",
      "              {'end': 12.8,\n",
      "               'start': 9.0,\n",
      "               'text': \"Specifically, we'll look at their impact on text \"\n",
      "                       'generation.'}],\n",
      " 'title': 'NLP Talk 01',\n",
      " 'url': 'https://www.youtube.com/watch?v=iXMh5_3IXww'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import jsonlines\n",
    "import time\n",
    "# For actual ASR, you would typically use a library like 'openai-whisper'\n",
    "# import whisper\n",
    "# For PDF to Image conversion (not directly for ASR but relevant if video frames were images)\n",
    "# from PIL import Image\n",
    "# import pytesseract\n",
    "\n",
    "# --- Configuration ---\n",
    "# Set the path to the Tesseract executable if needed for OCR on images *within the video*\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/tesseract'\n",
    "\n",
    "AUDIO_DOWNLOAD_DIR = \"conference_talk_audio\"\n",
    "TRANSCRIPTS_OUTPUT_FILE = \"talks_transcripts.jsonl\"\n",
    "\n",
    "# Create directory for audio downloads\n",
    "os.makedirs(AUDIO_DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# List of YouTube video IDs or URLs for NLP conference talks\n",
    "# Replace these with actual short NLP conference talk URLs (around 3 minutes each)\n",
    "# NOTE: Ensure these are short for practical demonstration and download limits.\n",
    "# You would fetch these URLs manually or from a curated list.\n",
    "YOUTUBE_TALKS = [\n",
    "    {\"title\": \"NLP Talk 01\", \"url\": \"https://www.youtube.com/watch?v=iXMh5_3IXww\"},\n",
    "    {\"title\": \"NLP Talk 02\", \"url\": \"https://www.youtube.com/watch?v=HZyej-kFueA\"},\n",
    "    {\"title\": \"NLP Talk 03\", \"url\": \"https://www.youtube.com/watch?v=4BdcAGS1XRU\"},\n",
    "    {\"title\": \"NLP Talk 04\", \"url\": \"https://www.youtube.com/watch?v=Cr7NmDdB4_0\"},\n",
    "    {\"title\": \"NLP Talk 05\", \"url\": \"https://www.youtube.com/watch?v=6aFyaUZWDfs\"},\n",
    "    {\"title\": \"NLP Talk 06\", \"url\": \"https://www.youtube.com/watch?v=8rXEIQBhnwM\"},    \n",
    "    {\"title\": \"NLP Talk 07\", \"url\": \"https://www.youtube.com/watch?v=5pBmF8-qK0Y\"},\n",
    "    {\"title\": \"NLP Talk 08\", \"url\": \"https://www.youtube.com/watch?v=QEaYrGvGtFw\"},\n",
    "    {\"title\": \"NLP Talk 09\", \"url\": \"https://www.youtube.com/watch?v=IiYvOQZPxqg\"},\n",
    "    {\"title\": \"NLP Talk 10\", \"url\": \"https://www.youtube.com/watch?v=6Z3qGfZL1Y4\"},  \n",
    "    # Add 8 more relevant short NLP conference talk URLs here\n",
    "    # Example for a real (but longer) video if you want to test the full process locally:\n",
    "    # {\"title\": \"Attention is All You Need\", \"url\": \"https://www.youtube.com/watch?v=rBCJzF0Sxdg\"}\n",
    "]\n",
    "\n",
    "# --- Helper Functions (Conceptual/External) ---\n",
    "\n",
    "def download_audio_with_yt_dlp(youtube_url, output_path):\n",
    "    \"\"\"\n",
    "    CONCEPTUAL: This function represents an external call to yt-dlp.\n",
    "    It cannot be directly executed in this environment.\n",
    "    You would run this command in your terminal or via os.system()/subprocess.run()\n",
    "    if you have yt-dlp installed on your system.\n",
    "    \"\"\"\n",
    "    print(f\"  [EXTERNAL STEP] Downloading audio for {youtube_url} using yt-dlp...\")\n",
    "    print(f\"  Command example: yt-dlp -x --audio-format mp3 -o '{output_path}/%(title)s.%(ext)s' {youtube_url}\")\n",
    "    # Simulate success for demonstration\n",
    "    time.sleep(1)\n",
    "    # In a real scenario, check the return code of the subprocess call\n",
    "    # For this demo, let's assume it saves as 'video_id.mp3'\n",
    "    video_id = youtube_url.split('v=')[-1]\n",
    "    simulated_audio_file = os.path.join(output_path, f\"{video_id}.mp3\")\n",
    "    # Create a dummy file for demonstration purposes\n",
    "    with open(simulated_audio_file, 'w') as f:\n",
    "        f.write(\"dummy audio content\")\n",
    "    return simulated_audio_file # Return the path to the downloaded audio file\n",
    "\n",
    "def transcribe_audio_with_whisper(audio_file_path):\n",
    "    \"\"\"\n",
    "    CONCEPTUAL: This function represents using the OpenAI Whisper model for ASR.\n",
    "    Requires the 'openai-whisper' library and potentially downloading a model.\n",
    "    \"\"\"\n",
    "    print(f\"  [ASR STEP] Transcribing audio file: {audio_file_path} with Whisper...\")\n",
    "    # Load the Whisper model (e.g., 'base', 'small', 'medium', 'large')\n",
    "    # model = whisper.load_model(\"base\")\n",
    "    \n",
    "    # Transcribe the audio\n",
    "    # result = model.transcribe(audio_file_path, word_timestamps=True)\n",
    "    \n",
    "    # Simulate transcription result for demonstration\n",
    "    simulated_segments = [\n",
    "        {\"start\": 0.0, \"end\": 3.5, \"text\": \"Hello, and welcome to this short talk on Natural Language Processing.\"},\n",
    "        {\"start\": 4.0, \"end\": 8.2, \"text\": \"Today, we will discuss the advancements in large language models.\"},\n",
    "        {\"start\": 9.0, \"end\": 12.8, \"text\": \"Specifically, we'll look at their impact on text generation.\"}\n",
    "    ]\n",
    "    # In a real scenario, 'result' would contain the segments and their timestamps\n",
    "    return {\"segments\": simulated_segments, \"text\": \" \".join([s['text'] for s in simulated_segments])}\n",
    "\n",
    "# --- Main Transcription Bot Function ---\n",
    "\n",
    "def run_whisper_transcription_bot(youtube_talks_list):\n",
    "    \"\"\"\n",
    "    Orchestrates downloading audio and transcribing with Whisper.\n",
    "    \"\"\"\n",
    "    print(\"Starting Whisper Transcription Bot...\")\n",
    "    \n",
    "    processed_transcripts = []\n",
    "\n",
    "    with jsonlines.open(TRANSCRIPTS_OUTPUT_FILE, mode='w') as writer:\n",
    "        for i, talk_info in enumerate(youtube_talks_list):\n",
    "            title = talk_info['title']\n",
    "            url = talk_info['url']\n",
    "            \n",
    "            print(f\"\\nProcessing talk {i+1}/{len(youtube_talks_list)}: {title} ({url})\")\n",
    "            \n",
    "            # Use video ID as part of the filename for uniqueness\n",
    "            video_id = url.split('v=')[-1]\n",
    "            audio_output_file_base = os.path.join(AUDIO_DOWNLOAD_DIR, video_id)\n",
    "            \n",
    "            # Step 1: Download Audio\n",
    "            # In a real scenario, this would involve calling yt-dlp via subprocess\n",
    "            # Example: subprocess.run(['yt-dlp', '-x', '--audio-format', 'mp3', '-o', audio_output_file_base + '.%(ext)s', url], check=True)\n",
    "            # For this conceptual demo, we call the placeholder function\n",
    "            audio_file_path = download_audio_with_yt_dlp(url, AUDIO_DOWNLOAD_DIR)\n",
    "            \n",
    "            if not audio_file_path or not os.path.exists(audio_file_path):\n",
    "                print(f\"  Skipping {title}: Audio download failed or file not created.\")\n",
    "                continue\n",
    "\n",
    "            # Step 2: Transcribe Audio using Whisper\n",
    "            # This is where the actual Whisper model would be used\n",
    "            transcription_result = transcribe_audio_with_whisper(audio_file_path)\n",
    "            \n",
    "            # Step 3 (Optional, if needed): OCR on video frames (Not directly implemented here)\n",
    "            # This would be a separate, more complex step involving video processing\n",
    "            # to extract frames and then apply pytesseract.\n",
    "            # E.g., using OpenCV to read video frames.\n",
    "            # print(\"  [Optional] OCR on video frames not implemented in this demo.\")\n",
    "\n",
    "            # Prepare data for .jsonl\n",
    "            transcript_entry = {\n",
    "                \"title\": title,\n",
    "                \"url\": url,\n",
    "                \"audio_file\": os.path.basename(audio_file_path),\n",
    "                \"full_transcript\": transcription_result.get(\"text\", \"\"),\n",
    "                \"segments\": transcription_result.get(\"segments\", []) # List of {\"start\", \"end\", \"text\"}\n",
    "            }\n",
    "            processed_transcripts.append(transcript_entry)\n",
    "            writer.write(transcript_entry) # Write immediately to .jsonl\n",
    "\n",
    "            # Clean up audio file after processing to save space if desired\n",
    "            # os.remove(audio_file_path)\n",
    "            # print(f\"  Removed audio file: {os.path.basename(audio_file_path)}\")\n",
    "            \n",
    "            time.sleep(1) # Be polite / simulate processing time\n",
    "\n",
    "    print(f\"\\nTranscription process complete. Transcripts saved to: {TRANSCRIPTS_OUTPUT_FILE}\")\n",
    "    print(f\"Total talks processed: {len(processed_transcripts)}\")\n",
    "    \n",
    "    return processed_transcripts\n",
    "\n",
    "# --- Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- IMPORTANT LOCAL SETUP STEPS ---\n",
    "    # 1. Install yt-dlp: pip install yt-dlp (or download executable)\n",
    "    # 2. Install Whisper: pip install openai-whisper\n",
    "    # 3. Ensure ffmpeg is installed and in your system PATH (required by Whisper)\n",
    "    #    (Windows: download from ffmpeg.org, add bin to PATH; macOS: brew install ffmpeg)\n",
    "    # 4. Replace example YOUTUBE_TALKS URLs with actual short NLP conference talks.\n",
    "    #    It's crucial that these are short (around 3 minutes) for practical reasons.\n",
    "    # ---\n",
    "\n",
    "    # If you run this on your local machine, you'd replace the conceptual calls\n",
    "    # with actual subprocess calls for yt-dlp and direct Whisper model usage.\n",
    "\n",
    "    # Example of how to use this in a real environment:\n",
    "    # 1. Manually download audio using yt-dlp in your terminal:\n",
    "    #    `yt-dlp -x --audio-format mp3 -o 'conference_talk_audio/%(id)s.%(ext)s' https://www.youtube.com/watch?v=VIDEO_ID_HERE`\n",
    "    # 2. Then, modify this script to iterate through the downloaded audio files\n",
    "    #    and call `whisper.load_model(\"base\").transcribe(...)` on each.\n",
    "    \n",
    "    # For this Jupyter environment, we'll run the conceptual flow.\n",
    "    transcribed_data = run_whisper_transcription_bot(YOUTUBE_TALKS)\n",
    "\n",
    "    # Optional: Display a sample of the transcribed data\n",
    "    if transcribed_data:\n",
    "        print(\"\\n--- Sample Transcribed Talk ---\")\n",
    "        import pprint\n",
    "        pprint.pprint(transcribed_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 4: Data Cleaning & Deduplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task Goal:__ \n",
    "End to End Cleaner:\r\n",
    "* Merge the outputs from Tasks-1 3 into one dataset.\r\n",
    "* Steps: language detection ‚Üí strip HTML noise ‚Üí use MinHash for deduplication (similarity ‚â• 0.7) ‚Üí remove PII (emails, credit card numbers, phone numbers) ‚Üí remove repetitive n grams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Core Tools:__\r\n",
    "langdetect, datasketc\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Deliverables:__ \n",
    "clean_corpus.txt + stats.md (token count, removal percentage\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ---------- ----------------------------- 262.1/981.5 kB ? eta -:--:--\n",
      "     -------------------- ----------------- 524.3/981.5 kB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 981.5/981.5 kB 1.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting datasketch\n",
      "  Downloading datasketch-1.6.5-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\ch939\\anaconda3\\lib\\site-packages (2.32.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: trafilatura in c:\\users\\ch939\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\ch939\\anaconda3\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pillow in c:\\users\\ch939\\anaconda3\\lib\\site-packages (10.3.0)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\ch939\\anaconda3\\lib\\site-packages (1.17.0)\n",
      "Collecting openai-whisper\n",
      "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
      "     ---------------------------------------- 0.0/803.2 kB ? eta -:--:--\n",
      "     ------------- -------------------------- 262.1/803.2 kB ? eta -:--:--\n",
      "     ------------------------ ------------- 524.3/803.2 kB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 803.2/803.2 kB 1.9 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: jsonlines in c:\\users\\ch939\\anaconda3\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: six in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from datasketch) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from datasketch) (1.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: courlan>=1.3.2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from trafilatura) (1.3.2)\n",
      "Requirement already satisfied: htmldate>=1.9.2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from trafilatura) (1.9.3)\n",
      "Requirement already satisfied: justext>=3.0.1 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from trafilatura) (3.0.2)\n",
      "Requirement already satisfied: lxml>=5.3.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from trafilatura) (5.4.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from openai-whisper) (10.1.0)\n",
      "Requirement already satisfied: numba in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from openai-whisper) (0.59.1)\n",
      "Collecting tiktoken (from openai-whisper)\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from openai-whisper) (2.7.1+cu128)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from openai-whisper) (4.66.4)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from jsonlines) (24.3.0)\n",
      "Requirement already satisfied: babel>=2.16.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from courlan>=1.3.2->trafilatura) (2.17.0)\n",
      "Requirement already satisfied: tld>=0.13 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from courlan>=1.3.2->trafilatura) (0.13.1)\n",
      "Requirement already satisfied: dateparser>=1.1.2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from htmldate>=1.9.2->trafilatura) (1.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.9.0.post0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from htmldate>=1.9.2->trafilatura) (2.9.0.post0)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from numba->openai-whisper) (0.42.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper) (2025.7.34)\n",
      "Requirement already satisfied: filelock in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (69.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2024.2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (2025.2)\n",
      "Requirement already satisfied: tzlocal>=0.2 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (5.3.1)\n",
      "Requirement already satisfied: lxml_html_clean in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from lxml[html_clean]>=4.4.2->justext>=3.0.1->trafilatura) (0.4.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
      "Requirement already satisfied: tzdata in c:\\users\\ch939\\anaconda3\\lib\\site-packages (from tzlocal>=0.2->dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (2023.3)\n",
      "Downloading datasketch-1.6.5-py3-none-any.whl (89 kB)\n",
      "Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.9 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/894.9 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 524.3/894.9 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 894.9/894.9 kB 1.7 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: langdetect, openai-whisper\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993255 sha256=3cab49a307a8f8be003cfff92a8fd8b50f72ad08539ebeab10ecb298cc07f4c1\n",
      "  Stored in directory: c:\\users\\ch939\\appdata\\local\\pip\\cache\\wheels\\c1\\67\\88\\e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "  Building wheel for openai-whisper (pyproject.toml): started\n",
      "  Building wheel for openai-whisper (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=804013 sha256=f4180ced68ba89dbf3875c70f721fe9b74bf7172dd250eee7e0cb57ed9eb6476\n",
      "  Stored in directory: c:\\users\\ch939\\appdata\\local\\pip\\cache\\wheels\\61\\d2\\20\\09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
      "Successfully built langdetect openai-whisper\n",
      "Installing collected packages: langdetect, tiktoken, datasketch, openai-whisper\n",
      "Successfully installed datasketch-1.6.5 langdetect-1.0.9 openai-whisper-20250625 tiktoken-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect datasketch requests beautifulsoup4 trafilatura pytesseract pillow pdf2image openai-whisper jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting End-to-End Data Cleaner...\n",
      "\n",
      "--- Loading Data ---\n",
      "Loaded 410 documents with 2099409 initial tokens.\n",
      "\n",
      "--- Initial Cleaning & Language Detection ---\n",
      "Removed 2 documents due to non-English language or unreliable detection.\n",
      "Removed 0 documents that became empty after initial cleaning.\n",
      "Remaining documents after initial cleaning & language detection: 408\n",
      "\n",
      "--- Deduplication using MinHash LSH (Similarity >= 0.7) ---\n",
      "Building MinHashes and LSH index...\n",
      "Querying for duplicates...\n",
      "Removed 9 documents due to deduplication.\n",
      "Remaining documents after deduplication: 399\n",
      "\n",
      "--- PII Removal & Repetitive N-gram Removal ---\n",
      "\n",
      "--- Saving Clean Corpus to clean_corpus.txt ---\n",
      "Clean corpus saved successfully.\n",
      "\n",
      "--- Generating Statistics ---\n",
      "Statistics saved to stats.md\n",
      "\n",
      "End-to-End Cleaner process complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from langdetect import detect, DetectorFactory\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "import jsonlines\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# Ensure consistent language detection results\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# --- Configuration ---\n",
    "# Input file paths from previous modules\n",
    "ARXIV_CLEAN_JSON = \"arxiv_clean.json\"\n",
    "PDF_OCR_DIR = \"pdf_ocr\"\n",
    "TALKS_TRANSCRIPTS_JSONL = \"talks_transcripts.jsonl\" # From Module 3\n",
    "\n",
    "# Output file paths for this module\n",
    "CLEAN_CORPUS_FILE = \"clean_corpus.txt\"\n",
    "STATS_FILE = \"stats.md\"\n",
    "\n",
    "# Deduplication similarity threshold\n",
    "MINHASH_SIMILARITY_THRESHOLD = 0.7\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def load_arxiv_data(filepath):\n",
    "    \"\"\"Loads data from arxiv_clean.json.\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Warning: {filepath} not found. Skipping arXiv data.\")\n",
    "        return []\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error reading {filepath}: {e}\")\n",
    "        return []\n",
    "\n",
    "def load_pdf_ocr_data(directory):\n",
    "    \"\"\"Loads OCR'd text from the pdf_ocr directory.\"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Warning: {directory} not found. Skipping PDF OCR data.\")\n",
    "        return []\n",
    "    \n",
    "    ocr_texts = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            try:\n",
    "                with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                    ocr_texts.append({\"source\": f\"pdf_ocr/{filename}\", \"text\": f.read()})\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filepath}: {e}\")\n",
    "    return ocr_texts\n",
    "\n",
    "def load_talk_transcripts(filepath):\n",
    "    \"\"\"Loads talk transcripts from talks_transcripts.jsonl.\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Warning: {filepath} not found. Skipping talk transcripts.\")\n",
    "        return []\n",
    "    \n",
    "    transcripts = []\n",
    "    try:\n",
    "        with jsonlines.open(filepath, mode='r') as reader:\n",
    "            for obj in reader:\n",
    "                transcripts.append({\"source\": obj.get(\"url\", \"unknown_url\"), \"text\": obj.get(\"full_transcript\", \"\")})\n",
    "    except FileNotFoundError: # jsonlines can also raise this\n",
    "        print(f\"Error reading {filepath}: File not found.\")\n",
    "    except Exception as e: # Catch other potential errors\n",
    "        print(f\"Error reading {filepath}: {e}\")\n",
    "    return transcripts\n",
    "\n",
    "def strip_html_noise(text):\n",
    "    \"\"\"Removes basic HTML tags and entities.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    # Decode HTML entities (e.g., &amp; -> &) - this is a basic approach\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "    text = re.sub(r'&lt;', '<', text)\n",
    "    text = re.sub(r'&gt;', '>', text)\n",
    "    text = re.sub(r'&quot;', '\"', text)\n",
    "    text = re.sub(r'&#(\\d+);', lambda m: chr(int(m.group(1))), text)\n",
    "    text = re.sub(r'&#x([0-9a-fA-F]+);', lambda m: chr(int(m.group(1), 16)), text)\n",
    "    \n",
    "    # Remove excessive whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def detect_language(text):\n",
    "    \"\"\"Detects language of a text.\"\"\"\n",
    "    if not isinstance(text, str) or len(text.strip()) < 20: # Needs sufficient text for accurate detection\n",
    "        return None\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except Exception: # Handle cases where language cannot be reliably detected\n",
    "        return None\n",
    "\n",
    "def remove_pii(text):\n",
    "    \"\"\"Removes common PII (emails, credit card numbers, phone numbers).\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Email addresses\n",
    "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '[EMAIL]', text)\n",
    "    # Credit card numbers (simplified, common patterns)\n",
    "    # Visa: 4[0-9]{12}(?:[0-9]{3})?\n",
    "    # MasterCard: 5[1-5][0-9]{14}\n",
    "    # Amex: 3[47][0-9]{13}\n",
    "    # Discover: 6(?:011|5[0-9]{2})[0-9]{12}\n",
    "    text = re.sub(r'\\b(?:4[0-9]{12}(?:[0-9]{3})?|5[1-5][0-9]{14}|3[47][0-9]{13}|6(?:011|5[0-9]{2})[0-9]{12})\\b', '[CREDIT_CARD]', text)\n",
    "    # Phone numbers (common North American patterns for simplicity)\n",
    "    text = re.sub(r'\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}', '[PHONE]', text)\n",
    "    return text\n",
    "\n",
    "def create_shingles(text, k=9):\n",
    "    \"\"\"Generates k-shingles from a text.\"\"\"\n",
    "    text = text.lower() # Case-insensitive shingles\n",
    "    text = re.sub(r'\\s+', ' ', text) # Normalize whitespace\n",
    "    words = text.split()\n",
    "    if len(words) < k:\n",
    "        return {text} # If text is shorter than k words, treat the whole text as one shingle\n",
    "    \n",
    "    shingles = set()\n",
    "    for i in range(len(words) - k + 1):\n",
    "        shingles.add(\" \".join(words[i:i+k]))\n",
    "    return shingles\n",
    "\n",
    "def remove_repetitive_ngrams(text, n_min=3, n_max=5, threshold=3):\n",
    "    \"\"\"\n",
    "    Removes n-grams that repeat too frequently (e.g., more than 'threshold' times).\n",
    "    This is a heuristic for boilerplate/noisy text that repeats.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    words = text.split()\n",
    "    if len(words) < n_min:\n",
    "        return text\n",
    "\n",
    "    original_text = text\n",
    "    modified_text = list(words) # Work on a mutable list\n",
    "\n",
    "    # Iterate backwards to avoid index issues when removing\n",
    "    for n in range(n_max, n_min - 1, -1): # Check larger n-grams first\n",
    "        if len(words) < n:\n",
    "            continue\n",
    "        \n",
    "        ngrams = []\n",
    "        for i in range(len(words) - n + 1):\n",
    "            ngrams.append(tuple(words[i : i + n]))\n",
    "        \n",
    "        ngram_counts = Counter(ngrams)\n",
    "        \n",
    "        for ngram, count in ngram_counts.items():\n",
    "            if count > threshold:\n",
    "                # print(f\"  Removing repetitive {n}-gram: '{' '.join(ngram)}' (count: {count})\")\n",
    "                # Replace all occurrences of this repetitive n-gram with a single space\n",
    "                # This is a simple replacement; more sophisticated methods might use placeholders\n",
    "                pattern = r'\\b' + re.escape(' '.join(ngram)) + r'\\b'\n",
    "                original_text = re.sub(pattern, ' ', original_text, flags=re.IGNORECASE)\n",
    "                original_text = re.sub(r'\\s+', ' ', original_text).strip() # Normalize whitespace after replacement\n",
    "    return original_text\n",
    "\n",
    "\n",
    "# --- Main Cleaning and Deduplication Function ---\n",
    "\n",
    "def run_end_to_end_cleaner():\n",
    "    \"\"\"\n",
    "    Merges data, cleans, deduplicates, removes PII, and handles repetitive n-grams.\n",
    "    \"\"\"\n",
    "    print(\"Starting End-to-End Data Cleaner...\")\n",
    "\n",
    "    # 1. Load Data from all Modules\n",
    "    print(\"\\n--- Loading Data ---\")\n",
    "    arxiv_papers = load_arxiv_data(ARXIV_CLEAN_JSON)\n",
    "    pdf_ocr_texts = load_pdf_ocr_data(PDF_OCR_DIR)\n",
    "    talk_transcripts = load_talk_transcripts(TALKS_TRANSCRIPTS_JSONL)\n",
    "\n",
    "    all_raw_documents = []\n",
    "\n",
    "    # Add arXiv abstracts\n",
    "    for paper in arxiv_papers:\n",
    "        if paper.get('abstract'):\n",
    "            all_raw_documents.append({\n",
    "                \"source\": paper.get('url', 'arxiv_abstract'),\n",
    "                \"text\": paper['abstract'],\n",
    "                \"type\": \"arxiv_abstract\"\n",
    "            })\n",
    "    \n",
    "    # Add PDF OCR texts\n",
    "    for ocr_data in pdf_ocr_texts:\n",
    "        all_raw_documents.append({\n",
    "            \"source\": ocr_data['source'],\n",
    "            \"text\": ocr_data['text'],\n",
    "            \"type\": \"pdf_ocr\"\n",
    "        })\n",
    "\n",
    "    # Add talk transcripts\n",
    "    for transcript_data in talk_transcripts:\n",
    "        all_raw_documents.append({\n",
    "            \"source\": transcript_data['source'],\n",
    "            \"text\": transcript_data['text'],\n",
    "            \"type\": \"talk_transcript\"\n",
    "        })\n",
    "\n",
    "    total_initial_docs = len(all_raw_documents)\n",
    "    total_initial_tokens = sum(len(doc[\"text\"].split()) for doc in all_raw_documents if doc[\"text\"])\n",
    "    print(f\"Loaded {total_initial_docs} documents with {total_initial_tokens} initial tokens.\")\n",
    "\n",
    "    # 2. Initial Cleaning and Language Detection\n",
    "    print(\"\\n--- Initial Cleaning & Language Detection ---\")\n",
    "    cleaned_docs = []\n",
    "    docs_removed_lang = 0\n",
    "    docs_empty_after_clean = 0\n",
    "\n",
    "    for i, doc in enumerate(all_raw_documents):\n",
    "        cleaned_text = strip_html_noise(doc[\"text\"])\n",
    "        \n",
    "        # Language detection (only keep English)\n",
    "        lang = detect_language(cleaned_text)\n",
    "        if lang != 'en':\n",
    "            docs_removed_lang += 1\n",
    "            continue\n",
    "        \n",
    "        if not cleaned_text.strip():\n",
    "            docs_empty_after_clean += 1\n",
    "            continue\n",
    "\n",
    "        cleaned_docs.append({\n",
    "            \"id\": i, # Assign a unique ID for LSH\n",
    "            \"source\": doc[\"source\"],\n",
    "            \"type\": doc[\"type\"],\n",
    "            \"text\": cleaned_text\n",
    "        })\n",
    "    \n",
    "    print(f\"Removed {docs_removed_lang} documents due to non-English language or unreliable detection.\")\n",
    "    print(f\"Removed {docs_empty_after_clean} documents that became empty after initial cleaning.\")\n",
    "    print(f\"Remaining documents after initial cleaning & language detection: {len(cleaned_docs)}\")\n",
    "    \n",
    "    # 3. Deduplication using MinHash LSH\n",
    "    print(f\"\\n--- Deduplication using MinHash LSH (Similarity >= {MINHASH_SIMILARITY_THRESHOLD}) ---\")\n",
    "    num_perm = 128 # Number of permutations for MinHash\n",
    "    lsh = MinHashLSH(threshold=MINHASH_SIMILARITY_THRESHOLD, num_perm=num_perm)\n",
    "    \n",
    "    unique_documents = []\n",
    "    processed_doc_ids = set() # To track which documents have already been processed/added\n",
    "    \n",
    "    document_minhashes = {} # Store MinHash objects by ID\n",
    "    \n",
    "    # First pass: Create MinHashes and add to LSH\n",
    "    print(\"Building MinHashes and LSH index...\")\n",
    "    for doc in cleaned_docs:\n",
    "        shingles = create_shingles(doc[\"text\"])\n",
    "        if not shingles: # Skip if no shingles can be formed\n",
    "            continue\n",
    "        m = MinHash(num_perm=num_perm)\n",
    "        for s in shingles:\n",
    "            m.update(s.encode('utf8'))\n",
    "        document_minhashes[doc[\"id\"]] = m\n",
    "        lsh.insert(doc[\"id\"], m)\n",
    "\n",
    "    # Second pass: Query for duplicates\n",
    "    print(\"Querying for duplicates...\")\n",
    "    docs_removed_dedup = 0\n",
    "    for doc in cleaned_docs:\n",
    "        if doc[\"id\"] in processed_doc_ids:\n",
    "            continue # Already handled as a duplicate or original\n",
    "        \n",
    "        current_minhash = document_minhashes.get(doc[\"id\"])\n",
    "        if not current_minhash:\n",
    "            continue\n",
    "            \n",
    "        # Query LSH for similar items\n",
    "        # Returns a list of candidate IDs that might be duplicates\n",
    "        candidates = lsh.query(current_minhash)\n",
    "        \n",
    "        # Filter candidates based on exact MinHash similarity\n",
    "        # Since LSH is approximate, we need to verify exact similarity\n",
    "        is_duplicate = False\n",
    "        for candidate_id in candidates:\n",
    "            if candidate_id == doc[\"id\"]:\n",
    "                continue # Don't compare with self\n",
    "            \n",
    "            candidate_minhash = document_minhashes.get(candidate_id)\n",
    "            if candidate_minhash and current_minhash.jaccard(candidate_minhash) >= MINHASH_SIMILARITY_THRESHOLD:\n",
    "                # This current 'doc' is a duplicate of an already processed 'candidate_id'\n",
    "                if candidate_id in processed_doc_ids: # Ensure candidate is an original we already kept\n",
    "                    is_duplicate = True\n",
    "                    break\n",
    "        \n",
    "        if not is_duplicate:\n",
    "            unique_documents.append(doc)\n",
    "            processed_doc_ids.add(doc[\"id\"]) # Mark this as an original we're keeping\n",
    "        else:\n",
    "            docs_removed_dedup += 1\n",
    "\n",
    "    print(f\"Removed {docs_removed_dedup} documents due to deduplication.\")\n",
    "    print(f\"Remaining documents after deduplication: {len(unique_documents)}\")\n",
    "\n",
    "    # 4. PII Removal and Repetitive N-gram Removal\n",
    "    print(\"\\n--- PII Removal & Repetitive N-gram Removal ---\")\n",
    "    final_corpus_documents = []\n",
    "    tokens_after_dedup = sum(len(doc[\"text\"].split()) for doc in unique_documents)\n",
    "    tokens_after_pii_ngrams = 0\n",
    "\n",
    "    for doc in unique_documents:\n",
    "        text_after_pii = remove_pii(doc[\"text\"])\n",
    "        text_after_ngrams = remove_repetitive_ngrams(text_after_pii)\n",
    "        \n",
    "        final_corpus_documents.append(text_after_ngrams)\n",
    "        tokens_after_pii_ngrams += len(text_after_ngrams.split())\n",
    "    \n",
    "    # 5. Save Clean Corpus\n",
    "    print(f\"\\n--- Saving Clean Corpus to {CLEAN_CORPUS_FILE} ---\")\n",
    "    with open(CLEAN_CORPUS_FILE, 'w', encoding='utf-8') as f:\n",
    "        for text in final_corpus_documents:\n",
    "            f.write(text + \"\\n\\n\") # Add double newline for separation\n",
    "\n",
    "    print(\"Clean corpus saved successfully.\")\n",
    "\n",
    "    # 6. Generate Statistics\n",
    "    print(\"\\n--- Generating Statistics ---\")\n",
    "    stats_content = []\n",
    "    stats_content.append(\"# Corpus Cleaning Statistics\\n\")\n",
    "    stats_content.append(f\"**Total initial documents:** {total_initial_docs}\\n\")\n",
    "    stats_content.append(f\"**Total initial tokens:** {total_initial_tokens:,}\\n\")\n",
    "    \n",
    "    stats_content.append(\"\\n## Removal Breakdown:\\n\")\n",
    "    stats_content.append(f\"- Documents removed (non-English/empty after basic clean): {docs_removed_lang + docs_empty_after_clean}\\n\")\n",
    "    stats_content.append(f\"- Documents removed (deduplication): {docs_removed_dedup}\\n\")\n",
    "    stats_content.append(f\"- Final unique documents in corpus: {len(final_corpus_documents)}\\n\")\n",
    "    \n",
    "    final_tokens = sum(len(text.split()) for text in final_corpus_documents)\n",
    "    stats_content.append(f\"- Tokens after deduplication: {tokens_after_dedup:,}\\n\")\n",
    "    stats_content.append(f\"- Tokens after PII/Repetitive n-gram removal: {final_tokens:,}\\n\")\n",
    "\n",
    "    token_removal_percentage = 0\n",
    "    if total_initial_tokens > 0:\n",
    "        token_removal_percentage = ((total_initial_tokens - final_tokens) / total_initial_tokens) * 100\n",
    "    \n",
    "    stats_content.append(f\"\\n**Overall Token Removal Percentage:** {token_removal_percentage:.2f}%\\n\")\n",
    "\n",
    "    with open(STATS_FILE, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\".join(stats_content))\n",
    "\n",
    "    print(f\"Statistics saved to {STATS_FILE}\")\n",
    "    print(\"\\nEnd-to-End Cleaner process complete.\")\n",
    "\n",
    "# --- Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure you have run Modules 1, 2, and conceptually Module 3,\n",
    "    # and that their output files/directories exist in the expected paths.\n",
    "    \n",
    "    # IMPORTANT: The script will only process data that is *actually present*.\n",
    "    # If arxiv_clean.json, pdf_ocr/, or talks_transcripts.jsonl are missing,\n",
    "    # it will warn and skip those data sources.\n",
    "    \n",
    "    run_end_to_end_cleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
